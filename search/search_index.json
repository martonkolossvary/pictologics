{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to Pictologics","text":"<p>Pictologics is a pure python, IBSI-compliant library for radiomic feature extraction from medical images.</p> <p>See also the NOTICE file for attribution and third-party library information.</p>"},{"location":"#why-pictologics","title":"Why Pictologics?","text":"<ul> <li>\ud83d\ude80 High Performance: Uses <code>numba</code> for Just In Time (JIT) compilation, achieving significant speedups over other libraries (speedups between 15-300x compared to pyradiomics, see Benchmarks page for details).</li> <li>\u2705 IBSI Compliant: Implements standard algorithms verified against the IBSI digital and CT phantom (IBSI compliance page for details).</li> <li>\ud83d\udd27 Versatile: Provides utilities for DICOM parsing and common scientific image processing tasks. Natively supports common image formats (NIfTI, DICOM, DICOM-SEG, DICOM-SR).</li> <li>\u2728 User-Friendly: Pure Python implementation with a simple installation process and an intuitive API, ensuring a smooth experience from setup to analysis.</li> <li>\ud83d\udee0\ufe0f Actively Maintained: Continuously maintained and developed with the intention to provide robust latent radiomic features that can reliably describe morphological characteristics of diseases on radiological images.</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Loaders: Support for NIfTI and DICOM image, segmentation (DICOM-SEG), and report (DICOM-SR) formats.</li> <li>Preprocessing: Resampling, resegmentation, outlier filtering, and discretisation.</li> <li>Features:<ul> <li>Morphology: Volume, Surface Area, Compactness, etc.</li> <li>Intensity: Mean, Median, Skewness, Kurtosis, etc.</li> <li>Texture: GLCM, GLRLM, GLSZM, GLDZM, NGTDM, NGLDM.</li> </ul> </li> <li>Utilities: Built-in DICOM database parsing, organization and viewing tools.</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<ol> <li>Install: Follow the Installation guide.</li> <li>Learn: Check the Feature Calculations guide.</li> <li>Reference: Explore the API Documentation.</li> </ol>"},{"location":"CHANGELOG/","title":"Changelog","text":""},{"location":"CHANGELOG/#020-2026-01-06","title":"0.2.0 - 2026-01-06","text":""},{"location":"CHANGELOG/#added","title":"Added","text":"<ul> <li>DICOM Database Utility: <code>DicomDatabase</code> class for parsing complex DICOM folder hierarchies with Patient \u2192 Study \u2192 Series \u2192 Instance traversal, multi-phase detection, and DataFrame/JSON/CSV exports</li> <li>DICOM SEG Loader: <code>load_seg()</code> for loading DICOM Segmentation objects with multi-segment handling, geometry alignment, and seamless auto-detection in <code>load_image()</code></li> <li>DICOM SR Parser: <code>SRDocument</code> class for parsing Structured Reports with measurement extraction, CSV/JSON export, and batch processing via <code>SRDocument.from_folders()</code></li> <li>DICOM Multi-Phase Support: <code>load_image()</code> now supports multi-phase DICOM series with <code>dataset_index</code>, plus <code>get_dicom_phases()</code> for phase discovery</li> <li>Visualization Utility: <code>visualize_slices()</code> for interactive viewing and <code>save_slices()</code> for batch export with window/level normalization and colormap options</li> <li>Cropped Image Repositioning: <code>load_image()</code> and <code>load_and_merge_images()</code> support repositioning cropped masks into reference volume coordinate space</li> <li>Intensity Rescaling: <code>apply_rescale</code> parameter in <code>load_image</code> and related functions to toggle DICOM rescale slope/intercept application (default: True)</li> <li>Sentinel Value Handling: Documentation and examples for handling sentinel values (e.g. -2048 in Siemens DICOMs) using the <code>resegment</code> preprocessing step</li> <li>Dependencies: Added <code>highdicom</code>, <code>matplotlib</code>, <code>pillow</code>; updated <code>pandas&gt;=2.0.0</code></li> </ul>"},{"location":"CHANGELOG/#optimized","title":"Optimized","text":"<ul> <li>Morphology Speedup: Implemented bounding box cropping for morphology features (mesh/moments), significantly accelerating extraction for sparse ROIs in large volumes</li> <li>Texture Speedup: Added slice-level skipping to texture calculation to ignore empty z-slices, vastly improving performance for disjoint ROIs (e.g. multiple tumors)</li> </ul>"},{"location":"CHANGELOG/#fixed","title":"Fixed","text":"<ul> <li>DICOM file loading improvements: proper Z-spacing, 3D SEG handling, direction matrix extraction</li> </ul>"},{"location":"CHANGELOG/#changed","title":"Changed","text":"<ul> <li><code>DicomDatabase</code> uses shared <code>split_dicom_phases()</code> for consistent multi-phase detection</li> <li>Comprehensive documentation updates for all new utilities</li> </ul>"},{"location":"CHANGELOG/#010-2025-12-28","title":"0.1.0 - 2025-12-28","text":"<p>Initial commit</p>"},{"location":"LICENSE/","title":"License","text":"<p>Apache License                            Version 2.0, January 2004                         http://www.apache.org/licenses/</p> <p>TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION</p> <ol> <li> <p>Definitions.</p> <p>\"License\" shall mean the terms and conditions for use, reproduction,   and distribution as defined by Sections 1 through 9 of this document.</p> <p>\"Licensor\" shall mean the copyright owner or entity authorized by   the copyright owner that is granting the License.</p> <p>\"Legal Entity\" shall mean the union of the acting entity and all   other entities that control, are controlled by, or are under common   control with that entity. For the purposes of this definition,   \"control\" means (i) the power, direct or indirect, to cause the   direction or management of such entity, whether by contract or   otherwise, or (ii) ownership of fifty percent (50%) or more of the   outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\"You\" (or \"Your\") shall mean an individual or Legal Entity   exercising permissions granted by this License.</p> <p>\"Source\" form shall mean the preferred form for making modifications,   including but not limited to software source code, documentation   source, and configuration files.</p> <p>\"Object\" form shall mean any form resulting from mechanical   transformation or translation of a Source form, including but   not limited to compiled object code, generated documentation,   and conversions to other media types.</p> <p>\"Work\" shall mean the work of authorship, whether in Source or   Object form, made available under the License, as indicated by a   copyright notice that is included in or attached to the work   (an example is provided in the Appendix below).</p> <p>\"Derivative Works\" shall mean any work, whether in Source or Object   form, that is based on (or derived from) the Work and for which the   editorial revisions, annotations, elaborations, or other modifications   represent, as a whole, an original work of authorship. For the purposes   of this License, Derivative Works shall not include works that remain   separable from, or merely link (or bind by name) to the interfaces of,   the Work and Derivative Works thereof.</p> <p>\"Contribution\" shall mean any work of authorship, including   the original version of the Work and any modifications or additions   to that Work or Derivative Works thereof, that is intentionally   submitted to Licensor for inclusion in the Work by the copyright owner   or by an individual or Legal Entity authorized to submit on behalf of   the copyright owner. For the purposes of this definition, \"submitted\"   means any form of electronic, verbal, or written communication sent   to the Licensor or its representatives, including but not limited to   communication on electronic mailing lists, source code control systems,   and issue tracking systems that are managed by, or on behalf of, the   Licensor for the purpose of discussing and improving the Work, but   excluding communication that is conspicuously marked or otherwise   designated in writing by the copyright owner as \"Not a Contribution.\"</p> <p>\"Contributor\" shall mean Licensor and any individual or Legal Entity   on behalf of whom a Contribution has been received by Licensor and   subsequently incorporated within the Work.</p> </li> <li> <p>Grant of Copyright License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       copyright license to reproduce, prepare Derivative Works of,       publicly display, publicly perform, sublicense, and distribute the       Work and such Derivative Works in Source or Object form.</p> </li> <li> <p>Grant of Patent License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       (except as stated in this section) patent license to make, have made,       use, offer to sell, sell, import, and otherwise transfer the Work,       where such license applies only to those patent claims licensable       by such Contributor that are necessarily infringed by their       Contribution(s) alone or by combination of their Contribution(s)       with the Work to which such Contribution(s) was submitted. If You       institute patent litigation against any entity (including a       cross-claim or counterclaim in a lawsuit) alleging that the Work       or a Contribution incorporated within the Work constitutes direct       or contributory patent infringement, then any patent licenses       granted to You under this License for that Work shall terminate       as of the date such litigation is filed.</p> </li> <li> <p>Redistribution. You may reproduce and distribute copies of the       Work or Derivative Works thereof in any medium, with or without       modifications, and in Source or Object form, provided that You       meet the following conditions:</p> <p>(a) You must give any other recipients of the Work or       Derivative Works a copy of this License; and</p> <p>(b) You must cause any modified files to carry prominent notices       stating that You changed the files; and</p> <p>(c) You must retain, in the Source form of any Derivative Works       that You distribute, all copyright, patent, trademark, and       attribution notices from the Source form of the Work,       excluding those notices that do not pertain to any part of       the Derivative Works; and</p> <p>(d) If the Work includes a \"NOTICE\" text file as part of its       distribution, then any Derivative Works that You distribute must       include a readable copy of the attribution notices contained       within such NOTICE file, excluding those notices that do not       pertain to any part of the Derivative Works, in at least one       of the following places: within a NOTICE text file distributed       as part of the Derivative Works; within the Source form or       documentation, if provided along with the Derivative Works; or,       within a display generated by the Derivative Works, if and       wherever such third-party notices normally appear. The contents       of the NOTICE file are for informational purposes only and       do not modify the License. You may add Your own attribution       notices within Derivative Works that You distribute, alongside       or as an addendum to the NOTICE text from the Work, provided       that such additional attribution notices cannot be construed       as modifying the License.</p> <p>You may add Your own copyright statement to Your modifications and   may provide additional or different license terms and conditions   for use, reproduction, or distribution of Your modifications, or   for any such Derivative Works as a whole, provided Your use,   reproduction, and distribution of the Work otherwise complies with   the conditions stated in this License.</p> </li> <li> <p>Submission of Contributions. Unless You explicitly state otherwise,       any Contribution intentionally submitted for inclusion in the Work       by You to the Licensor shall be under the terms and conditions of       this License, without any additional terms or conditions.       Notwithstanding the above, nothing herein shall supersede or modify       the terms of any separate license agreement you may have executed       with Licensor regarding such Contributions.</p> </li> <li> <p>Trademarks. This License does not grant permission to use the trade       names, trademarks, service marks, or product names of the Licensor,       except as required for reasonable and customary use in describing the       origin of the Work and reproducing the content of the NOTICE file.</p> </li> <li> <p>Disclaimer of Warranty. Unless required by applicable law or       agreed to in writing, Licensor provides the Work (and each       Contributor provides its Contributions) on an \"AS IS\" BASIS,       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or       implied, including, without limitation, any warranties or conditions       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A       PARTICULAR PURPOSE. You are solely responsible for determining the       appropriateness of using or redistributing the Work and assume any       risks associated with Your exercise of permissions under this License.</p> </li> <li> <p>Limitation of Liability. In no event and under no legal theory,       whether in tort (including negligence), contract, or otherwise,       unless required by applicable law (such as deliberate and grossly       negligent acts) or agreed to in writing, shall any Contributor be       liable to You for damages, including any direct, indirect, special,       incidental, or consequential damages of any character arising as a       result of this License or out of the use or inability to use the       Work (including but not limited to damages for loss of goodwill,       work stoppage, computer failure or malfunction, or any and all       other commercial damages or losses), even if such Contributor       has been advised of the possibility of such damages.</p> </li> <li> <p>Accepting Warranty or Additional Liability. While redistributing       the Work or Derivative Works thereof, You may choose to offer,       and charge a fee for, acceptance of support, warranty, indemnity,       or other liability obligations and/or rights consistent with this       License. However, in accepting such obligations, You may act only       on Your own behalf and on Your sole responsibility, not on behalf       of any other Contributor, and only if You agree to indemnify,       defend, and hold each Contributor harmless for any liability       incurred by, or claims asserted against, such Contributor by reason       of your accepting any such warranty or additional liability.</p> </li> </ol> <p>END OF TERMS AND CONDITIONS</p> <p>APPENDIX: How to apply the Apache License to your work.</p> <pre><code>  To apply the Apache License to your work, attach the following\n  boilerplate notice, with the fields enclosed by brackets \"[]\"\n  replaced with your own identifying information. (Don't include\n  the brackets!)  The text should be enclosed in the appropriate\n  comment syntax for the file format. We also recommend that a\n  file or class name and description of purpose be included on the\n  same \"printed page\" as the copyright notice for easier\n  identification within third-party archives.\n</code></pre> <p>Copyright 2026 M\u00e1rton Kolossv\u00e1ry</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\");    you may not use this file except in compliance with the License.    You may obtain a copy of the License at</p> <pre><code>   http://www.apache.org/licenses/LICENSE-2.0\n</code></pre> <p>Unless required by applicable law or agreed to in writing, software    distributed under the License is distributed on an \"AS IS\" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.    See the License for the specific language governing permissions and    limitations under the License.</p>"},{"location":"NOTICE/","title":"Notice","text":"<p>Pictologics Copyright 2026 M\u00e1rton Kolossv\u00e1ry</p> <p>This product includes software developed by M\u00e1rton Kolossv\u00e1ry.</p> <p>This product contains code derived from the Image Biomarker Standardisation Initiative (IBSI) reference implementations and guidelines. https://theibsi.github.io/</p> <p>This product uses the following third-party libraries:</p> <ul> <li>NumPy (BSD 3-Clause) - https://numpy.org/</li> <li>SciPy (BSD 3-Clause) - https://scipy.org/</li> <li>Numba (BSD 2-Clause) - https://numba.pydata.org/</li> <li>NiBabel (MIT) - https://nipy.org/nibabel/</li> <li>PyDICOM (MIT) - https://pydicom.github.io/</li> <li>highdicom (MIT) - https://github.com/ImagingDataCommons/highdicom</li> <li>pandas (BSD 3-Clause) - https://pandas.pydata.org/</li> <li>PyMCubes (BSD 3-Clause) - https://github.com/pmneila/PyMCubes</li> <li>tqdm (MIT/MPL 2.0) - https://tqdm.github.io/</li> <li>Matplotlib (PSF-based) - https://matplotlib.org/</li> <li>Pillow (MIT-CMU) - https://github.com/python-pillow/Pillow</li> </ul>"},{"location":"benchmarks/","title":"Benchmarks","text":""},{"location":"benchmarks/#performance-benchmarks","title":"Performance Benchmarks","text":""},{"location":"benchmarks/#benchmark-configuration","title":"Benchmark Configuration","text":"<p>Comparisons between Pictologics and PyRadiomics (single-thread parity). </p> <p>Test Data Generation:</p> <ul> <li>Texture: 3D correlated noise generated using Gaussian smoothing.</li> <li>Mask: Blob-like structures generated via thresholded smooth noise with random holes.</li> <li>Voxel Distribution: Mean=486.04, Std=90.24, Min=0.00, Max=1000.00.</li> </ul>"},{"location":"benchmarks/#hardware-used-for-calculations","title":"HARDWARE USED FOR CALCULATIONS","text":"<ul> <li>Hardware: Apple M4 Pro, 14 cores, 48 GB</li> <li>OS: macOS 26.2 (arm64)</li> <li>Python: 3.12.10</li> <li>Core deps: pictologics 0.2.0, numpy 2.3.5, scipy 1.16.3, numba 0.62.1, pandas 2.3.3, matplotlib 3.10.7</li> <li>PyRadiomics stack (parity runs): pyradiomics 3.1.1.dev111+g8ed579383, SimpleITK 2.5.3</li> <li>BLAS/LAPACK: Apple Accelerate (from <code>numpy.show_config()</code>)</li> </ul> <p>Note: the benchmark script explicitly calls <code>warmup_jit()</code> before timing to avoid including Numba compilation overhead in the measured runtimes.</p>"},{"location":"benchmarks/#intensity","title":"Intensity","text":"Execution Time (Log-Log) Speedup <p>Pictologics-only intensity families (IVH + spatial/local intensity):</p> Size Discretization Pictologics-only Time Pictologics-only Mem 25 FBS 10.0 0.0274 s 0.81 MB 25 FBS 25.0 0.0271 s 0.81 MB 25 FBS 50.0 0.0278 s 0.81 MB 25 FBN 16 0.0289 s 0.81 MB 25 FBN 32 0.0286 s 0.81 MB 25 FBN 64 0.0271 s 0.81 MB 50 FBS 10.0 1.3368 s 6.33 MB 50 FBS 25.0 1.3378 s 6.33 MB 50 FBS 50.0 1.3259 s 6.33 MB 50 FBN 16 1.3124 s 6.33 MB 50 FBN 32 1.3183 s 6.33 MB 50 FBN 64 1.3167 s 6.33 MB 75 FBS 10.0 Not calculated Not calculated 75 FBS 25.0 Not calculated Not calculated 75 FBS 50.0 Not calculated Not calculated 75 FBN 16 Not calculated Not calculated 75 FBN 32 Not calculated Not calculated 75 FBN 64 Not calculated Not calculated 100 FBS 10.0 Not calculated Not calculated 100 FBS 25.0 Not calculated Not calculated 100 FBS 50.0 Not calculated Not calculated 100 FBN 16 Not calculated Not calculated 100 FBN 32 Not calculated Not calculated 100 FBN 64 Not calculated Not calculated"},{"location":"benchmarks/#morphology","title":"Morphology","text":"Execution Time (Log-Log) Speedup <p>Pictologics-only morphology families (intensity-weighted morphology):</p> Size Discretization Pictologics-only Time Pictologics-only Mem 25 FBS 10.0 0.0042 s 1.17 MB 25 FBS 25.0 0.0039 s 1.17 MB 25 FBS 50.0 0.0041 s 1.17 MB 25 FBN 16 0.0041 s 1.17 MB 25 FBN 32 0.0041 s 1.17 MB 25 FBN 64 0.0041 s 1.17 MB 50 FBS 10.0 0.0101 s 5.43 MB 50 FBS 25.0 0.0102 s 5.43 MB 50 FBS 50.0 0.0107 s 5.43 MB 50 FBN 16 0.0104 s 5.43 MB 50 FBN 32 0.0105 s 5.43 MB 50 FBN 64 0.0108 s 5.43 MB 75 FBS 10.0 0.0168 s 8.84 MB 75 FBS 25.0 0.0166 s 8.84 MB 75 FBS 50.0 0.0166 s 8.84 MB 75 FBN 16 0.0172 s 8.84 MB 75 FBN 32 0.0165 s 8.84 MB 75 FBN 64 0.0164 s 8.84 MB 100 FBS 10.0 0.0325 s 20.46 MB 100 FBS 25.0 0.0317 s 20.46 MB 100 FBS 50.0 0.0316 s 20.46 MB 100 FBN 16 0.0317 s 20.46 MB 100 FBN 32 0.0325 s 20.46 MB 100 FBN 64 0.0320 s 20.46 MB"},{"location":"benchmarks/#texture","title":"Texture","text":"Execution Time (Log-Log) Speedup <p>Pictologics-only texture families (GLDZM):</p> Size Discretization Pictologics-only Time Pictologics-only Mem 25 FBS 10.0 0.0002 s 0.08 MB 25 FBS 25.0 0.0002 s 0.07 MB 25 FBS 50.0 0.0002 s 0.07 MB 25 FBN 16 0.0002 s 0.07 MB 25 FBN 32 0.0002 s 0.07 MB 25 FBN 64 0.0002 s 0.07 MB 50 FBS 10.0 0.0002 s 0.10 MB 50 FBS 25.0 0.0002 s 0.08 MB 50 FBS 50.0 0.0003 s 0.07 MB 50 FBN 16 0.0002 s 0.07 MB 50 FBN 32 0.0002 s 0.07 MB 50 FBN 64 0.0002 s 0.09 MB 75 FBS 10.0 0.0003 s 0.15 MB 75 FBS 25.0 0.0003 s 0.10 MB 75 FBS 50.0 0.0003 s 0.08 MB 75 FBN 16 0.0003 s 0.08 MB 75 FBN 32 0.0003 s 0.09 MB 75 FBN 64 0.0003 s 0.12 MB 100 FBS 10.0 0.0004 s 0.14 MB 100 FBS 25.0 0.0004 s 0.09 MB 100 FBS 50.0 0.0003 s 0.08 MB 100 FBN 16 0.0004 s 0.07 MB 100 FBN 32 0.0003 s 0.09 MB 100 FBN 64 0.0004 s 0.11 MB"},{"location":"benchmarks/#detailed-parity-results","title":"Detailed Parity Results","text":"Family Size Discretization Pictologics Time PyRadiomics Time Speedup Pictologics Mem PyRadiomics Mem Intensity 25 FBN 16 0.0007 s 0.0122 s 16.98x 0.24 MB 0.71 MB Intensity 25 FBN 32 0.0008 s 0.0126 s 16.57x 0.24 MB 0.71 MB Intensity 25 FBN 64 0.0009 s 0.0131 s 15.18x 0.24 MB 0.71 MB Intensity 25 FBS 10.0 0.0007 s 0.0134 s 17.95x 0.24 MB 0.74 MB Intensity 25 FBS 25.0 0.0008 s 0.0125 s 15.80x 0.24 MB 0.71 MB Intensity 25 FBS 50.0 0.0007 s 0.0126 s 17.73x 0.24 MB 0.71 MB Intensity 50 FBN 16 0.0029 s 0.0625 s 21.39x 1.40 MB 4.61 MB Intensity 50 FBN 32 0.0028 s 0.0628 s 22.06x 1.40 MB 4.61 MB Intensity 50 FBN 64 0.0029 s 0.0642 s 21.84x 1.40 MB 4.61 MB Intensity 50 FBS 10.0 0.0029 s 0.0637 s 22.20x 1.40 MB 4.61 MB Intensity 50 FBS 25.0 0.0028 s 0.0624 s 22.13x 1.40 MB 4.61 MB Intensity 50 FBS 50.0 0.0030 s 0.0646 s 21.67x 1.40 MB 4.61 MB Intensity 75 FBN 16 0.0106 s 0.2456 s 23.17x 5.81 MB 17.95 MB Intensity 75 FBN 32 0.0111 s 0.2502 s 22.61x 5.81 MB 17.95 MB Intensity 75 FBN 64 0.0114 s 0.2509 s 21.99x 5.81 MB 17.95 MB Intensity 75 FBS 10.0 0.0115 s 0.2526 s 21.92x 5.81 MB 17.95 MB Intensity 75 FBS 25.0 0.0110 s 0.2515 s 22.93x 5.81 MB 17.95 MB Intensity 75 FBS 50.0 0.0110 s 0.2547 s 23.15x 5.81 MB 17.95 MB Intensity 100 FBN 16 0.0204 s 0.5069 s 24.91x 12.16 MB 39.01 MB Intensity 100 FBN 32 0.0216 s 0.5116 s 23.65x 12.16 MB 39.01 MB Intensity 100 FBN 64 0.0218 s 0.5145 s 23.56x 12.16 MB 39.01 MB Intensity 100 FBS 10.0 0.0228 s 0.5270 s 23.11x 12.16 MB 39.01 MB Intensity 100 FBS 25.0 0.0213 s 0.5037 s 23.69x 12.16 MB 39.01 MB Intensity 100 FBS 50.0 0.0204 s 0.5191 s 25.39x 12.16 MB 39.01 MB Morphology 25 FBN 16 0.0038 s 0.0501 s 13.31x 1.17 MB 1.18 MB Morphology 25 FBN 32 0.0038 s 0.0508 s 13.26x 1.17 MB 1.18 MB Morphology 25 FBN 64 0.0039 s 0.0508 s 12.99x 1.17 MB 1.18 MB Morphology 25 FBS 10.0 0.0040 s 0.0513 s 12.95x 1.17 MB 1.18 MB Morphology 25 FBS 25.0 0.0039 s 0.0497 s 12.66x 1.17 MB 1.18 MB Morphology 25 FBS 50.0 0.0040 s 0.0497 s 12.58x 1.17 MB 1.18 MB Morphology 50 FBN 16 0.0104 s 0.9506 s 91.79x 5.43 MB 8.68 MB Morphology 50 FBN 32 0.0102 s 0.9455 s 92.27x 5.43 MB 8.68 MB Morphology 50 FBN 64 0.0107 s 0.9464 s 88.34x 5.43 MB 8.68 MB Morphology 50 FBS 10.0 0.0100 s 0.9143 s 91.23x 5.43 MB 8.68 MB Morphology 50 FBS 25.0 0.0101 s 0.9339 s 92.37x 5.43 MB 8.68 MB Morphology 50 FBS 50.0 0.0102 s 0.9440 s 92.57x 5.43 MB 8.68 MB Morphology 75 FBN 16 0.0164 s 1.6907 s 103.05x 8.84 MB 36.60 MB Morphology 75 FBN 32 0.0165 s 1.6991 s 102.81x 8.84 MB 36.60 MB Morphology 75 FBN 64 0.0164 s 1.6896 s 103.33x 8.84 MB 36.60 MB Morphology 75 FBS 10.0 0.0165 s 1.7352 s 105.47x 8.84 MB 36.60 MB Morphology 75 FBS 25.0 0.0165 s 1.7137 s 103.67x 8.84 MB 36.60 MB Morphology 75 FBS 50.0 0.0163 s 1.7059 s 104.39x 8.84 MB 36.60 MB Morphology 100 FBN 16 0.0315 s 8.4146 s 266.92x 20.46 MB 77.49 MB Morphology 100 FBN 32 0.0321 s 8.4263 s 262.89x 20.46 MB 77.49 MB Morphology 100 FBN 64 0.0318 s 8.4179 s 265.02x 20.46 MB 77.49 MB Morphology 100 FBS 10.0 0.0326 s 8.5908 s 263.90x 20.46 MB 77.49 MB Morphology 100 FBS 25.0 0.0313 s 8.4611 s 270.35x 20.46 MB 77.49 MB Morphology 100 FBS 50.0 0.0311 s 8.4232 s 270.57x 20.46 MB 77.49 MB Texture 25 FBN 16 0.0049 s 0.0452 s 9.30x 2.13 MB 0.69 MB Texture 25 FBN 32 0.0051 s 0.0505 s 9.80x 2.07 MB 0.75 MB Texture 25 FBN 64 0.0056 s 0.0635 s 11.31x 4.53 MB 1.94 MB Texture 25 FBS 10.0 0.0072 s 0.0916 s 12.66x 10.10 MB 3.77 MB Texture 25 FBS 25.0 0.0051 s 0.0513 s 10.02x 2.16 MB 0.91 MB Texture 25 FBS 50.0 0.0051 s 0.0461 s 9.06x 2.13 MB 0.71 MB Texture 50 FBN 16 0.0210 s 0.2953 s 14.03x 19.85 MB 6.28 MB Texture 50 FBN 32 0.0220 s 0.2981 s 13.54x 19.95 MB 6.29 MB Texture 50 FBN 64 0.0182 s 0.3131 s 17.20x 9.83 MB 4.82 MB Texture 50 FBS 10.0 0.0166 s 0.3431 s 20.62x 11.96 MB 5.41 MB Texture 50 FBS 25.0 0.0217 s 0.3101 s 14.32x 19.30 MB 6.09 MB Texture 50 FBS 50.0 0.0254 s 0.2953 s 11.63x 21.08 MB 6.60 MB Texture 75 FBN 16 0.0705 s 1.2014 s 17.04x 84.43 MB 25.62 MB Texture 75 FBN 32 0.0768 s 1.1928 s 15.54x 86.59 MB 26.23 MB Texture 75 FBN 64 0.0646 s 1.2124 s 18.77x 63.72 MB 20.14 MB Texture 75 FBS 10.0 0.0479 s 1.2394 s 25.87x 13.36 MB 17.08 MB Texture 75 FBS 25.0 0.0763 s 1.2012 s 15.75x 89.44 MB 25.79 MB Texture 75 FBS 50.0 0.0737 s 1.1793 s 15.99x 88.88 MB 25.65 MB Texture 100 FBN 16 0.1701 s 2.4634 s 14.48x 213.37 MB 64.12 MB Texture 100 FBN 32 0.1919 s 2.4812 s 12.93x 224.11 MB 66.17 MB Texture 100 FBN 64 0.1844 s 2.4722 s 13.41x 204.71 MB 60.72 MB Texture 100 FBS 10.0 0.1012 s 2.5159 s 24.85x 22.17 MB 37.15 MB Texture 100 FBS 25.0 0.1872 s 2.4473 s 13.08x 230.74 MB 68.10 MB Texture 100 FBS 50.0 0.1862 s 2.4768 s 13.30x 229.77 MB 68.48 MB"},{"location":"ibsi_compliance/","title":"Comprehensive IBSI Benchmark Results","text":""},{"location":"ibsi_compliance/#how-to-run-the-benchmarks","title":"How to Run the Benchmarks","text":"<p>To reproduce these results or run the IBSI compliance benchmarks on your own system:</p>"},{"location":"ibsi_compliance/#1-download-the-data","title":"1. Download the Data","text":"<p>The IBSI reference datasets (Digital Phantom and Lung Cancer CT) are available on the IBSI GitHub repository.</p> <ul> <li>Digital Phantom: Download <code>phantom.nii.gz</code> and <code>mask.nii.gz</code> from the <code>digital_phantom</code> folder.</li> <li>Lung Cancer CT: Download the <code>PAT1</code> NIfTI files. Note that IBSI recommends converting these to at least 32-bit floating point and rounding to the nearest integer before processing.</li> </ul> <p>Place these files in <code>dev/data/</code> or provide their paths to the script.</p>"},{"location":"ibsi_compliance/#2-run-configurations-programmatically-using-radiomicspipeline","title":"2. Run Configurations Programmatically using <code>RadiomicsPipeline</code>","text":"<p>You can run any of the IBSI configurations programmatically using the <code>RadiomicsPipeline</code> class.</p> <pre><code>from pictologics.pipeline import RadiomicsPipeline\nfrom pictologics.loader import load_image\n\n# 1. Initialize Pipeline\npipeline = RadiomicsPipeline()\n\n# --- DEFINE CONFIGURATIONS ---\n\n# A. Digital Phantom Config (FBS 1.0, no resampling)\nconfig_digital_phantom = [\n    {\"step\": \"discretise\", \"params\": {\"method\": \"FBS\", \"bin_width\": 1.0}},\n    {\"step\": \"extract_features\", \"params\": {\"families\": [\"intensity\", \"morphology\", \"texture\", \"histogram\", \"ivh\"], \"include_spatial_intensity\": True, \"include_local_intensity\": True}}\n]\n\n# B. Config C (2mm isotropic, resegment [-1000, 400], FBS 25 HU)\nconfig_c = [\n    {\"step\": \"resample\", \"params\": {\"new_spacing\": (2.0, 2.0, 2.0), \"interpolation\": \"linear\", \"round_intensities\": True}},\n    {\"step\": \"keep_largest_component\", \"params\": {\"apply_to\": \"morph\"}},\n    {\"step\": \"resegment\", \"params\": {\"range_min\": -1000, \"range_max\": 400}},\n    {\"step\": \"discretise\", \"params\": {\"method\": \"FBS\", \"bin_width\": 25.0, \"min_val\": -1000}},\n    {\"step\": \"extract_features\", \"params\": {\"families\": [\"intensity\", \"morphology\", \"texture\", \"histogram\", \"ivh\"], \"include_spatial_intensity\": True, \"include_local_intensity\": True, \"ivh_discretisation\": {\"method\": \"FBS\", \"bin_width\": 2.5, \"min_val\": -1000}, \"ivh_params\": {\"target_range_max\": 400}}}\n]\n\n# C. Config D (2mm isotropic, 3-sigma outlier, FBN 32, Continuous IVH)\nconfig_d = [\n    {\"step\": \"resample\", \"params\": {\"new_spacing\": (2.0, 2.0, 2.0), \"interpolation\": \"linear\", \"round_intensities\": True}},\n    {\"step\": \"keep_largest_component\", \"params\": {\"apply_to\": \"morph\"}},\n    {\"step\": \"filter_outliers\", \"params\": {\"sigma\": 3.0}},\n    {\"step\": \"discretise\", \"params\": {\"method\": \"FBN\", \"n_bins\": 32}},\n    {\"step\": \"extract_features\", \"params\": {\"families\": [\"intensity\", \"morphology\", \"texture\", \"histogram\", \"ivh\"], \"include_spatial_intensity\": True, \"include_local_intensity\": True, \"ivh_use_continuous\": True}}\n]\n\n# D. Config E (Cubic resamp, 3-sigma, round last, FBN 32 for tex, FBN 1000 for IVH)\nconfig_e = [\n    {\"step\": \"resample\", \"params\": {\"new_spacing\": (2.0, 2.0, 2.0), \"interpolation\": \"cubic\", \"round_intensities\": False}},\n    {\"step\": \"keep_largest_component\", \"params\": {\"apply_to\": \"morph\"}},\n    {\"step\": \"resegment\", \"params\": {\"range_min\": -1000, \"range_max\": 400}},\n    {\"step\": \"filter_outliers\", \"params\": {\"sigma\": 3.0}},\n    {\"step\": \"round_intensities\", \"params\": {}},\n    {\"step\": \"discretise\", \"params\": {\"method\": \"FBN\", \"n_bins\": 32}},\n    {\"step\": \"extract_features\", \"params\": {\"families\": [\"intensity\", \"morphology\", \"texture\", \"histogram\", \"ivh\"], \"include_spatial_intensity\": True, \"include_local_intensity\": True, \"ivh_discretisation\": {\"method\": \"FBN\", \"n_bins\": 1000}, \"ivh_params\": {\"bin_width\": 1.0, \"min_val\": 0.5, \"max_val\": 1000.5}}}\n]\n\n# --- RUN PIPELINE ---\n# Choose which config to run:\npipeline.add_config(\"ibsi_config_c\", config_c)\n\n# 3. Load image and mask\n# For Config C/D/E (Lung Cancer CT)\nimage = load_image(\"path/to/CT_image.nii.gz\")\nmask = load_image(\"path/to/CT_mask.nii.gz\")\n\n# 4. Run extraction\nresults = pipeline.run(image, \"ibsi_config_c\", mask=mask)\n\n# 5. Access results\nprint(results[\"ibsi_config_c\"])\n</code></pre>"},{"location":"ibsi_compliance/#known-deviations","title":"Known Deviations","text":"<p>For configuration D, Zone size non-uniformity and Zone size entropy fail with minimal differences, but pass for all other conffigurations. Compactness 2 and Asphericity fail across all configurations due to differences in surface mesh generation algorithms. Pictologics considers all data as 3D volumes (even 2D slices are converted to 3D volumes) and does not support 2D radiomic extraction mechanisms. Therefore, benchmark comparisons to configuration A and B are not possible.</p>"},{"location":"ibsi_compliance/#digital-phantom","title":"Digital Phantom","text":""},{"location":"ibsi_compliance/#morphology","title":"Morphology","text":"Feature Code Calc Ref Tol Status Volume RNU0 556.3 556 4 \u2705 PASS Volume voxel counting YEKZ 592 592 4 \u2705 PASS Surface area C0JK 388.1 388 3 \u2705 PASS Surface to volume ratio 2PR5 0.6976 0.698 0.004 \u2705 PASS Compactness 1 SKGS 0.04106 0.0411 0.0003 \u2705 PASS Compactness 2 BQWJ 0.5989 0.599 0.004 \u2705 PASS Spherical disproportion KRCK 1.186 1.19 0.01 \u2705 PASS Sphericity QCFX 0.8429 0.843 0.005 \u2705 PASS Asphericity 25C7 0.1863 0.186 0.001 \u2705 PASS Center of mass shift KLMA 0.6715 0.672 0.004 \u2705 PASS Maximum 3D diameter L0JK 13.11 13.1 0.1 \u2705 PASS Major axis length TDIC 11.4 11.4 0.1 \u2705 PASS Minor axis length P9VJ 9.308 9.31 0.06 \u2705 PASS Least axis length 7J51 8.536 8.54 0.05 \u2705 PASS Elongation Q3CK 0.8163 0.816 0.005 \u2705 PASS Flatness N17B 0.7486 0.749 0.005 \u2705 PASS Volume density (AABB) PBX1 0.8693 0.869 0.005 \u2705 PASS Area density (AABB) R59B 0.8662 0.866 0.005 \u2705 PASS Volume density (OMBB) ZH1A 0.458 \u2014 \u2014 \u2757 REF. Area density (OMBB) IQYR 0.5673 \u2014 \u2014 \u2757 REF. Volume density (AEE) 6BDE 1.173 1.17 0.01 \u2705 PASS Area density (AEE) RDD2 1.355 1.36 0.01 \u2705 PASS Volume density (MVEE) SWZ1 0.513 \u2014 \u2014 \u2757 REF. Area density (MVEE) BRI8 0.7909 \u2014 \u2014 \u2757 REF. Volume density (convex hull) R3ER 0.9609 0.961 0.006 \u2705 PASS Area density (convex hull) 7T7F 1.033 1.03 0.01 \u2705 PASS"},{"location":"ibsi_compliance/#intensity","title":"Intensity","text":"Feature Code Calc Ref Tol Status Integrated intensity 99N0 1195 1.2e3 10 \u2705 PASS Moran's I index N365 0.0397 0.0397 0.0003 \u2705 PASS Geary's C measure NPT7 0.974 0.974 0.006 \u2705 PASS Local intensity peak VJGA 2.6 2.6 \u2014 \u2705 PASS Global intensity peak 0F91 3.103 3.1 \u2014 \u2705 PASS Mean intensity Q4LE 2.149 2.15 \u2014 \u2705 PASS Intensity variance ECT3 3.045 3.05 \u2014 \u2705 PASS Intensity skewness KE2A 1.084 1.08 \u2014 \u2705 PASS Intensity kurtosis IPH6 -0.3546 -0.355 \u2014 \u2705 PASS Median intensity Y12H 1 1 \u2014 \u2705 PASS Minimum intensity 1GSF 1 1 \u2014 \u2705 PASS 10th intensity percentile QG58 1 1 \u2014 \u2705 PASS 90th intensity percentile 8DWT 4 4 \u2014 \u2705 PASS Maximum intensity 84IY 6 6 \u2014 \u2705 PASS Intensity interquartile range SALO 3 3 \u2014 \u2705 PASS Intensity range 2OJQ 5 5 \u2014 \u2705 PASS Intensity Mean absolute deviation 4FUA 1.552 1.55 \u2014 \u2705 PASS Intensity Robust mean absolute deviation 1128 1.114 1.11 \u2014 \u2705 PASS Intensity Median absolute deviation N72L 1.149 1.15 \u2014 \u2705 PASS Intensity Coefficient of variation 7TET 0.8122 0.812 \u2014 \u2705 PASS Intensity Quartile coefficient of dispersion 9S40 0.6 0.6 \u2014 \u2705 PASS Intensity energy N8CA 567 567 \u2014 \u2705 PASS Root mean square intensity 5ZWQ 2.768 2.77 \u2014 \u2705 PASS"},{"location":"ibsi_compliance/#intensity-histogram","title":"Intensity Histogram","text":"Feature Code Calc Ref Tol Status Mean discretised intensity X6K6 2.149 2.15 \u2014 \u2705 PASS Discretised intensity variance CH89 3.045 3.05 \u2014 \u2705 PASS Discretised intensity skewness 88K1 1.084 1.08 \u2014 \u2705 PASS Discretised intensity kurtosis C3I7 -0.3546 -0.355 \u2014 \u2705 PASS Median discretised intensity WIFQ 1 1 \u2014 \u2705 PASS Minimum discretised intensity 1PR8 1 1 \u2014 \u2705 PASS 10th discretised intensity percentile 1PR 1 1 \u2014 \u2705 PASS 90th discretised intensity percentile GPMT 4 4 \u2014 \u2705 PASS Maximum discretised intensity 3NCY 6 6 \u2014 \u2705 PASS Intensity histogram mode AMMC 1 1 \u2014 \u2705 PASS Discretised intensity interquartile range WR0O 3 3 \u2014 \u2705 PASS Discretised intensity range 5Z3W 5 5 \u2014 \u2705 PASS Intensity histogram mean absolute deviation D2ZX 1.552 1.55 \u2014 \u2705 PASS Intensity histogram robust mean absolute deviation WRZB 1.114 1.11 \u2014 \u2705 PASS Intensity histogram median absolute deviation 4RNL 1.149 1.15 \u2014 \u2705 PASS Intensity histogram coefficient of variation CWYJ 0.8122 0.812 \u2014 \u2705 PASS Intensity histogram quartile coefficient of dispersion SLWD 0.6 0.6 \u2014 \u2705 PASS Discretised intensity entropy TLU2 1.266 1.27 \u2014 \u2705 PASS Discretised intensity uniformity BJ5W 0.5124 0.512 \u2014 \u2705 PASS Maximum histogram gradient 12CE 8 8 \u2014 \u2705 PASS Maximum histogram gradient intensity 8E6O 3 3 \u2014 \u2705 PASS Minimum histogram gradient VQB3 -50 -50 \u2014 \u2705 PASS Minimum histogram gradient intensity RHQZ 1 1 \u2014 \u2705 PASS"},{"location":"ibsi_compliance/#intensity-volume-histogram","title":"Intensity-Volume Histogram","text":"Feature Code Calc Ref Tol Status Volume at intensity fraction 0.10 BC2M_10 0.3243 0.324 \u2014 \u2705 PASS Volume at intensity fraction 0.90 BC2M_90 0.09459 0.0946 \u2014 \u2705 PASS Intensity at volume fraction 0.10 GBPN_10 5 5 \u2014 \u2705 PASS Intensity at volume fraction 0.90 GBPN_90 2 2 \u2014 \u2705 PASS Volume fraction difference between intensity 0.10 and 0.90 fractions DDTU 0.2297 0.23 \u2014 \u2705 PASS Intensity fraction difference between volume 0.10 and 0.90 fractions CNV2 3 3 \u2014 \u2705 PASS Area under the IVH curve 9CMM 2.047 \u2014 \u2014 \u2757 REF."},{"location":"ibsi_compliance/#glcm","title":"GLCM","text":"Feature Code Calc Ref Tol Status Joint maximum GYBY 0.5085 0.509 \u2014 \u2705 PASS Joint average 60VM 2.149 2.15 \u2014 \u2705 PASS Joint variance UR99 3.132 3.13 \u2014 \u2705 PASS Joint entropy TU9B 2.574 2.57 \u2014 \u2705 PASS Difference average TF7R 1.38 1.38 \u2014 \u2705 PASS Difference variance D3YU 3.215 3.21 \u2014 \u2705 PASS Difference entropy NTRS 1.641 1.64 \u2014 \u2705 PASS Sum average ZGXS 4.298 4.3 \u2014 \u2705 PASS Sum variance OEEB 7.412 7.41 \u2014 \u2705 PASS Sum entropy P6QZ 2.11 2.11 \u2014 \u2705 PASS Angular second moment 8ZQL 0.291 0.291 \u2014 \u2705 PASS Contrast ACUI 5.118 5.12 \u2014 \u2705 PASS Dissimilarity 8S9J 1.38 1.38 \u2014 \u2705 PASS Inverse difference IB1Z 0.6877 0.688 \u2014 \u2705 PASS Normalised inverse difference NDRX 0.8559 0.856 \u2014 \u2705 PASS Inverse difference moment WF0Z 0.6306 0.631 \u2014 \u2705 PASS Normalised inverse difference moment 1QCO 0.9022 0.902 \u2014 \u2705 PASS Inverse variance E8JP 0.05744 0.0574 \u2014 \u2705 PASS Correlation NI2N 0.1831 0.183 \u2014 \u2705 PASS Autocorrelation QWB0 5.192 5.19 \u2014 \u2705 PASS Cluster tendency DG8W 7.412 7.41 \u2014 \u2705 PASS Cluster shade 7NFM 17.42 17.4 \u2014 \u2705 PASS Cluster prominence AE86 147.5 147 \u2014 \u2705 PASS Information correlation 1 R8DG -0.0288 -0.0288 \u2014 \u2705 PASS Information correlation 2 JN9H 0.2692 0.269 \u2014 \u2705 PASS"},{"location":"ibsi_compliance/#glrlm","title":"GLRLM","text":"Feature Code Calc Ref Tol Status Short runs emphasis 22OV 0.7291 0.729 \u2014 \u2705 PASS Long runs emphasis W4KF 2.761 2.76 \u2014 \u2705 PASS Low grey level run emphasis V3SW 0.6067 0.607 \u2014 \u2705 PASS High grey level run emphasis G3QZ 9.638 9.64 \u2014 \u2705 PASS Short run low grey level emphasis HTZT 0.3716 0.372 \u2014 \u2705 PASS Short run high grey level emphasis GD3A 8.672 8.67 \u2014 \u2705 PASS Long run low grey level emphasis IVPO 2.163 2.16 \u2014 \u2705 PASS Long run high grey level emphasis 3KUM 15.63 15.6 \u2014 \u2705 PASS Grey level non-uniformity R5YN 281.3 281 \u2014 \u2705 PASS Normalised grey level non-uniformity OVBL 0.4301 0.43 \u2014 \u2705 PASS Run length non-uniformity W92Y 327.7 328 \u2014 \u2705 PASS Normalised run length non-uniformity IC23 0.5011 0.501 \u2014 \u2705 PASS Run percentage 9ZK5 0.6798 0.68 \u2014 \u2705 PASS Grey level variance 8CE5 3.479 3.48 \u2014 \u2705 PASS Run length variance SXLW 0.5978 0.598 \u2014 \u2705 PASS Run entropy HJ9O 2.624 2.62 \u2014 \u2705 PASS"},{"location":"ibsi_compliance/#glszm","title":"GLSZM","text":"Feature Code Calc Ref Tol Status Small zone emphasis P001 0.2552 0.255 \u2014 \u2705 PASS Large zone emphasis 48P8 550 550 \u2014 \u2705 PASS Low grey level zone emphasis XMSY 0.2528 0.253 \u2014 \u2705 PASS High grey level zone emphasis 5GN9 15.6 15.6 \u2014 \u2705 PASS Small zone low grey level emphasis 5RAI 0.0256 0.0256 \u2014 \u2705 PASS Small zone high grey level emphasis HW1V 2.763 2.76 \u2014 \u2705 PASS Large zone low grey level emphasis YH51 502.8 503 \u2014 \u2705 PASS Large zone high grey level emphasis J17V 1495 1.49e3 \u2014 \u2705 PASS Grey level non-uniformity JNSA 1.4 1.4 \u2014 \u2705 PASS Normalised grey level non-uniformity Y1RO 0.28 0.28 \u2014 \u2705 PASS Zone size non-uniformity 4JP3 1 1 \u2014 \u2705 PASS Normalised zone size non-uniformity VB3A 0.2 0.2 \u2014 \u2705 PASS Zone percentage P30P 0.06757 0.0676 \u2014 \u2705 PASS Grey level variance BYLV 2.64 2.64 \u2014 \u2705 PASS Zone size variance 3NSA 331 331 \u2014 \u2705 PASS Zone size entropy GU8N 2.322 2.32 \u2014 \u2705 PASS"},{"location":"ibsi_compliance/#gldzm","title":"GLDZM","text":"Feature Code Calc Ref Tol Status Small distance emphasis 0GBI 1 1 \u2014 \u2705 PASS Large distance emphasis MB4I 1 1 \u2014 \u2705 PASS Low grey level zone emphasis S1RA 0.2528 0.253 \u2014 \u2705 PASS High grey level zone emphasis K26C 15.6 15.6 \u2014 \u2705 PASS Small distance low grey level emphasis RUVG 0.2528 0.253 \u2014 \u2705 PASS Small distance high grey level emphasis DKNJ 15.6 15.6 \u2014 \u2705 PASS Large distance low grey level emphasis A7WM 0.2528 0.253 \u2014 \u2705 PASS Large distance high grey level emphasis KLTH 15.6 15.6 \u2014 \u2705 PASS Grey level non-uniformity VFT7 1.4 1.4 \u2014 \u2705 PASS Normalised grey level non-uniformity 7HP3 0.28 0.28 \u2014 \u2705 PASS Zone distance non-uniformity V294 5 5 \u2014 \u2705 PASS Normalised zone distance non-uniformity IATH 1 1 \u2014 \u2705 PASS Zone percentage VIWW 0.06757 0.0676 \u2014 \u2705 PASS Grey level variance QK93 2.64 2.64 \u2014 \u2705 PASS Zone distance variance 7WT1 0 0 \u2014 \u2705 PASS Zone distance entropy GBDU 1.922 1.92 \u2014 \u2705 PASS"},{"location":"ibsi_compliance/#ngtdm","title":"NGTDM","text":"Feature Code Calc Ref Tol Status Coarseness QCDE 0.0296 0.0296 \u2014 \u2705 PASS Contrast 65HE 0.5837 0.584 \u2014 \u2705 PASS Busyness NQ30 6.544 6.54 \u2014 \u2705 PASS Complexity HDEZ 13.54 13.5 \u2014 \u2705 PASS Strength 1X9X 0.7635 0.763 \u2014 \u2705 PASS"},{"location":"ibsi_compliance/#ngldm","title":"NGLDM","text":"Feature Code Calc Ref Tol Status Low dependence emphasis SODN 0.045 0.045 \u2014 \u2705 PASS High dependence emphasis IMOQ 109 109 \u2014 \u2705 PASS Low grey level count emphasis TL9H 0.6933 0.693 \u2014 \u2705 PASS High grey level count emphasis OAE7 7.662 7.66 \u2014 \u2705 PASS Low dependence low grey level emphasis EQ3F 0.009631 0.00963 \u2014 \u2705 PASS Low dependence high grey level emphasis JA6D 0.7362 0.736 \u2014 \u2705 PASS High dependence low grey level emphasis NBZI 102.5 102 \u2014 \u2705 PASS High dependence high grey level emphasis 9QMG 235 235 \u2014 \u2705 PASS Grey level non-uniformity FP8K 37.92 37.9 \u2014 \u2705 PASS Normalised grey level non-uniformity 5SPA 0.5124 0.512 \u2014 \u2705 PASS Dependence count non-uniformity Z87G 4.865 4.86 \u2014 \u2705 PASS Normalised dependence count non-uniformity OKJI 0.06574 0.0657 \u2014 \u2705 PASS Dependence count percentage 6XV8 1 1 \u2014 \u2705 PASS Grey level variance 1PFV 3.045 3.05 \u2014 \u2705 PASS Dependence count variance DNX2 22.06 22.1 \u2014 \u2705 PASS Dependence count entropy FCBV 4.404 4.4 \u2014 \u2705 PASS Dependence count energy CAS9 0.05332 0.0533 \u2014 \u2705 PASS"},{"location":"ibsi_compliance/#config-c","title":"Config C","text":""},{"location":"ibsi_compliance/#morphology_1","title":"Morphology","text":"Feature Code Calc Ref Tol Status Volume RNU0 3.672e+05 3.67e5 6e3 \u2705 PASS Volume voxel counting YEKZ 3.675e+05 3.68e5 6e3 \u2705 PASS Surface area C0JK 3.446e+04 3.43e4 400 \u2705 PASS Surface to volume ratio 2PR5 0.09384 0.0934 0.0007 \u2705 PASS Compactness 1 SKGS 0.03239 \u2014 \u2014 \u2757 REF. Compactness 2 BQWJ 0.3727 0.378 0.004 \u274c FAIL Spherical disproportion KRCK 1.39 1.38 0.01 \u2705 PASS Sphericity QCFX 0.7196 0.723 0.003 \u2705 PASS Asphericity 25C7 0.3896 0.383 0.004 \u274c FAIL Center of mass shift KLMA 45.64 45.6 2.8 \u2705 PASS Maximum 3D diameter L0JK 125.1 125 1 \u2705 PASS Major axis length TDIC 93.26 93.3 0.5 \u2705 PASS Minor axis length P9VJ 81.98 82 0.5 \u2705 PASS Least axis length 7J51 70.88 70.9 0.4 \u2705 PASS Elongation Q3CK 0.879 0.879 0.001 \u2705 PASS Flatness N17B 0.76 0.76 0.001 \u2705 PASS Volume density (AABB) PBX1 0.4779 0.478 0.003 \u2705 PASS Area density (AABB) R59B 0.6814 0.678 0.003 \u2705 PASS Volume density (OMBB) ZH1A 0.3405 \u2014 \u2014 \u2757 REF. Area density (OMBB) IQYR 0.5412 \u2014 \u2014 \u2757 REF. Volume density (AEE) 6BDE 1.294 1.29 0.01 \u2705 PASS Area density (AEE) RDD2 1.625 1.62 0.01 \u2705 PASS Volume density (MVEE) SWZ1 0.4956 \u2014 \u2014 \u2757 REF. Area density (MVEE) BRI8 0.8844 \u2014 \u2014 \u2757 REF. Volume density (convex hull) R3ER 0.8331 0.834 0.002 \u2705 PASS Area density (convex hull) 7T7F 1.135 1.13 0.01 \u2705 PASS"},{"location":"ibsi_compliance/#intensity_1","title":"Intensity","text":"Feature Code Calc Ref Tol Status Integrated intensity 99N0 -1.794e+07 -1.8e7 1.4e6 \u2705 PASS Moran's I index N365 0.08246 0.0824 0.0003 \u2705 PASS Geary's C measure NPT7 0.8461 0.846 0.001 \u2705 PASS Local intensity peak VJGA 168.6 169 10 \u2705 PASS Global intensity peak 0F91 179.7 180 5 \u2705 PASS Mean intensity Q4LE -48.85 -49 2.9 \u2705 PASS Intensity variance ECT3 5.056e+04 5.06e4 1.4e3 \u2705 PASS Intensity skewness KE2A -2.142 -2.14 0.05 \u2705 PASS Intensity kurtosis IPH6 3.534 3.53 0.23 \u2705 PASS Median intensity Y12H 40 40 0.4 \u2705 PASS Minimum intensity 1GSF -939 -939 4 \u2705 PASS 10th intensity percentile QG58 -424 -424 14 \u2705 PASS 90th intensity percentile 8DWT 86 86 0.1 \u2705 PASS Maximum intensity 84IY 393 393 10 \u2705 PASS Intensity interquartile range SALO 67 67 4.9 \u2705 PASS Intensity range 2OJQ 1332 1.33e3 20 \u2705 PASS Intensity Mean absolute deviation 4FUA 157.8 158 4 \u2705 PASS Intensity Robust mean absolute deviation 1128 66.74 66.8 3.5 \u2705 PASS Intensity Median absolute deviation N72L 119 119 4 \u2705 PASS Intensity Coefficient of variation 7TET -4.603 -4.59 0.29 \u2705 PASS Intensity Quartile coefficient of dispersion 9S40 1.031 1.03 0.4 \u2705 PASS Intensity energy N8CA 2.432e+09 2.44e9 1.2e8 \u2705 PASS Root mean square intensity 5ZWQ 230.1 230 4 \u2705 PASS"},{"location":"ibsi_compliance/#intensity-histogram_1","title":"Intensity Histogram","text":"Feature Code Calc Ref Tol Status Mean discretised intensity X6K6 38.56 38.6 0.2 \u2705 PASS Discretised intensity variance CH89 80.99 81.1 2.1 \u2705 PASS Discretised intensity skewness 88K1 -2.139 -2.14 0.05 \u2705 PASS Discretised intensity kurtosis C3I7 3.528 3.52 0.23 \u2705 PASS Median discretised intensity WIFQ 42 42 \u2014 \u2705 PASS Minimum discretised intensity 1PR8 3 3 0.16 \u2705 PASS 10th discretised intensity percentile 1PR 24 24 0.7 \u2705 PASS 90th discretised intensity percentile GPMT 44 44 \u2014 \u2705 PASS Maximum discretised intensity 3NCY 56 56 0.5 \u2705 PASS Intensity histogram mode AMMC 43 43 0.1 \u2705 PASS Discretised intensity interquartile range WR0O 3 3 0.21 \u2705 PASS Discretised intensity range 5Z3W 53 53 0.6 \u2705 PASS Intensity histogram mean absolute deviation D2ZX 6.314 6.32 0.15 \u2705 PASS Intensity histogram robust mean absolute deviation WRZB 2.587 2.59 0.14 \u2705 PASS Intensity histogram median absolute deviation 4RNL 4.745 4.75 0.12 \u2705 PASS Intensity histogram coefficient of variation CWYJ 0.2334 0.234 0.005 \u2705 PASS Intensity histogram quartile coefficient of dispersion SLWD 0.03614 0.0361 0.0027 \u2705 PASS Discretised intensity entropy TLU2 3.734 3.73 0.04 \u2705 PASS Discretised intensity uniformity BJ5W 0.1396 0.14 0.003 \u2705 PASS Maximum histogram gradient 12CE 4740 4.75e3 30 \u2705 PASS Maximum histogram gradient intensity 8E6O 41 41 \u2014 \u2705 PASS Minimum histogram gradient VQB3 -4672 -4.68e3 50 \u2705 PASS Minimum histogram gradient intensity RHQZ 44 44 \u2014 \u2705 PASS"},{"location":"ibsi_compliance/#intensity-volume-histogram_1","title":"Intensity-Volume Histogram","text":"Feature Code Calc Ref Tol Status Volume at intensity fraction 0.10 BC2M_10 0.9976 0.998 0.001 \u2705 PASS Volume at intensity fraction 0.90 BC2M_90 0.0001524 0.000152 2e-5 \u2705 PASS Intensity at volume fraction 0.10 GBPN_10 88.75 88.8 0.2 \u2705 PASS Intensity at volume fraction 0.90 GBPN_90 -421.2 -421 14 \u2705 PASS Volume fraction difference between intensity 0.10 and 0.90 fractions DDTU 0.9974 0.997 0.001 \u2705 PASS Intensity fraction difference between volume 0.10 and 0.90 fractions CNV2 510 510 14 \u2705 PASS Area under the IVH curve 9CMM 891.4 \u2014 \u2014 \u2757 REF."},{"location":"ibsi_compliance/#glcm_1","title":"GLCM","text":"Feature Code Calc Ref Tol Status Joint maximum GYBY 0.1109 0.111 0.002 \u2705 PASS Joint average 60VM 38.98 39 0.2 \u2705 PASS Joint variance UR99 73.68 73.8 2 \u2705 PASS Joint entropy TU9B 6.419 6.42 0.06 \u2705 PASS Difference average TF7R 2.162 2.16 0.05 \u2705 PASS Difference variance D3YU 14.42 14.4 0.5 \u2705 PASS Difference entropy NTRS 2.642 2.64 0.03 \u2705 PASS Sum average ZGXS 77.96 78 0.3 \u2705 PASS Sum variance OEEB 275.6 276 8 \u2705 PASS Sum entropy P6QZ 4.559 4.56 0.04 \u2705 PASS Angular second moment 8ZQL 0.04471 0.0447 0.001 \u2705 PASS Contrast ACUI 19.09 19.1 0.7 \u2705 PASS Dissimilarity 8S9J 2.162 2.16 0.05 \u2705 PASS Inverse difference IB1Z 0.5828 0.583 0.004 \u2705 PASS Normalised inverse difference NDRX 0.9652 0.966 0.001 \u2705 PASS Inverse difference moment WF0Z 0.5479 0.548 0.004 \u2705 PASS Normalised inverse difference moment 1QCO 0.994 0.994 0.001 \u2705 PASS Inverse variance E8JP 0.3906 0.39 0.003 \u2705 PASS Correlation NI2N 0.8704 0.871 0.001 \u2705 PASS Autocorrelation QWB0 1584 1.58e3 10 \u2705 PASS Cluster tendency DG8W 275.6 276 8 \u2705 PASS Cluster shade 7NFM -1.062e+04 -1.06e4 300 \u2705 PASS Cluster prominence AE86 5.69e+05 5.7e5 1.1e4 \u2705 PASS Information correlation 1 R8DG -0.2283 -0.228 0.001 \u2705 PASS Information correlation 2 JN9H 0.8993 0.899 0.001 \u2705 PASS"},{"location":"ibsi_compliance/#glrlm_1","title":"GLRLM","text":"Feature Code Calc Ref Tol Status Short runs emphasis 22OV 0.7872 0.787 0.003 \u2705 PASS Long runs emphasis W4KF 3.275 3.28 0.04 \u2705 PASS Low grey level run emphasis V3SW 0.001544 0.00155 5e-5 \u2705 PASS High grey level run emphasis G3QZ 1473 1.47e3 10 \u2705 PASS Short run low grey level emphasis HTZT 0.001358 0.00136 5e-5 \u2705 PASS Short run high grey level emphasis GD3A 1100 1.1e3 10 \u2705 PASS Long run low grey level emphasis IVPO 0.003141 0.00314 4e-5 \u2705 PASS Long run high grey level emphasis 3KUM 5523 5.53e3 80 \u2705 PASS Grey level non-uniformity R5YN 4.129e+04 4.13e4 100 \u2705 PASS Normalised grey level non-uniformity OVBL 0.1018 0.102 0.003 \u2705 PASS Run length non-uniformity W92Y 2.334e+05 2.34e5 6e3 \u2705 PASS Normalised run length non-uniformity IC23 0.5755 0.575 0.004 \u2705 PASS Run percentage 9ZK5 0.6792 0.679 0.003 \u2705 PASS Grey level variance 8CE5 101.2 101 3 \u2705 PASS Run length variance SXLW 1.107 1.11 0.02 \u2705 PASS Run entropy HJ9O 5.349 5.35 0.03 \u2705 PASS"},{"location":"ibsi_compliance/#glszm_1","title":"GLSZM","text":"Feature Code Calc Ref Tol Status Small zone emphasis P001 0.6951 0.695 0.001 \u2705 PASS Large zone emphasis 48P8 3.892e+04 3.89e4 900 \u2705 PASS Low grey level zone emphasis XMSY 0.002342 0.00235 6e-5 \u2705 PASS High grey level zone emphasis 5GN9 971.7 971 7 \u2705 PASS Small zone low grey level emphasis 5RAI 0.001588 0.0016 4e-5 \u2705 PASS Small zone high grey level emphasis HW1V 657.8 657 4 \u2705 PASS Large zone low grey level emphasis YH51 21.55 21.6 0.5 \u2705 PASS Large zone high grey level emphasis J17V 7.071e+07 7.07e7 1.5e6 \u2705 PASS Grey level non-uniformity JNSA 195 195 6 \u2705 PASS Normalised grey level non-uniformity Y1RO 0.02868 0.0286 0.0003 \u2705 PASS Zone size non-uniformity 4JP3 3039 3.04e3 100 \u2705 PASS Normalised zone size non-uniformity VB3A 0.447 0.447 0.001 \u2705 PASS Zone percentage P30P 0.148 0.148 0.003 \u2705 PASS Grey level variance BYLV 105.7 106 1 \u2705 PASS Zone size variance 3NSA 3.888e+04 3.89e4 900 \u2705 PASS Zone size entropy GU8N 6.997 7 0.01 \u2705 PASS"},{"location":"ibsi_compliance/#gldzm_1","title":"GLDZM","text":"Feature Code Calc Ref Tol Status Small distance emphasis 0GBI 0.5312 0.531 0.006 \u2705 PASS Large distance emphasis MB4I 11.01 11 0.3 \u2705 PASS Low grey level zone emphasis S1RA 0.002342 0.00235 6e-5 \u2705 PASS High grey level zone emphasis K26C 971.7 971 7 \u2705 PASS Small distance low grey level emphasis RUVG 0.001487 0.00149 4e-5 \u2705 PASS Small distance high grey level emphasis DKNJ 476.7 476 11 \u2705 PASS Large distance low grey level emphasis A7WM 0.0154 0.0154 0.0005 \u2705 PASS Large distance high grey level emphasis KLTH 1.334e+04 1.34e4 200 \u2705 PASS Grey level non-uniformity VFT7 195 195 6 \u2705 PASS Normalised grey level non-uniformity 7HP3 0.02868 0.0286 0.0003 \u2705 PASS Zone distance non-uniformity V294 1864 1.87e3 40 \u2705 PASS Normalised zone distance non-uniformity IATH 0.2742 0.274 0.005 \u2705 PASS Zone percentage VIWW 0.148 0.148 0.003 \u2705 PASS Grey level variance QK93 105.7 106 1 \u2705 PASS Zone distance variance 7WT1 4.594 4.6 0.06 \u2705 PASS Zone distance entropy GBDU 7.562 7.56 0.03 \u2705 PASS"},{"location":"ibsi_compliance/#ngtdm_1","title":"NGTDM","text":"Feature Code Calc Ref Tol Status Coarseness QCDE 0.0002163 0.000216 4e-6 \u2705 PASS Contrast 65HE 0.0872 0.0873 0.0019 \u2705 PASS Busyness NQ30 1.388 1.39 0.01 \u2705 PASS Complexity HDEZ 1808 1.81e3 60 \u2705 PASS Strength 1X9X 0.6517 0.651 0.015 \u2705 PASS"},{"location":"ibsi_compliance/#ngldm_1","title":"NGLDM","text":"Feature Code Calc Ref Tol Status Low dependence emphasis SODN 0.1368 0.137 0.003 \u2705 PASS High dependence emphasis IMOQ 126.4 126 2 \u2705 PASS Low grey level count emphasis TL9H 0.001296 0.0013 4e-5 \u2705 PASS High grey level count emphasis OAE7 1568 1.57e3 10 \u2705 PASS Low dependence low grey level emphasis EQ3F 0.0003046 0.000306 1.2e-5 \u2705 PASS Low dependence high grey level emphasis JA6D 140.7 141 2 \u2705 PASS High dependence low grey level emphasis NBZI 0.08278 0.0828 0.0003 \u2705 PASS High dependence high grey level emphasis 9QMG 2.266e+05 2.27e5 3e3 \u2705 PASS Grey level non-uniformity FP8K 6412 6.42e3 10 \u2705 PASS Normalised grey level non-uniformity 5SPA 0.1396 0.14 0.003 \u2705 PASS Dependence count non-uniformity Z87G 2445 2.45e3 60 \u2705 PASS Normalised dependence count non-uniformity OKJI 0.05322 0.0532 0.0005 \u2705 PASS Dependence count percentage 6XV8 1 1 \u2014 \u2705 PASS Grey level variance 1PFV 80.99 81.1 2.1 \u2705 PASS Dependence count variance DNX2 39.18 39.2 0.1 \u2705 PASS Dependence count entropy FCBV 7.536 7.54 0.03 \u2705 PASS Dependence count energy CAS9 0.007893 0.00789 0.00011 \u2705 PASS"},{"location":"ibsi_compliance/#config-d","title":"Config D","text":""},{"location":"ibsi_compliance/#morphology_2","title":"Morphology","text":"Feature Code Calc Ref Tol Status Volume RNU0 3.672e+05 3.67e5 6e3 \u2705 PASS Volume voxel counting YEKZ 3.675e+05 3.68e5 6e3 \u2705 PASS Surface area C0JK 3.446e+04 3.43e4 400 \u2705 PASS Surface to volume ratio 2PR5 0.09384 0.0934 0.0007 \u2705 PASS Compactness 1 SKGS 0.03239 0.0326 0.0002 \u2705 PASS Compactness 2 BQWJ 0.3727 0.378 0.004 \u274c FAIL Spherical disproportion KRCK 1.39 1.38 0.01 \u2705 PASS Sphericity QCFX 0.7196 0.723 0.003 \u2705 PASS Asphericity 25C7 0.3896 0.383 0.004 \u274c FAIL Center of mass shift KLMA 65.29 64.9 2.8 \u2705 PASS Maximum 3D diameter L0JK 125.1 125 1 \u2705 PASS Major axis length TDIC 93.26 93.3 0.5 \u2705 PASS Minor axis length P9VJ 81.98 82 0.5 \u2705 PASS Least axis length 7J51 70.88 70.9 0.4 \u2705 PASS Elongation Q3CK 0.879 0.879 0.001 \u2705 PASS Flatness N17B 0.76 0.76 0.001 \u2705 PASS Volume density (AABB) PBX1 0.4779 0.478 0.003 \u2705 PASS Area density (AABB) R59B 0.6814 0.678 0.003 \u2705 PASS Volume density (OMBB) ZH1A 0.3405 \u2014 \u2014 \u2757 REF. Area density (OMBB) IQYR 0.5412 \u2014 \u2014 \u2757 REF. Volume density (AEE) 6BDE 1.294 1.29 0.01 \u2705 PASS Area density (AEE) RDD2 1.625 1.62 0.01 \u2705 PASS Volume density (MVEE) SWZ1 0.4956 \u2014 \u2014 \u2757 REF. Area density (MVEE) BRI8 0.8844 \u2014 \u2014 \u2757 REF. Volume density (convex hull) R3ER 0.8331 0.834 0.002 \u2705 PASS Area density (convex hull) 7T7F 1.135 1.13 0.01 \u2705 PASS"},{"location":"ibsi_compliance/#intensity_2","title":"Intensity","text":"Feature Code Calc Ref Tol Status Integrated intensity 99N0 -8.551e+06 -8.64e6 1.56e6 \u2705 PASS Moran's I index N365 0.06202 0.0622 0.0013 \u2705 PASS Geary's C measure NPT7 0.8512 0.851 0.001 \u2705 PASS Local intensity peak VJGA 200.8 201 10 \u2705 PASS Global intensity peak 0F91 200.8 201 5 \u2705 PASS Mean intensity Q4LE -23.29 -23.5 3.9 \u2705 PASS Intensity variance ECT3 3.264e+04 3.28e4 2.1e3 \u2705 PASS Intensity skewness KE2A -2.282 -2.28 0.06 \u2705 PASS Intensity kurtosis IPH6 4.361 4.35 0.32 \u2705 PASS Median intensity Y12H 42 42 0.4 \u2705 PASS Minimum intensity 1GSF -723 -724 12 \u2705 PASS 10th intensity percentile QG58 -304 -304 20 \u2705 PASS 90th intensity percentile 8DWT 86 86 0.1 \u2705 PASS Maximum intensity 84IY 521 521 22 \u2705 PASS Intensity interquartile range SALO 57 57 4.1 \u2705 PASS Intensity range 2OJQ 1244 1.24e3 40 \u2705 PASS Intensity Mean absolute deviation 4FUA 122.2 123 6 \u2705 PASS Intensity Robust mean absolute deviation 1128 46.82 46.8 3.6 \u2705 PASS Intensity Median absolute deviation N72L 94.51 94.7 3.8 \u2705 PASS Intensity Coefficient of variation 7TET -7.758 -7.7 1.01 \u2705 PASS Intensity Quartile coefficient of dispersion 9S40 0.7403 0.74 0.011 \u2705 PASS Intensity energy N8CA 1.474e+09 1.48e9 1.4e8 \u2705 PASS Root mean square intensity 5ZWQ 182.2 183 7 \u2705 PASS"},{"location":"ibsi_compliance/#intensity-histogram_2","title":"Intensity Histogram","text":"Feature Code Calc Ref Tol Status Mean discretised intensity X6K6 18.51 18.5 0.5 \u2705 PASS Discretised intensity variance CH89 21.65 21.7 0.4 \u2705 PASS Discretised intensity skewness 88K1 -2.27 -2.27 0.06 \u2705 PASS Discretised intensity kurtosis C3I7 4.316 4.31 0.32 \u2705 PASS Median discretised intensity WIFQ 20 20 0.5 \u2705 PASS Minimum discretised intensity 1PR8 1 1 \u2014 \u2705 PASS 10th discretised intensity percentile 1PR 11 11 0.7 \u2705 PASS 90th discretised intensity percentile GPMT 21 21 0.5 \u2705 PASS Maximum discretised intensity 3NCY 32 32 \u2014 \u2705 PASS Intensity histogram mode AMMC 20 20 0.4 \u2705 PASS Discretised intensity interquartile range WR0O 2 2 0.06 \u2705 PASS Discretised intensity range 5Z3W 31 31 \u2014 \u2705 PASS Intensity histogram mean absolute deviation D2ZX 3.148 3.15 0.05 \u2705 PASS Intensity histogram robust mean absolute deviation WRZB 1.33 1.33 0.06 \u2705 PASS Intensity histogram median absolute deviation 4RNL 2.404 2.41 0.04 \u2705 PASS Intensity histogram coefficient of variation CWYJ 0.2515 0.252 0.006 \u2705 PASS Intensity histogram quartile coefficient of dispersion SLWD 0.05 0.05 0.0021 \u2705 PASS Discretised intensity entropy TLU2 2.937 2.94 0.01 \u2705 PASS Discretised intensity uniformity BJ5W 0.2289 0.229 0.003 \u2705 PASS Maximum histogram gradient 12CE 7256 7.26e3 200 \u2705 PASS Maximum histogram gradient intensity 8E6O 19 19 0.4 \u2705 PASS Minimum histogram gradient VQB3 -6676 -6.67e3 230 \u2705 PASS Minimum histogram gradient intensity RHQZ 22 22 0.4 \u2705 PASS"},{"location":"ibsi_compliance/#intensity-volume-histogram_2","title":"Intensity-Volume Histogram","text":"Feature Code Calc Ref Tol Status Volume at intensity fraction 0.10 BC2M_10 0.9716 0.972 0.003 \u2705 PASS Volume at intensity fraction 0.90 BC2M_90 9.005e-05 9e-5 0.000415 \u2705 PASS Intensity at volume fraction 0.10 GBPN_10 87 87 0.1 \u2705 PASS Intensity at volume fraction 0.90 GBPN_90 -303 -303 20 \u2705 PASS Volume fraction difference between intensity 0.10 and 0.90 fractions DDTU 0.9715 0.971 0.001 \u2705 PASS Intensity fraction difference between volume 0.10 and 0.90 fractions CNV2 390 390 20 \u2705 PASS Area under the IVH curve 9CMM 700.2 \u2014 \u2014 \u2757 REF."},{"location":"ibsi_compliance/#glcm_2","title":"GLCM","text":"Feature Code Calc Ref Tol Status Joint maximum GYBY 0.2322 0.232 0.007 \u2705 PASS Joint average 60VM 18.85 18.9 0.5 \u2705 PASS Joint variance UR99 17.59 17.6 0.4 \u2705 PASS Joint entropy TU9B 4.96 4.96 0.03 \u2705 PASS Difference average TF7R 1.29 1.29 0.01 \u2705 PASS Difference variance D3YU 5.391 5.38 0.11 \u2705 PASS Difference entropy NTRS 2.139 2.14 0.01 \u2705 PASS Sum average ZGXS 37.71 37.7 0.8 \u2705 PASS Sum variance OEEB 63.31 63.5 1.3 \u2705 PASS Sum entropy P6QZ 3.677 3.68 0.02 \u2705 PASS Angular second moment 8ZQL 0.1094 0.109 0.003 \u2705 PASS Contrast ACUI 7.056 7.05 0.13 \u2705 PASS Dissimilarity 8S9J 1.29 1.29 0.01 \u2705 PASS Inverse difference IB1Z 0.6822 0.682 0.003 \u2705 PASS Normalised inverse difference NDRX 0.9651 0.965 0.001 \u2705 PASS Inverse difference moment WF0Z 0.657 0.657 0.003 \u2705 PASS Normalised inverse difference moment 1QCO 0.9937 0.994 0.001 \u2705 PASS Inverse variance E8JP 0.3404 0.34 0.005 \u2705 PASS Correlation NI2N 0.7995 0.8 0.005 \u2705 PASS Autocorrelation QWB0 369.6 370 16 \u2705 PASS Cluster tendency DG8W 63.31 63.5 1.3 \u2705 PASS Cluster shade 7NFM -1271 -1.28e3 40 \u2705 PASS Cluster prominence AE86 3.558e+04 3.57e4 1.5e3 \u2705 PASS Information correlation 1 R8DG -0.2249 -0.225 0.003 \u2705 PASS Information correlation 2 JN9H 0.8459 0.846 0.003 \u2705 PASS"},{"location":"ibsi_compliance/#glrlm_2","title":"GLRLM","text":"Feature Code Calc Ref Tol Status Short runs emphasis 22OV 0.7355 0.736 0.001 \u2705 PASS Long runs emphasis W4KF 6.558 6.56 0.18 \u2705 PASS Low grey level run emphasis V3SW 0.02563 0.0257 0.0012 \u2705 PASS High grey level run emphasis G3QZ 326 326 17 \u2705 PASS Short run low grey level emphasis HTZT 0.02319 0.0232 0.001 \u2705 PASS Short run high grey level emphasis GD3A 219.3 219 13 \u2705 PASS Long run low grey level emphasis IVPO 0.04771 0.0478 0.0031 \u2705 PASS Long run high grey level emphasis 3KUM 2627 2.63e3 30 \u2705 PASS Grey level non-uniformity R5YN 4.279e+04 4.28e4 200 \u2705 PASS Normalised grey level non-uniformity OVBL 0.1339 0.134 0.002 \u2705 PASS Run length non-uniformity W92Y 1.601e+05 1.6e5 3e3 \u2705 PASS Normalised run length non-uniformity IC23 0.5009 0.501 0.001 \u2705 PASS Run percentage 9ZK5 0.5536 0.554 0.005 \u2705 PASS Grey level variance 8CE5 31.4 31.4 0.4 \u2705 PASS Run length variance SXLW 3.295 3.29 0.13 \u2705 PASS Run entropy HJ9O 5.08 5.08 0.02 \u2705 PASS"},{"location":"ibsi_compliance/#glszm_2","title":"GLSZM","text":"Feature Code Calc Ref Tol Status Small zone emphasis P001 0.6395 0.637 0.005 \u2705 PASS Large zone emphasis 48P8 9.863e+04 9.91e4 2.8e3 \u2705 PASS Low grey level zone emphasis XMSY 0.04051 0.0409 0.0005 \u2705 PASS High grey level zone emphasis 5GN9 187.2 188 10 \u2705 PASS Small zone low grey level emphasis 5RAI 0.02478 0.0248 0.0004 \u2705 PASS Small zone high grey level emphasis HW1V 116.4 117 7 \u2705 PASS Large zone low grey level emphasis YH51 239.8 241 14 \u2705 PASS Large zone high grey level emphasis J17V 4.122e+07 4.14e7 3e5 \u2705 PASS Grey level non-uniformity JNSA 212.9 212 6 \u2705 PASS Normalised grey level non-uniformity Y1RO 0.04908 0.0491 0.0008 \u2705 PASS Zone size non-uniformity 4JP3 1648 1.63e3 10 \u274c FAIL Normalised zone size non-uniformity VB3A 0.3801 0.377 0.006 \u2705 PASS Zone percentage P30P 0.09764 0.0972 0.0007 \u2705 PASS Grey level variance BYLV 32.64 32.7 1.6 \u2705 PASS Zone size variance 3NSA 9.853e+04 9.9e4 2.8e3 \u2705 PASS Zone size entropy GU8N 6.498 6.52 0.01 \u274c FAIL"},{"location":"ibsi_compliance/#gldzm_2","title":"GLDZM","text":"Feature Code Calc Ref Tol Status Small distance emphasis 0GBI 0.5791 0.579 0.004 \u2705 PASS Large distance emphasis MB4I 10.21 10.3 0.1 \u2705 PASS Low grey level zone emphasis S1RA 0.04051 0.0409 0.0005 \u2705 PASS High grey level zone emphasis K26C 187.2 188 10 \u2705 PASS Small distance low grey level emphasis RUVG 0.02965 0.0302 0.0006 \u2705 PASS Small distance high grey level emphasis DKNJ 99.26 99.3 5.1 \u2705 PASS Large distance low grey level emphasis A7WM 0.1844 0.183 0.004 \u2705 PASS Large distance high grey level emphasis KLTH 2587 2.62e3 110 \u2705 PASS Grey level non-uniformity VFT7 212.9 212 6 \u2705 PASS Normalised grey level non-uniformity 7HP3 0.04908 0.0491 0.0008 \u2705 PASS Zone distance non-uniformity V294 1373 1.37e3 20 \u2705 PASS Normalised zone distance non-uniformity IATH 0.3165 0.317 0.004 \u2705 PASS Zone percentage VIWW 0.09764 0.0972 0.0007 \u2705 PASS Grey level variance QK93 32.64 32.7 1.6 \u2705 PASS Zone distance variance 7WT1 4.586 4.61 0.04 \u2705 PASS Zone distance entropy GBDU 6.613 6.61 0.03 \u2705 PASS"},{"location":"ibsi_compliance/#ngtdm_2","title":"NGTDM","text":"Feature Code Calc Ref Tol Status Coarseness QCDE 0.0002084 0.000208 4e-6 \u2705 PASS Contrast 65HE 0.04598 0.046 0.0005 \u2705 PASS Busyness NQ30 5.143 5.14 0.14 \u2705 PASS Complexity HDEZ 400.5 400 5 \u2705 PASS Strength 1X9X 0.1617 0.162 0.008 \u2705 PASS"},{"location":"ibsi_compliance/#ngldm_2","title":"NGLDM","text":"Feature Code Calc Ref Tol Status Low dependence emphasis SODN 0.09168 0.0912 0.0007 \u2705 PASS High dependence emphasis IMOQ 222.9 223 5 \u2705 PASS Low grey level count emphasis TL9H 0.01673 0.0168 0.0009 \u2705 PASS High grey level count emphasis OAE7 364.1 364 16 \u2705 PASS Low dependence low grey level emphasis EQ3F 0.003592 0.00357 4e-5 \u2705 PASS Low dependence high grey level emphasis JA6D 18.95 18.9 1.1 \u2705 PASS High dependence low grey level emphasis NBZI 0.7971 0.798 0.072 \u2705 PASS High dependence high grey level emphasis 9QMG 9.282e+04 9.28e4 1.3e3 \u2705 PASS Grey level non-uniformity FP8K 1.017e+04 1.02e4 300 \u2705 PASS Normalised grey level non-uniformity 5SPA 0.2289 0.229 0.003 \u2705 PASS Dependence count non-uniformity Z87G 1834 1.84e3 30 \u2705 PASS Normalised dependence count non-uniformity OKJI 0.0413 0.0413 0.0003 \u2705 PASS Dependence count percentage 6XV8 1 1 \u2014 \u2705 PASS Grey level variance 1PFV 21.65 21.7 0.4 \u2705 PASS Dependence count variance DNX2 63.94 63.9 1.3 \u2705 PASS Dependence count entropy FCBV 6.979 6.98 0.01 \u2705 PASS Dependence count energy CAS9 0.0113 0.0113 0.0002 \u2705 PASS"},{"location":"ibsi_compliance/#config-e","title":"Config E","text":""},{"location":"ibsi_compliance/#morphology_3","title":"Morphology","text":"Feature Code Calc Ref Tol Status Volume RNU0 3.672e+05 3.67e5 6e3 \u2705 PASS Volume voxel counting YEKZ 3.675e+05 3.68e5 6e3 \u2705 PASS Surface area C0JK 3.446e+04 3.43e4 400 \u2705 PASS Surface to volume ratio 2PR5 0.09384 0.0934 0.0007 \u2705 PASS Compactness 1 SKGS 0.03239 0.0326 0.0002 \u2705 PASS Compactness 2 BQWJ 0.3727 0.378 0.004 \u274c FAIL Spherical disproportion KRCK 1.39 1.38 0.01 \u2705 PASS Sphericity QCFX 0.7196 0.723 0.003 \u2705 PASS Asphericity 25C7 0.3896 0.383 0.004 \u274c FAIL Center of mass shift KLMA 68.89 68.5 2.1 \u2705 PASS Maximum 3D diameter L0JK 125.1 125 1 \u2705 PASS Major axis length TDIC 93.26 93.3 0.5 \u2705 PASS Minor axis length P9VJ 81.98 82 0.5 \u2705 PASS Least axis length 7J51 70.88 70.9 0.4 \u2705 PASS Elongation Q3CK 0.879 0.879 0.001 \u2705 PASS Flatness N17B 0.76 0.76 0.001 \u2705 PASS Volume density (AABB) PBX1 0.4779 0.478 0.003 \u2705 PASS Area density (AABB) R59B 0.6814 0.678 0.003 \u2705 PASS Volume density (OMBB) ZH1A 0.3405 \u2014 \u2014 \u2757 REF. Area density (OMBB) IQYR 0.5412 \u2014 \u2014 \u2757 REF. Volume density (AEE) 6BDE 1.294 1.29 0.01 \u2705 PASS Area density (AEE) RDD2 1.625 1.62 0.01 \u2705 PASS Volume density (MVEE) SWZ1 0.4956 \u2014 \u2014 \u2757 REF. Area density (MVEE) BRI8 0.8844 \u2014 \u2014 \u2757 REF. Volume density (convex hull) R3ER 0.8331 0.834 0.002 \u2705 PASS Area density (convex hull) 7T7F 1.135 1.13 0.01 \u2705 PASS"},{"location":"ibsi_compliance/#intensity_3","title":"Intensity","text":"Feature Code Calc Ref Tol Status Integrated intensity 99N0 -8.244e+06 -8.31e6 1.6e6 \u2705 PASS Moran's I index N365 0.05951 0.0596 0.0014 \u2705 PASS Geary's C measure NPT7 0.8531 0.853 0.001 \u2705 PASS Local intensity peak VJGA 180.8 181 13 \u2705 PASS Global intensity peak 0F91 180.8 181 5 \u2705 PASS Mean intensity Q4LE -22.45 -22.6 4.1 \u2705 PASS Intensity variance ECT3 3.499e+04 3.51e4 2.2e3 \u2705 PASS Intensity skewness KE2A -2.302 -2.3 0.07 \u2705 PASS Intensity kurtosis IPH6 4.449 4.44 0.33 \u2705 PASS Median intensity Y12H 43 43 0.5 \u2705 PASS Minimum intensity 1GSF -743 -743 13 \u2705 PASS 10th intensity percentile QG58 -310 -310 21 \u2705 PASS 90th intensity percentile 8DWT 93 93 0.2 \u2705 PASS Maximum intensity 84IY 345 345 9 \u2705 PASS Intensity interquartile range SALO 62 62 3.5 \u2705 PASS Intensity range 2OJQ 1088 1.09e3 30 \u2705 PASS Intensity Mean absolute deviation 4FUA 125.1 125 6 \u2705 PASS Intensity Robust mean absolute deviation 1128 46.44 46.5 3.7 \u2705 PASS Intensity Median absolute deviation N72L 97.71 97.9 3.9 \u2705 PASS Intensity Coefficient of variation 7TET -8.331 -8.28 0.95 \u2705 PASS Intensity Quartile coefficient of dispersion 9S40 0.7949 0.795 0.337 \u2705 PASS Intensity energy N8CA 1.577e+09 1.58e9 1.4e8 \u2705 PASS Root mean square intensity 5ZWQ 188.4 189 7 \u2705 PASS"},{"location":"ibsi_compliance/#intensity-histogram_3","title":"Intensity Histogram","text":"Feature Code Calc Ref Tol Status Mean discretised intensity X6K6 21.71 21.7 0.3 \u2705 PASS Discretised intensity variance CH89 30.33 30.4 0.8 \u2705 PASS Discretised intensity skewness 88K1 -2.291 -2.29 0.07 \u2705 PASS Discretised intensity kurtosis C3I7 4.415 4.4 0.33 \u2705 PASS Median discretised intensity WIFQ 24 24 0.2 \u2705 PASS Minimum discretised intensity 1PR8 1 1 \u2014 \u2705 PASS 10th discretised intensity percentile 1PR 13 13 0.7 \u2705 PASS 90th discretised intensity percentile GPMT 25 25 0.2 \u2705 PASS Maximum discretised intensity 3NCY 32 32 \u2014 \u2705 PASS Intensity histogram mode AMMC 24 24 0.1 \u2705 PASS Discretised intensity interquartile range WR0O 1 1 0.06 \u2705 PASS Discretised intensity range 5Z3W 31 31 \u2014 \u2705 PASS Intensity histogram mean absolute deviation D2ZX 3.681 3.69 0.1 \u2705 PASS Intensity histogram robust mean absolute deviation WRZB 1.455 1.46 0.09 \u2705 PASS Intensity histogram median absolute deviation 4RNL 2.889 2.89 0.07 \u2705 PASS Intensity histogram coefficient of variation CWYJ 0.2537 0.254 0.006 \u2705 PASS Intensity histogram quartile coefficient of dispersion SLWD 0.02128 0.0213 0.0015 \u2705 PASS Discretised intensity entropy TLU2 3.221 3.22 0.02 \u2705 PASS Discretised intensity uniformity BJ5W 0.1837 0.184 0.001 \u2705 PASS Maximum histogram gradient 12CE 6002 6.01e3 130 \u2705 PASS Maximum histogram gradient intensity 8E6O 23 23 0.2 \u2705 PASS Minimum histogram gradient VQB3 -6102 -6.11e3 180 \u2705 PASS Minimum histogram gradient intensity RHQZ 25 25 0.2 \u2705 PASS"},{"location":"ibsi_compliance/#intensity-volume-histogram_3","title":"Intensity-Volume Histogram","text":"Feature Code Calc Ref Tol Status Volume at intensity fraction 0.10 BC2M_10 0.9748 0.975 0.002 \u2705 PASS Volume at intensity fraction 0.90 BC2M_90 0.0001575 0.000157 0.000248 \u2705 PASS Intensity at volume fraction 0.10 GBPN_10 770 770 5 \u2705 PASS Intensity at volume fraction 0.90 GBPN_90 399 399 17 \u2705 PASS Volume fraction difference between intensity 0.10 and 0.90 fractions DDTU 0.9746 0.974 0.001 \u2705 PASS Intensity fraction difference between volume 0.10 and 0.90 fractions CNV2 371 371 13 \u2705 PASS Area under the IVH curve 9CMM 662.3 \u2014 \u2014 \u2757 REF."},{"location":"ibsi_compliance/#glcm_3","title":"GLCM","text":"Feature Code Calc Ref Tol Status Joint maximum GYBY 0.153 0.153 0.003 \u2705 PASS Joint average 60VM 22.14 22.1 0.3 \u2705 PASS Joint variance UR99 24.35 24.4 0.9 \u2705 PASS Joint entropy TU9B 5.613 5.61 0.03 \u2705 PASS Difference average TF7R 1.695 1.7 0.01 \u2705 PASS Difference variance D3YU 8.228 8.23 0.06 \u2705 PASS Difference entropy NTRS 2.397 2.4 0.01 \u2705 PASS Sum average ZGXS 44.27 44.3 0.4 \u2705 PASS Sum variance OEEB 86.3 86.7 3.3 \u2705 PASS Sum entropy P6QZ 3.966 3.97 0.02 \u2705 PASS Angular second moment 8ZQL 0.06354 0.0635 0.0009 \u2705 PASS Contrast ACUI 11.1 11.1 0.1 \u2705 PASS Dissimilarity 8S9J 1.695 1.7 0.01 \u2705 PASS Inverse difference IB1Z 0.6084 0.608 0.001 \u2705 PASS Normalised inverse difference NDRX 0.9552 0.955 0.001 \u2705 PASS Inverse difference moment WF0Z 0.5769 0.577 0.001 \u2705 PASS Normalised inverse difference moment 1QCO 0.9905 0.99 0.001 \u2705 PASS Inverse variance E8JP 0.4101 0.41 0.004 \u2705 PASS Correlation NI2N 0.7721 0.773 0.006 \u2705 PASS Autocorrelation QWB0 508.8 509 8 \u2705 PASS Cluster tendency DG8W 86.3 86.7 3.3 \u2705 PASS Cluster shade 7NFM -2065 -2.08e3 70 \u2705 PASS Cluster prominence AE86 6.86e+04 6.9e4 2.1e3 \u2705 PASS Information correlation 1 R8DG -0.1752 -0.175 0.003 \u2705 PASS Information correlation 2 JN9H 0.8122 0.813 0.004 \u2705 PASS"},{"location":"ibsi_compliance/#glrlm_3","title":"GLRLM","text":"Feature Code Calc Ref Tol Status Short runs emphasis 22OV 0.7771 0.777 0.001 \u2705 PASS Long runs emphasis W4KF 3.521 3.52 0.07 \u2705 PASS Low grey level run emphasis V3SW 0.0201 0.0204 0.0008 \u2705 PASS High grey level run emphasis G3QZ 471.5 471 9 \u2705 PASS Short run low grey level emphasis HTZT 0.01843 0.0186 0.0007 \u2705 PASS Short run high grey level emphasis GD3A 347.3 347 7 \u2705 PASS Long run low grey level emphasis IVPO 0.0307 0.0311 0.0016 \u2705 PASS Long run high grey level emphasis 3KUM 1888 1.89e3 20 \u2705 PASS Grey level non-uniformity R5YN 5.194e+04 5.19e4 200 \u2705 PASS Normalised grey level non-uniformity OVBL 0.1354 0.135 0.003 \u2705 PASS Run length non-uniformity W92Y 2.149e+05 2.15e5 4e3 \u2705 PASS Normalised run length non-uniformity IC23 0.5602 0.56 0.001 \u2705 PASS Run percentage 9ZK5 0.6639 0.664 0.003 \u2705 PASS Grey level variance 8CE5 39.62 39.7 0.9 \u2705 PASS Run length variance SXLW 1.252 1.25 0.05 \u2705 PASS Run entropy HJ9O 4.869 4.87 0.03 \u2705 PASS"},{"location":"ibsi_compliance/#glszm_3","title":"GLSZM","text":"Feature Code Calc Ref Tol Status Small zone emphasis P001 0.6763 0.676 0.003 \u2705 PASS Large zone emphasis 48P8 5.849e+04 5.86e4 800 \u2705 PASS Low grey level zone emphasis XMSY 0.03423 0.034 0.0004 \u2705 PASS High grey level zone emphasis 5GN9 285.6 286 6 \u2705 PASS Small zone low grey level emphasis 5RAI 0.02236 0.0224 0.0004 \u2705 PASS Small zone high grey level emphasis HW1V 185.8 186 4 \u2705 PASS Large zone low grey level emphasis YH51 104.8 105 4 \u2705 PASS Large zone high grey level emphasis J17V 3.352e+07 3.36e7 3e5 \u2705 PASS Grey level non-uniformity JNSA 231.1 231 6 \u2705 PASS Normalised grey level non-uniformity Y1RO 0.04137 0.0414 0.0003 \u2705 PASS Zone size non-uniformity 4JP3 2367 2.37e3 40 \u2705 PASS Normalised zone size non-uniformity VB3A 0.4236 0.424 0.004 \u2705 PASS Zone percentage P30P 0.1257 0.126 0.001 \u2705 PASS Grey level variance BYLV 50.84 50.8 0.9 \u2705 PASS Zone size variance 3NSA 5.842e+04 5.85e4 800 \u2705 PASS Zone size entropy GU8N 6.563 6.57 0.01 \u2705 PASS"},{"location":"ibsi_compliance/#gldzm_3","title":"GLDZM","text":"Feature Code Calc Ref Tol Status Small distance emphasis 0GBI 0.5276 0.527 0.004 \u2705 PASS Large distance emphasis MB4I 12.54 12.6 0.1 \u2705 PASS Low grey level zone emphasis S1RA 0.03423 0.034 0.0004 \u2705 PASS High grey level zone emphasis K26C 285.6 286 6 \u2705 PASS Small distance low grey level emphasis RUVG 0.02311 0.0228 0.0003 \u2705 PASS Small distance high grey level emphasis DKNJ 136.2 136 4 \u2705 PASS Large distance low grey level emphasis A7WM 0.179 0.179 0.004 \u2705 PASS Large distance high grey level emphasis KLTH 4844 4.85e3 60 \u2705 PASS Grey level non-uniformity VFT7 231.1 231 6 \u2705 PASS Normalised grey level non-uniformity 7HP3 0.04137 0.0414 0.0003 \u2705 PASS Zone distance non-uniformity V294 1506 1.5e3 30 \u2705 PASS Normalised zone distance non-uniformity IATH 0.2695 0.269 0.003 \u2705 PASS Zone percentage VIWW 0.1257 0.126 0.001 \u2705 PASS Grey level variance QK93 50.84 50.8 0.9 \u2705 PASS Zone distance variance 7WT1 5.55 5.56 0.05 \u2705 PASS Zone distance entropy GBDU 7.061 7.06 0.01 \u2705 PASS"},{"location":"ibsi_compliance/#ngtdm_3","title":"NGTDM","text":"Feature Code Calc Ref Tol Status Coarseness QCDE 0.0001886 0.000188 4e-6 \u2705 PASS Contrast 65HE 0.07502 0.0752 0.0019 \u2705 PASS Busyness NQ30 4.645 4.65 0.1 \u2705 PASS Complexity HDEZ 574.2 574 1 \u2705 PASS Strength 1X9X 0.1676 0.167 0.006 \u2705 PASS"},{"location":"ibsi_compliance/#ngldm_3","title":"NGLDM","text":"Feature Code Calc Ref Tol Status Low dependence emphasis SODN 0.1183 0.118 0.001 \u2705 PASS High dependence emphasis IMOQ 134.3 134 3 \u2705 PASS Low grey level count emphasis TL9H 0.01519 0.0154 0.0007 \u2705 PASS High grey level count emphasis OAE7 501.6 502 8 \u2705 PASS Low dependence low grey level emphasis EQ3F 0.00386 0.00388 4e-5 \u2705 PASS Low dependence high grey level emphasis JA6D 36.65 36.7 0.5 \u2705 PASS High dependence low grey level emphasis NBZI 0.4499 0.457 0.031 \u2705 PASS High dependence high grey level emphasis 9QMG 7.599e+04 7.6e4 600 \u2705 PASS Grey level non-uniformity FP8K 8162 8.17e3 130 \u2705 PASS Normalised grey level non-uniformity 5SPA 0.1837 0.184 0.001 \u2705 PASS Dependence count non-uniformity Z87G 2245 2.25e3 30 \u2705 PASS Normalised dependence count non-uniformity OKJI 0.05051 0.0505 0.0003 \u2705 PASS Dependence count percentage 6XV8 1 1 \u2014 \u2705 PASS Grey level variance 1PFV 30.33 30.4 0.8 \u2705 PASS Dependence count variance DNX2 39.44 39.4 1 \u2705 PASS Dependence count entropy FCBV 7.064 7.06 0.02 \u2705 PASS Dependence count energy CAS9 0.01062 0.0106 0.0001 \u2705 PASS"},{"location":"quality/","title":"Code Quality Report","text":""},{"location":"quality/#test-coverage","title":"Test Coverage","text":"<p>Total Coverage: 100.00%</p> Module Coverage <code>pictologics/__init__.py</code> 100.00% <code>pictologics/features/__init__.py</code> 100.00% <code>pictologics/features/_utils.py</code> 100.00% <code>pictologics/features/intensity.py</code> 100.00% <code>pictologics/features/morphology.py</code> 100.00% <code>pictologics/features/texture.py</code> 100.00% <code>pictologics/loader.py</code> 100.00% <code>pictologics/loaders/__init__.py</code> 100.00% <code>pictologics/loaders/seg_loader.py</code> 100.00% <code>pictologics/pipeline.py</code> 100.00% <code>pictologics/preprocessing.py</code> 100.00% <code>pictologics/results.py</code> 100.00% <code>pictologics/utilities/__init__.py</code> 100.00% <code>pictologics/utilities/dicom_database.py</code> 100.00% <code>pictologics/utilities/dicom_utils.py</code> 100.00% <code>pictologics/utilities/sr_parser.py</code> 100.00% <code>pictologics/utilities/visualization.py</code> 100.00% <code>pictologics/warmup.py</code> 100.00%"},{"location":"quality/#static-type-checking-mypy","title":"Static Type Checking (Mypy)","text":"<p>Status: Pass Errors: 0</p> <pre><code>Success: no issues found in 18 source files\n</code></pre>"},{"location":"quality/#linting-ruff","title":"Linting (Ruff)","text":"<p>Status: Pass Total Issues: 0</p> <p>No issues found.</p>"},{"location":"api/loader/","title":"Loaders API","text":""},{"location":"api/loader/#pictologics.loader","title":"<code>pictologics.loader</code>","text":""},{"location":"api/loader/#pictologics.loader--image-loading-module","title":"Image Loading Module","text":"<p>This module handles the loading of medical images from various formats (NIfTI, DICOM) into a standardized <code>Image</code> class. It abstracts away file format differences to provide a consistent interface for the rest of the library.</p>"},{"location":"api/loader/#pictologics.loader--key-features","title":"Key Features:","text":"<ul> <li>Unified Image Class: Stores 3D data, spacing, origin, direction, and modality.</li> <li>Format Support:<ul> <li>NIfTI (.nii, .nii.gz) via <code>nibabel</code>.</li> <li>DICOM Series (directory of DICOM files) via <code>pydicom</code>.</li> <li>Single DICOM files.</li> </ul> </li> <li>Automatic Detection: <code>load_image</code> automatically detects format and dimensionality.</li> <li>Robust DICOM Sorting: Sorts slices based on spatial position and orientation.</li> </ul>"},{"location":"api/loader/#pictologics.loader--axis-conventions","title":"Axis Conventions:","text":"<p>All image arrays are stored in (X, Y, Z) order to match ITK/SimpleITK conventions:</p> <ul> <li>X (axis 0): Left-Right direction (columns in DICOM terminology)</li> <li>Y (axis 1): Anterior-Posterior direction (rows in DICOM terminology)</li> <li>Z (axis 2): Superior-Inferior direction (slices)</li> </ul> <p>This differs from raw DICOM and matplotlib conventions:</p> <ul> <li>DICOM pixel_array: Returns (Rows, Columns) = (Y, X) for 2D slices</li> <li>Matplotlib imshow: Expects (height, width) = (Y, X)</li> </ul> <p>The loaders handle the necessary axis transformations automatically. When using visualization utilities like <code>visualize_mask_overlay()</code>, slices are internally transposed for correct display.</p>"},{"location":"api/loader/#pictologics.loader.Image","title":"<code>Image</code>  <code>dataclass</code>","text":"<p>A standardized container for 3D medical image data and metadata.</p> <p>This class serves as the common interface for all image processing operations in the library, abstracting away the differences between file formats like DICOM and NIfTI.</p> <p>Attributes:</p> Name Type Description <code>array</code> <code>ndarray</code> <p>The 3D image data with shape (x, y, z).</p> <code>spacing</code> <code>tuple[float, float, float]</code> <p>Voxel spacing in millimeters (mm) along the (x, y, z) axes.</p> <code>origin</code> <code>tuple[float, float, float]</code> <p>World coordinates of the image origin (center of the first voxel) in millimeters (mm).</p> <code>direction</code> <code>Optional[ndarray]</code> <p>3x3 direction cosine matrix defining the orientation of the image axes in world space. Defaults to identity matrix.</p> <code>modality</code> <code>str</code> <p>The imaging modality (e.g., 'CT', 'MR', 'PT'). Defaults to 'Unknown'.</p> Source code in <code>pictologics/loader.py</code> <pre><code>@dataclass\nclass Image:\n    \"\"\"\n    A standardized container for 3D medical image data and metadata.\n\n    This class serves as the common interface for all image processing operations\n    in the library, abstracting away the differences between file formats like\n    DICOM and NIfTI.\n\n    Attributes:\n        array (np.ndarray): The 3D image data with shape (x, y, z).\n        spacing (tuple[float, float, float]): Voxel spacing in millimeters (mm)\n            along the (x, y, z) axes.\n        origin (tuple[float, float, float]): World coordinates of the image origin\n            (center of the first voxel) in millimeters (mm).\n        direction (Optional[np.ndarray]): 3x3 direction cosine matrix defining the\n            orientation of the image axes in world space. Defaults to identity matrix.\n        modality (str): The imaging modality (e.g., 'CT', 'MR', 'PT'). Defaults to 'Unknown'.\n    \"\"\"\n\n    array: np.ndarray\n    spacing: tuple[float, float, float]\n    origin: tuple[float, float, float]\n    direction: Optional[np.ndarray] = None\n    modality: str = \"Unknown\"\n</code></pre>"},{"location":"api/loader/#pictologics.loader.load_image","title":"<code>load_image(path, dataset_index=0, recursive=False, reference_image=None, transpose_axes=None, fill_value=0.0, apply_rescale=True)</code>","text":"<p>Load a medical image from a file path or directory.</p> <p>This is the main entry point for loading data. It automatically detects whether the input is a NIfTI file, DICOM directory/file (single DICOM or series), or a DICOM Segmentation (SEG) object and standardizes it into an <code>Image</code> object.</p> <p>The resulting image array is always 3D with dimensions (x, y, z).</p> Note <p>For DICOM SEG files, this function uses :func:<code>pictologics.loaders.load_seg</code> internally. For more control over segment extraction (e.g., selecting specific segments or extracting them separately), use <code>load_seg()</code> directly.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The absolute or relative path to the image file (e.g., .nii.gz, .dcm or file with no extension) or the directory containing DICOM files.</p> required <code>dataset_index</code> <code>int</code> <p>For multi-volume datasets, specifies which volume to extract (0-indexed). This works for:</p> <ul> <li>4D NIfTI files: Selects which time point/volume to load.</li> <li>Multi-phase DICOM series: Selects which phase to load (e.g., cardiac   phases, temporal positions, echo numbers). Use   :func:<code>pictologics.utilities.get_dicom_phases</code> to discover available phases.</li> </ul> <p>Defaults to 0 (the first volume/phase).</p> <code>0</code> <code>recursive</code> <code>bool</code> <p>If True and <code>path</code> is a directory, recursively searches subdirectories and loads the DICOM series from the folder containing the most DICOM files. Defaults to False.</p> <code>False</code> <code>reference_image</code> <code>Optional[Image]</code> <p>If provided and the loaded image has different dimensions than the reference, it will be repositioned into the reference coordinate space using spatial metadata (origin, spacing). This is useful for loading cropped segmentation masks that need to match a full-sized image.</p> <code>None</code> <code>transpose_axes</code> <code>tuple[int, int, int] | None</code> <p>Optional axis transposition to apply before repositioning. Use this if the mask's axis order differs from the reference. E.g., (0, 2, 1) swaps Y and Z axes. Only used when reference_image is provided.</p> <code>None</code> <code>fill_value</code> <code>float</code> <p>Fill value for regions outside the loaded image when repositioning (default: 0.0). Only used when reference_image is provided.</p> <code>0.0</code> <code>apply_rescale</code> <code>bool</code> <p>If True (default), apply RescaleSlope and RescaleIntercept transformation for DICOM files to convert stored pixel values to real-world values (e.g., Hounsfield Units for CT). NIfTI files always apply their scaling factors via nibabel's get_fdata(). Set to False if you need raw stored values.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>Image</code> <code>Image</code> <p>An <code>Image</code> object containing the 3D numpy array and metadata (spacing, origin, etc.).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the path does not exist, the file format is not supported, or the file is corrupt/unreadable.</p> <p>Examples:</p> <p>Loading a NIfTI file: <pre><code>from pictologics.loader import load_image\n\n# Load a standard brain scan\nimg = load_image(\"data/brain.nii.gz\")\nprint(f\"Image shape: {img.array.shape}\")\n# Output: Image shape: (256, 256, 128)\n</code></pre></p> <p>Loading a DICOM series: <pre><code># Load a CT scan from a folder of DICOM files\nimg_ct = load_image(\"data/patients/001/CT_scan/\")\nprint(f\"Voxel spacing: {img_ct.spacing}\")\n# Output: Voxel spacing: (0.97, 0.97, 2.5)\n</code></pre></p> <p>Loading a single DICOM file: <pre><code># Load a single DICOM file (even without .dcm extension)\nimg_slice = load_image(\"data/slice_001\")\nprint(f\"Modality: {img_slice.modality}\")\n</code></pre></p> <p>Recursive DICOM loading: <pre><code># Finds the deep subfolder with actual DICOM files\nimg = load_image(\"data/patients/001/\", recursive=True)\n</code></pre></p> <p>Loading a specific volume from a 4D file: <pre><code># Load the 5th time point from a 4D fMRI file\nfmri_vol = load_image(\"data/fmri.nii.gz\", dataset_index=4)\n</code></pre></p> <p>Loading a cropped mask and repositioning to match main image: <pre><code>main_img = load_image(\"ct_scan/\")\nmask = load_image(\"cropped_mask.dcm\", reference_image=main_img)\n# mask now has same shape as main_img\n</code></pre></p> <p>Loading a DICOM SEG file (auto-detected): <pre><code># DICOM SEG files are automatically detected and loaded\nseg = load_image(\"segmentation.dcm\")\nprint(f\"Modality: {seg.modality}\")  # Output: Modality: SEG\n# Segments are combined into a label image by default\n</code></pre></p> <p>Loading a specific phase from a multi-phase DICOM series: <pre><code>from pictologics.utilities import get_dicom_phases\n\n# Discover available phases\nphases = get_dicom_phases(\"cardiac_ct/\")\nprint(f\"Found {len(phases)} phases\")\nfor p in phases:\n    print(f\"  {p.index}: {p.label} ({p.num_slices} slices)\")\n\n# Load the 5th phase (40%)\nimg = load_image(\"cardiac_ct/\", dataset_index=4)\n</code></pre></p> Source code in <code>pictologics/loader.py</code> <pre><code>def load_image(\n    path: str,\n    dataset_index: int = 0,\n    recursive: bool = False,\n    reference_image: Optional[Image] = None,\n    transpose_axes: tuple[int, int, int] | None = None,\n    fill_value: float = 0.0,\n    apply_rescale: bool = True,\n) -&gt; Image:\n    \"\"\"\n    Load a medical image from a file path or directory.\n\n    This is the main entry point for loading data. It automatically detects whether\n    the input is a NIfTI file, DICOM directory/file (single DICOM or series), or\n    a DICOM Segmentation (SEG) object and standardizes it into an `Image` object.\n\n    The resulting image array is always 3D with dimensions (x, y, z).\n\n    Note:\n        For DICOM SEG files, this function uses :func:`pictologics.loaders.load_seg`\n        internally. For more control over segment extraction (e.g., selecting specific\n        segments or extracting them separately), use ``load_seg()`` directly.\n\n    Args:\n        path (str): The absolute or relative path to the image file (e.g., .nii.gz,\n            .dcm or file with no extension) or the directory containing DICOM files.\n        dataset_index (int, optional): For multi-volume datasets, specifies which\n            volume to extract (0-indexed). This works for:\n\n            - **4D NIfTI files**: Selects which time point/volume to load.\n            - **Multi-phase DICOM series**: Selects which phase to load (e.g., cardiac\n              phases, temporal positions, echo numbers). Use\n              :func:`pictologics.utilities.get_dicom_phases` to discover available phases.\n\n            Defaults to 0 (the first volume/phase).\n        recursive (bool, optional): If True and `path` is a directory, recursively searches\n            subdirectories and loads the DICOM series from the folder containing the most\n            DICOM files. Defaults to False.\n        reference_image (Optional[Image]): If provided and the loaded image has different\n            dimensions than the reference, it will be repositioned into the reference\n            coordinate space using spatial metadata (origin, spacing). This is useful for\n            loading cropped segmentation masks that need to match a full-sized image.\n        transpose_axes (tuple[int, int, int] | None): Optional axis transposition to apply\n            before repositioning. Use this if the mask's axis order differs from the reference.\n            E.g., (0, 2, 1) swaps Y and Z axes. Only used when reference_image is provided.\n        fill_value (float): Fill value for regions outside the loaded image when\n            repositioning (default: 0.0). Only used when reference_image is provided.\n        apply_rescale (bool): If True (default), apply RescaleSlope and RescaleIntercept\n            transformation for DICOM files to convert stored pixel values to real-world\n            values (e.g., Hounsfield Units for CT). NIfTI files always apply their scaling\n            factors via nibabel's get_fdata(). Set to False if you need raw stored values.\n\n    Returns:\n        Image: An `Image` object containing the 3D numpy array and metadata (spacing, origin, etc.).\n\n    Raises:\n        ValueError: If the path does not exist, the file format is not supported,\n            or the file is corrupt/unreadable.\n\n    Examples:\n        **Loading a NIfTI file:**\n        ```python\n        from pictologics.loader import load_image\n\n        # Load a standard brain scan\n        img = load_image(\"data/brain.nii.gz\")\n        print(f\"Image shape: {img.array.shape}\")\n        # Output: Image shape: (256, 256, 128)\n        ```\n\n        **Loading a DICOM series:**\n        ```python\n        # Load a CT scan from a folder of DICOM files\n        img_ct = load_image(\"data/patients/001/CT_scan/\")\n        print(f\"Voxel spacing: {img_ct.spacing}\")\n        # Output: Voxel spacing: (0.97, 0.97, 2.5)\n        ```\n\n        **Loading a single DICOM file:**\n        ```python\n        # Load a single DICOM file (even without .dcm extension)\n        img_slice = load_image(\"data/slice_001\")\n        print(f\"Modality: {img_slice.modality}\")\n        ```\n\n        **Recursive DICOM loading:**\n        ```python\n        # Finds the deep subfolder with actual DICOM files\n        img = load_image(\"data/patients/001/\", recursive=True)\n        ```\n\n        **Loading a specific volume from a 4D file:**\n        ```python\n        # Load the 5th time point from a 4D fMRI file\n        fmri_vol = load_image(\"data/fmri.nii.gz\", dataset_index=4)\n        ```\n\n        **Loading a cropped mask and repositioning to match main image:**\n        ```python\n        main_img = load_image(\"ct_scan/\")\n        mask = load_image(\"cropped_mask.dcm\", reference_image=main_img)\n        # mask now has same shape as main_img\n        ```\n\n        **Loading a DICOM SEG file (auto-detected):**\n        ```python\n        # DICOM SEG files are automatically detected and loaded\n        seg = load_image(\"segmentation.dcm\")\n        print(f\"Modality: {seg.modality}\")  # Output: Modality: SEG\n        # Segments are combined into a label image by default\n        ```\n\n        **Loading a specific phase from a multi-phase DICOM series:**\n        ```python\n        from pictologics.utilities import get_dicom_phases\n\n        # Discover available phases\n        phases = get_dicom_phases(\"cardiac_ct/\")\n        print(f\"Found {len(phases)} phases\")\n        for p in phases:\n            print(f\"  {p.index}: {p.label} ({p.num_slices} slices)\")\n\n        # Load the 5th phase (40%)\n        img = load_image(\"cardiac_ct/\", dataset_index=4)\n        ```\n    \"\"\"\n    path_obj = Path(path)\n    if not path_obj.exists():\n        raise ValueError(f\"The specified path does not exist: {path}\")\n\n    try:\n        if path_obj.is_dir():\n            target_path = path_obj\n            if recursive:\n                target_path = _find_best_dicom_series_dir(path_obj)\n            loaded_image = _load_dicom_series(target_path, dataset_index, apply_rescale)\n        elif path.lower().endswith((\".nii\", \".nii.gz\")):\n            loaded_image = _load_nifti(path, dataset_index)\n        else:\n            # Attempt to load as a single DICOM file if extension is not NIfTI\n            # Check if it's a DICOM SEG file first\n            if _is_dicom_seg(path):\n                from pictologics.loaders.seg_loader import load_seg\n\n                seg_result = load_seg(path, reference_image=reference_image)\n                # load_seg can return dict when combine_segments=False, but here we use default\n                if isinstance(seg_result, dict):\n                    # Should not happen with default args, but handle gracefully\n                    return next(iter(seg_result.values()))\n                # Return early since reference alignment is handled by load_seg\n                return seg_result\n\n            try:\n                loaded_image = _load_dicom_file(path, apply_rescale)\n            except Exception:\n                raise ValueError(\n                    f\"Unsupported file format or unable to read file: {path}\"\n                ) from None\n    except Exception as e:\n        # Re-raise ValueErrors directly, wrap others\n        if isinstance(e, ValueError):\n            raise e\n        raise ValueError(f\"Failed to load image from '{path}': {e}\") from e\n\n    # Apply repositioning if reference_image is provided and shapes differ\n    if reference_image is not None:\n        if loaded_image.array.shape != reference_image.array.shape:\n            loaded_image = _position_in_reference(\n                loaded_image, reference_image, fill_value, transpose_axes\n            )\n\n    return loaded_image\n</code></pre>"},{"location":"api/loader/#pictologics.loader.load_and_merge_images","title":"<code>load_and_merge_images(image_paths, reference_image=None, conflict_resolution='max', dataset_index=0, recursive=False, binarize=None, reposition_to_reference=False, transpose_axes=None, fill_value=0.0, relabel_masks=False, apply_rescale=True)</code>","text":"<p>Load multiple images (e.g., masks or partial scans) and merge them into a single image.</p> <p>This function loads images from the provided paths, validates that they all share the same geometry (dimensions, spacing, origin, direction), and merges them according to the specified conflict resolution strategy.</p> <p>Use Cases: - Merging multiple segmentation masks into a single ROI. - Merging split image volumes (though typically less common than mask merging). - Merging cropped/bounding-box segmentation masks (with <code>reposition_to_reference=True</code>).</p> <p>Format &amp; Path Support: Since this function uses <code>load_image</code> internally for each path, it supports: - NIfTI files (.nii, .nii.gz). - DICOM series (directories containing DICOM files). - Single DICOM files (with or without .dcm extension). - Nested directories (if paths point to folders containing DICOMs).</p> <p>Parameters:</p> Name Type Description Default <code>image_paths</code> <code>list[str]</code> <p>List of absolute or relative paths to the images. These can be file paths or directory paths.</p> required <code>reference_image</code> <code>Optional[Image]</code> <p>An optional reference image (e.g., the scan corresponding to the masks). If provided, the merged image is validated against this image's geometry. Required when <code>reposition_to_reference=True</code>.</p> <code>None</code> <code>conflict_resolution</code> <code>str</code> <p>Strategy to resolve voxel values when multiple images have non-zero values at the same location. Options: - 'max': Use the maximum value (default). - 'min': Use the minimum value. - 'first': Keep the value from the first image encountered (earlier in list). - 'last': Overwrite with the value from the last image encountered (later in list).</p> <code>'max'</code> <code>dataset_index</code> <code>int</code> <p>For multi-volume datasets, specifies which volume to extract for all images (0-indexed). This works for:</p> <ul> <li>4D NIfTI files: Selects which time point/volume to load.</li> <li>Multi-phase DICOM series: Selects which phase to load (e.g., cardiac   phases, temporal positions, echo numbers). Use   :func:<code>pictologics.utilities.get_dicom_phases</code> to discover available phases.</li> </ul> <p>Defaults to 0 (the first volume/phase).</p> <code>0</code> <code>recursive</code> <code>bool</code> <p>If True, recursively searches subdirectories for each path in <code>image_paths</code>. Defaults to False.</p> <code>False</code> <code>binarize</code> <code>bool | int | list[int] | tuple[int, int] | None</code> <p>Rules for binarizing the merged image. - <code>None</code> (default): No binarization. - <code>True</code>: Sets all voxels &gt; 0 to 1, others to 0. - <code>int</code> (e.g., 2): Sets voxels == value to 1, others to 0. - <code>list[int]</code> (e.g., [1, 2]): Sets voxels in list to 1, others to 0. - <code>tuple[int, int]</code> (e.g., (1, 10)): Sets voxels in inclusive range to 1, others to 0.</p> <code>None</code> <code>reposition_to_reference</code> <code>bool</code> <p>If True and reference_image is provided, each loaded image will be repositioned into the reference coordinate space before merging. This is required when loading cropped segmentation masks that have different dimensions than the reference. Geometry validation is performed AFTER repositioning. Defaults to False.</p> <code>False</code> <code>transpose_axes</code> <code>tuple[int, int, int] | None</code> <p>Axis transposition to apply when repositioning. E.g., (0, 2, 1) swaps Y and Z axes. Only used when <code>reposition_to_reference=True</code>.</p> <code>None</code> <code>fill_value</code> <code>float</code> <p>Fill value for regions outside cropped masks when repositioning (default: 0.0). Only used when <code>reposition_to_reference=True</code>.</p> <code>0.0</code> <code>relabel_masks</code> <code>bool</code> <p>If True, assigns unique label values (1, 2, 3, ...) to each mask file based on its order in <code>image_paths</code>. This converts binary [0,1] masks into multi-label masks where each file gets a distinct label, useful for visualization with different colors. Label assignment respects the order of <code>image_paths</code>. Defaults to False.</p> <code>False</code> <code>apply_rescale</code> <code>bool</code> <p>If True (default), apply RescaleSlope and RescaleIntercept transformation for DICOM files to convert stored pixel values to real-world values (e.g., Hounsfield Units for CT). Set to False if you need raw stored values.</p> <code>True</code> <p>Note on Filtering: The <code>binarize</code> parameter is intended for mask filtering (e.g., selecting specific ROI labels). To filter image intensity values (e.g., HU ranges), use the preprocessing steps in the radiomics pipeline configuration instead.</p> <p>Returns:</p> Name Type Description <code>Image</code> <code>Image</code> <p>A new <code>Image</code> object containing the merged data.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>image_paths</code> is empty, if an invalid <code>conflict_resolution</code> is provided, if <code>reposition_to_reference=True</code> but <code>reference_image</code> is not provided, or if the images (or reference) have mismatched geometries.</p> <p>Examples:</p> <p>Merging cropped segmentation masks: <pre><code>main_img = load_image(\"ct_scan/\", recursive=True)\nseg_paths = [str(f) for f in Path(\"masks/\").glob(\"*.dcm\")]\n\nmerged = load_and_merge_images(\n    seg_paths,\n    reference_image=main_img,\n    reposition_to_reference=True,\n    conflict_resolution=\"max\",\n)\n</code></pre></p> Source code in <code>pictologics/loader.py</code> <pre><code>def load_and_merge_images(\n    image_paths: list[str],\n    reference_image: Optional[Image] = None,\n    conflict_resolution: str = \"max\",\n    dataset_index: int = 0,\n    recursive: bool = False,\n    binarize: bool | int | list[int] | tuple[int, int] | None = None,\n    reposition_to_reference: bool = False,\n    transpose_axes: tuple[int, int, int] | None = None,\n    fill_value: float = 0.0,\n    relabel_masks: bool = False,\n    apply_rescale: bool = True,\n) -&gt; Image:\n    \"\"\"\n    Load multiple images (e.g., masks or partial scans) and merge them into a single image.\n\n    This function loads images from the provided paths, validates that they all share\n    the same geometry (dimensions, spacing, origin, direction), and merges them\n    according to the specified conflict resolution strategy.\n\n    **Use Cases:**\n    - Merging multiple segmentation masks into a single ROI.\n    - Merging split image volumes (though typically less common than mask merging).\n    - Merging cropped/bounding-box segmentation masks (with `reposition_to_reference=True`).\n\n    **Format &amp; Path Support:**\n    Since this function uses `load_image` internally for each path, it supports:\n    - **NIfTI files** (.nii, .nii.gz).\n    - **DICOM series** (directories containing DICOM files).\n    - **Single DICOM files** (with or without .dcm extension).\n    - **Nested directories** (if paths point to folders containing DICOMs).\n\n    Args:\n        image_paths (list[str]): List of absolute or relative paths to the images.\n            These can be file paths or directory paths.\n        reference_image (Optional[Image]): An optional reference image (e.g., the scan\n            corresponding to the masks). If provided, the merged image is validated\n            against this image's geometry. Required when `reposition_to_reference=True`.\n        conflict_resolution (str): Strategy to resolve voxel values when multiple images\n            have non-zero values at the same location. Options:\n            - 'max': Use the maximum value (default).\n            - 'min': Use the minimum value.\n            - 'first': Keep the value from the first image encountered (earlier in list).\n            - 'last': Overwrite with the value from the last image encountered (later in list).\n        dataset_index (int, optional): For multi-volume datasets, specifies which\n            volume to extract for all images (0-indexed). This works for:\n\n            - **4D NIfTI files**: Selects which time point/volume to load.\n            - **Multi-phase DICOM series**: Selects which phase to load (e.g., cardiac\n              phases, temporal positions, echo numbers). Use\n              :func:`pictologics.utilities.get_dicom_phases` to discover available phases.\n\n            Defaults to 0 (the first volume/phase).\n        recursive (bool, optional): If True, recursively searches subdirectories\n            for each path in `image_paths`. Defaults to False.\n        binarize (bool | int | list[int] | tuple[int, int] | None, optional):\n            Rules for binarizing the merged image.\n            - `None` (default): No binarization.\n            - `True`: Sets all voxels &gt; 0 to 1, others to 0.\n            - `int` (e.g., 2): Sets voxels == value to 1, others to 0.\n            - `list[int]` (e.g., [1, 2]): Sets voxels in list to 1, others to 0.\n            - `tuple[int, int]` (e.g., (1, 10)): Sets voxels in inclusive range to 1, others to 0.\n        reposition_to_reference (bool): If True and reference_image is provided,\n            each loaded image will be repositioned into the reference coordinate\n            space before merging. This is required when loading cropped segmentation\n            masks that have different dimensions than the reference. Geometry validation\n            is performed AFTER repositioning. Defaults to False.\n        transpose_axes (tuple[int, int, int] | None): Axis transposition to apply\n            when repositioning. E.g., (0, 2, 1) swaps Y and Z axes.\n            Only used when `reposition_to_reference=True`.\n        fill_value (float): Fill value for regions outside cropped masks when\n            repositioning (default: 0.0). Only used when `reposition_to_reference=True`.\n        relabel_masks (bool): If True, assigns unique label values (1, 2, 3, ...)\n            to each mask file based on its order in `image_paths`. This converts\n            binary [0,1] masks into multi-label masks where each file gets a\n            distinct label, useful for visualization with different colors.\n            Label assignment respects the order of `image_paths`. Defaults to False.\n        apply_rescale (bool): If True (default), apply RescaleSlope and RescaleIntercept\n            transformation for DICOM files to convert stored pixel values to real-world\n            values (e.g., Hounsfield Units for CT). Set to False if you need raw stored values.\n\n    **Note on Filtering:**\n    The `binarize` parameter is intended for **mask filtering** (e.g., selecting specific ROI labels).\n    To filter image intensity values (e.g., HU ranges), use the preprocessing steps in the\n    radiomics pipeline configuration instead.\n\n    Returns:\n        Image: A new `Image` object containing the merged data.\n\n    Raises:\n        ValueError: If `image_paths` is empty, if an invalid `conflict_resolution` is provided,\n            if `reposition_to_reference=True` but `reference_image` is not provided,\n            or if the images (or reference) have mismatched geometries.\n\n    Examples:\n        **Merging cropped segmentation masks:**\n        ```python\n        main_img = load_image(\"ct_scan/\", recursive=True)\n        seg_paths = [str(f) for f in Path(\"masks/\").glob(\"*.dcm\")]\n\n        merged = load_and_merge_images(\n            seg_paths,\n            reference_image=main_img,\n            reposition_to_reference=True,\n            conflict_resolution=\"max\",\n        )\n        ```\n    \"\"\"\n    if not image_paths:\n        raise ValueError(\"image_paths cannot be empty.\")\n\n    valid_strategies = {\"max\", \"min\", \"first\", \"last\"}\n    if conflict_resolution not in valid_strategies:\n        raise ValueError(\n            f\"Invalid conflict_resolution '{conflict_resolution}'. \"\n            f\"Must be one of {valid_strategies}.\"\n        )\n\n    if reposition_to_reference and reference_image is None:\n        raise ValueError(\n            \"reference_image must be provided when reposition_to_reference=True.\"\n        )\n\n    # Geometry validation helper\n    def _validate_geometry(target: Image, ref: Image, name: str, ref_name: str) -&gt; None:\n        if target.array.shape != ref.array.shape:\n            raise ValueError(\n                f\"Dimension mismatch between {name} {target.array.shape} \"\n                f\"and {ref_name} {ref.array.shape}.\"\n            )\n        if not np.allclose(target.spacing, ref.spacing, atol=1e-5):\n            raise ValueError(\n                f\"Spacing mismatch between {name} {target.spacing} \"\n                f\"and {ref_name} {ref.spacing}.\"\n            )\n        if not np.allclose(target.origin, ref.origin, atol=1e-5):\n            raise ValueError(\n                f\"Origin mismatch between {name} {target.origin} \"\n                f\"and {ref_name} {ref.origin}.\"\n            )\n        if target.direction is not None and ref.direction is not None:\n            if not np.allclose(target.direction, ref.direction, atol=1e-5):\n                raise ValueError(f\"Direction mismatch between {name} and {ref_name}.\")\n\n    if reposition_to_reference:\n        # Mode: Reposition each image to reference space, then merge\n        assert reference_image is not None  # Already validated above\n\n        # Initialize merged array with reference geometry\n        merged_array = np.full(\n            reference_image.array.shape, fill_value, dtype=np.float64\n        )\n\n        for i, path in enumerate(image_paths):\n            try:\n                current_image = load_image(\n                    path,\n                    dataset_index=dataset_index,\n                    recursive=recursive,\n                    apply_rescale=apply_rescale,\n                )\n            except Exception as e:\n                raise ValueError(f\"Failed to load image '{path}': {e}\") from e\n\n            # Reposition to reference space\n            repositioned = _position_in_reference(\n                current_image, reference_image, fill_value, transpose_axes\n            )\n\n            # Validate geometry after repositioning\n            _validate_geometry(\n                repositioned,\n                reference_image,\n                f\"repositioned image '{path}'\",\n                \"reference image\",\n            )\n\n            current_array = repositioned.array\n\n            # Apply relabeling: replace all non-zero values with mask index + 1\n            if relabel_masks:\n                label_value = i + 1  # 1-indexed labels\n                current_array = np.where(\n                    current_array != fill_value, label_value, fill_value\n                )\n\n            # Merge with conflict resolution\n            if i == 0:\n                # First image: just copy non-fill values\n                non_fill_mask = current_array != fill_value\n                merged_array[non_fill_mask] = current_array[non_fill_mask]\n            else:\n                # Subsequent images: apply conflict resolution\n                # Overlap: non-fill in both\n                overlap_mask = (merged_array != fill_value) &amp; (\n                    current_array != fill_value\n                )\n                # New data: fill in merged, non-fill in current\n                new_data_mask = (merged_array == fill_value) &amp; (\n                    current_array != fill_value\n                )\n\n                # Apply new data\n                merged_array[new_data_mask] = current_array[new_data_mask]\n\n                # Resolve conflicts\n                if np.any(overlap_mask):\n                    if conflict_resolution == \"max\":\n                        merged_array[overlap_mask] = np.maximum(\n                            merged_array[overlap_mask], current_array[overlap_mask]\n                        )\n                    elif conflict_resolution == \"min\":\n                        merged_array[overlap_mask] = np.minimum(\n                            merged_array[overlap_mask], current_array[overlap_mask]\n                        )\n                    elif conflict_resolution == \"last\":\n                        merged_array[overlap_mask] = current_array[overlap_mask]\n                    elif conflict_resolution == \"first\":\n                        pass  # Keep existing values\n\n        # Use reference geometry for output\n        consensus_spacing = reference_image.spacing\n        consensus_origin = reference_image.origin\n        consensus_direction = reference_image.direction\n\n    else:\n        # Mode: Standard merging with strict geometry validation\n        # Load the first image to serve as the consensus geometry\n        try:\n            consensus_image = load_image(\n                image_paths[0],\n                dataset_index=dataset_index,\n                recursive=recursive,\n                apply_rescale=apply_rescale,\n            )\n        except Exception as e:\n            raise ValueError(\n                f\"Failed to load first image '{image_paths[0]}': {e}\"\n            ) from e\n\n        merged_array = consensus_image.array.copy()\n\n        # Apply relabeling for the first image\n        if relabel_masks:\n            merged_array = np.where(merged_array != 0, 1, 0).astype(merged_array.dtype)\n\n        # Iterate through remaining images\n        for idx, path in enumerate(image_paths[1:], start=2):\n            try:\n                current_image = load_image(\n                    path,\n                    dataset_index=dataset_index,\n                    recursive=recursive,\n                    apply_rescale=apply_rescale,\n                )\n            except Exception as e:\n                raise ValueError(f\"Failed to load image '{path}': {e}\") from e\n\n            _validate_geometry(\n                current_image, consensus_image, f\"image '{path}'\", \"consensus image\"\n            )\n\n            current_array = current_image.array\n\n            # Apply relabeling: replace all non-zero values with mask index\n            if relabel_masks:\n                label_value = idx  # idx starts at 2 for second file\n                current_array = np.where(current_array != 0, label_value, 0).astype(\n                    current_array.dtype\n                )\n\n            # Identify regions\n            overlap_mask = (merged_array != 0) &amp; (current_array != 0)\n            new_data_mask = (merged_array == 0) &amp; (current_array != 0)\n\n            # Apply new data\n            merged_array[new_data_mask] = current_array[new_data_mask]\n\n            # Resolve conflicts\n            if np.any(overlap_mask):\n                if conflict_resolution == \"max\":\n                    merged_array[overlap_mask] = np.maximum(\n                        merged_array[overlap_mask], current_array[overlap_mask]\n                    )\n                elif conflict_resolution == \"min\":\n                    merged_array[overlap_mask] = np.minimum(\n                        merged_array[overlap_mask], current_array[overlap_mask]\n                    )\n                elif conflict_resolution == \"last\":\n                    merged_array[overlap_mask] = current_array[overlap_mask]\n                elif conflict_resolution == \"first\":\n                    pass  # Already have the 'first' value\n\n        consensus_spacing = consensus_image.spacing\n        consensus_origin = consensus_image.origin\n        consensus_direction = consensus_image.direction\n\n        # Validate against reference image if provided (for non-reposition mode)\n        if reference_image is not None:\n            final_merged_image = Image(\n                array=merged_array,\n                spacing=consensus_spacing,\n                origin=consensus_origin,\n                direction=consensus_direction,\n                modality=\"Image\",\n            )\n            _validate_geometry(\n                final_merged_image, reference_image, \"merged image\", \"reference image\"\n            )\n\n    # Apply binarization if requested\n    if binarize is not None:\n        mask_out: np.ndarray = np.zeros_like(merged_array, dtype=np.uint8)\n        if isinstance(binarize, bool) and binarize is True:\n            mask_out[merged_array &gt; 0] = 1\n        elif isinstance(binarize, int) and not isinstance(binarize, bool):\n            mask_out[merged_array == binarize] = 1\n        elif isinstance(binarize, list):\n            mask_out[np.isin(merged_array, binarize)] = 1\n        elif isinstance(binarize, tuple) and len(binarize) == 2:\n            mask_out[(merged_array &gt;= binarize[0]) &amp; (merged_array &lt;= binarize[1])] = 1\n        else:\n            if binarize is not False:\n                raise ValueError(f\"Unsupported binarize value: {binarize}\")\n            mask_out = merged_array\n\n        if binarize is not False:\n            merged_array = mask_out\n\n    return Image(\n        array=merged_array,\n        spacing=consensus_spacing,\n        origin=consensus_origin,\n        direction=consensus_direction,\n        modality=\"MergedImage\",\n    )\n</code></pre>"},{"location":"api/loader/#pictologics.loader.create_full_mask","title":"<code>create_full_mask(reference_image, dtype=np.uint8)</code>","text":"<p>Create a whole-image ROI mask matching a reference image.</p> <p>This utility is primarily used when a user does not provide a segmentation mask. The returned mask has the same geometry (shape, spacing, origin, direction) as the reference image and contains a value of 1 for every voxel.</p> <p>Parameters:</p> Name Type Description Default <code>reference_image</code> <code>Image</code> <p>Image whose geometry should be copied.</p> required <code>dtype</code> <code>DTypeLike</code> <p>Numpy dtype to use for the mask array. Defaults to <code>np.uint8</code>.</p> <code>uint8</code> <p>Returns:</p> Type Description <code>Image</code> <p>An <code>Image</code> mask with <code>array == 1</code> everywhere.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the reference image does not have a valid 3D array.</p> Source code in <code>pictologics/loader.py</code> <pre><code>def create_full_mask(reference_image: Image, dtype: DTypeLike = np.uint8) -&gt; Image:\n    \"\"\"Create a whole-image ROI mask matching a reference image.\n\n    This utility is primarily used when a user does not provide a segmentation mask.\n    The returned mask has the same geometry (shape, spacing, origin, direction) as\n    the reference image and contains a value of 1 for every voxel.\n\n    Args:\n        reference_image: Image whose geometry should be copied.\n        dtype: Numpy dtype to use for the mask array. Defaults to `np.uint8`.\n\n    Returns:\n        An `Image` mask with `array == 1` everywhere.\n\n    Raises:\n        ValueError: If the reference image does not have a valid 3D array.\n    \"\"\"\n    if reference_image.array.ndim != 3:\n        raise ValueError(\n            f\"reference_image.array must be 3D, got shape {reference_image.array.shape}\"\n        )\n\n    mask_array = np.ones(reference_image.array.shape, dtype=dtype)\n    return Image(\n        array=mask_array,\n        spacing=reference_image.spacing,\n        origin=reference_image.origin,\n        direction=reference_image.direction,\n        modality=\"mask\",\n    )\n</code></pre>"},{"location":"api/loader/#pictologics.loaders.seg_loader","title":"<code>pictologics.loaders.seg_loader</code>","text":""},{"location":"api/loader/#pictologics.loaders.seg_loader--dicom-segmentation-seg-loader","title":"DICOM Segmentation (SEG) Loader","text":"<p>This module provides functionality for loading DICOM Segmentation objects as pictologics Image instances. SEG files are specialized DICOM objects that store segmentation masks with multi-segment support.</p> <p>Uses highdicom for robust SEG parsing and extraction.</p>"},{"location":"api/loader/#pictologics.loaders.seg_loader.load_seg","title":"<code>load_seg(path, segment_numbers=None, combine_segments=True, reference_image=None)</code>","text":"<p>Load a DICOM SEG file as a mask Image.</p> <p>This function loads a DICOM Segmentation object and converts it to the standard pictologics Image format. The resulting Image has the same structure as images returned by load_image():</p> <ul> <li>array: np.ndarray with shape (X, Y, Z)</li> <li>spacing: tuple[float, float, float] in mm</li> <li>origin: tuple[float, float, float] in mm</li> <li>direction: Optional[np.ndarray] - 3x3 direction cosines</li> <li>modality: str - set to \"SEG\"</li> </ul> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the DICOM SEG file.</p> required <code>segment_numbers</code> <code>list[int] | None</code> <p>Specific segment numbers to extract. If None, all segments are extracted. Segment numbers are 1-indexed as per DICOM convention.</p> <code>None</code> <code>combine_segments</code> <code>bool</code> <p>Controls how segments are returned:</p> <ul> <li> <p>True (default): Returns a single Image where each segment   is encoded as its segment number (1, 2, 3...) in the voxel values.   Background voxels are 0. This is useful when you want a single   label map for visualization or when segments are mutually exclusive   (e.g., organ segmentation where each voxel belongs to one structure).</p> </li> <li> <p>False: Returns a dict mapping segment numbers to individual   binary Image masks. Each mask contains only 0s and 1s. This is   useful when:</p> </li> <li> <p>Segments may overlap (e.g., nested structures like tumor     within organ)</p> </li> <li>You need to process each segment independently (e.g., extract     radiomics from each segment separately)</li> <li>You want to select specific segments for different analyses</li> </ul> <code>True</code> <code>reference_image</code> <code>'Image | None'</code> <p>Optional reference Image for geometry alignment. When provided, the output mask will be resampled/repositioned to match the reference geometry.</p> <code>None</code> <p>Returns:</p> Type Description <code>'Image | dict[int, Image]'</code> <p>If combine_segments is True: A single Image with segment labels.</p> <code>'Image | dict[int, Image]'</code> <p>If combine_segments is False: A dict of {segment_number: Image}.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the file is not a valid DICOM SEG object.</p> <code>FileNotFoundError</code> <p>If the file does not exist.</p> <p>Examples:</p> <p>Load a SEG file with all segments combined (label map):</p> <pre><code>&gt;&gt;&gt; mask = load_seg(\"segmentation.dcm\")\n&gt;&gt;&gt; print(mask.array.shape)  # (X, Y, Z)\n&gt;&gt;&gt; print(np.unique(mask.array))  # [0, 1, 2, ...]\n</code></pre> <p>Load specific segments as separate binary masks:</p> <pre><code>&gt;&gt;&gt; masks = load_seg(\"segmentation.dcm\", segment_numbers=[1, 2],\n...                  combine_segments=False)\n&gt;&gt;&gt; for seg_num, mask in masks.items():\n...     print(f\"Segment {seg_num}: {mask.array.sum()} voxels\")\n</code></pre> <p>Extract radiomics from each coronary territory separately:</p> <pre><code>&gt;&gt;&gt; masks = load_seg(\"cardiac_seg.dcm\", combine_segments=False)\n&gt;&gt;&gt; for seg_num, mask in masks.items():\n...     features = pipeline.run(image=ct, mask=mask)\n</code></pre> <p>Align mask to a reference CT image:</p> <pre><code>&gt;&gt;&gt; ct = load_image(\"ct_scan/\")\n&gt;&gt;&gt; mask = load_seg(\"segmentation.dcm\", reference_image=ct)\n&gt;&gt;&gt; assert mask.array.shape == ct.array.shape\n</code></pre> Source code in <code>pictologics/loaders/seg_loader.py</code> <pre><code>def load_seg(\n    path: str | Path,\n    segment_numbers: list[int] | None = None,\n    combine_segments: bool = True,\n    reference_image: \"Image | None\" = None,\n) -&gt; \"Image | dict[int, Image]\":\n    \"\"\"Load a DICOM SEG file as a mask Image.\n\n    This function loads a DICOM Segmentation object and converts it to\n    the standard pictologics Image format. The resulting Image has the\n    same structure as images returned by load_image():\n\n    - array: np.ndarray with shape (X, Y, Z)\n    - spacing: tuple[float, float, float] in mm\n    - origin: tuple[float, float, float] in mm\n    - direction: Optional[np.ndarray] - 3x3 direction cosines\n    - modality: str - set to \"SEG\"\n\n    Args:\n        path: Path to the DICOM SEG file.\n        segment_numbers: Specific segment numbers to extract. If None, all\n            segments are extracted. Segment numbers are 1-indexed as per\n            DICOM convention.\n        combine_segments: Controls how segments are returned:\n\n            - **True (default)**: Returns a single Image where each segment\n              is encoded as its segment number (1, 2, 3...) in the voxel values.\n              Background voxels are 0. This is useful when you want a single\n              label map for visualization or when segments are mutually exclusive\n              (e.g., organ segmentation where each voxel belongs to one structure).\n\n            - **False**: Returns a dict mapping segment numbers to individual\n              binary Image masks. Each mask contains only 0s and 1s. This is\n              useful when:\n\n              - Segments may overlap (e.g., nested structures like tumor\n                within organ)\n              - You need to process each segment independently (e.g., extract\n                radiomics from each segment separately)\n              - You want to select specific segments for different analyses\n\n        reference_image: Optional reference Image for geometry alignment.\n            When provided, the output mask will be resampled/repositioned\n            to match the reference geometry.\n\n    Returns:\n        If combine_segments is True: A single Image with segment labels.\n        If combine_segments is False: A dict of {segment_number: Image}.\n\n    Raises:\n        ValueError: If the file is not a valid DICOM SEG object.\n        FileNotFoundError: If the file does not exist.\n\n    Examples:\n        Load a SEG file with all segments combined (label map):\n\n        &gt;&gt;&gt; mask = load_seg(\"segmentation.dcm\")\n        &gt;&gt;&gt; print(mask.array.shape)  # (X, Y, Z)\n        &gt;&gt;&gt; print(np.unique(mask.array))  # [0, 1, 2, ...]\n\n        Load specific segments as separate binary masks:\n\n        &gt;&gt;&gt; masks = load_seg(\"segmentation.dcm\", segment_numbers=[1, 2],\n        ...                  combine_segments=False)\n        &gt;&gt;&gt; for seg_num, mask in masks.items():\n        ...     print(f\"Segment {seg_num}: {mask.array.sum()} voxels\")\n\n        Extract radiomics from each coronary territory separately:\n\n        &gt;&gt;&gt; masks = load_seg(\"cardiac_seg.dcm\", combine_segments=False)\n        &gt;&gt;&gt; for seg_num, mask in masks.items():\n        ...     features = pipeline.run(image=ct, mask=mask)\n\n        Align mask to a reference CT image:\n\n        &gt;&gt;&gt; ct = load_image(\"ct_scan/\")\n        &gt;&gt;&gt; mask = load_seg(\"segmentation.dcm\", reference_image=ct)\n        &gt;&gt;&gt; assert mask.array.shape == ct.array.shape\n    \"\"\"\n    import highdicom as hd\n\n    from pictologics.loader import Image\n\n    path_obj = Path(path)\n    if not path_obj.exists():\n        raise FileNotFoundError(f\"SEG file not found: {path}\")\n\n    # Load the DICOM SEG using highdicom\n    try:\n        seg = hd.seg.segread(str(path_obj))\n    except Exception as e:\n        raise ValueError(f\"Failed to load DICOM SEG file: {e}\") from e\n\n    # Verify it's a SEG object\n    if not hasattr(seg, \"SegmentSequence\"):\n        raise ValueError(f\"File is not a valid DICOM SEG object: {path}\")\n\n    # Get available segment numbers\n    available_segments = [s.SegmentNumber for s in seg.SegmentSequence]\n\n    # Determine which segments to extract\n    if segment_numbers is None:\n        target_segments = available_segments\n    else:\n        # Validate requested segments exist\n        for seg_num in segment_numbers:\n            if seg_num not in available_segments:\n                raise ValueError(\n                    f\"Segment {seg_num} not found. \"\n                    f\"Available segments: {available_segments}\"\n                )\n        target_segments = segment_numbers\n\n    # Extract geometry information from the SEG\n    spacing, origin, direction = _extract_seg_geometry(seg)\n\n    # Extract pixel array - shape is typically (frames, rows, cols)\n    pixel_array = seg.pixel_array\n\n    # Get the number of segments and frames\n    n_frames = pixel_array.shape[0] if pixel_array.ndim == 3 else 1\n\n    if combine_segments:\n        # Create combined label image\n        combined_array = _extract_combined_segments(\n            seg, pixel_array, target_segments, n_frames\n        )\n\n        # Reorder axes from (Z, Y, X) or (frames, rows, cols) to (X, Y, Z)\n        combined_array = np.transpose(combined_array, (2, 1, 0))\n\n        result = Image(\n            array=combined_array,\n            spacing=spacing,\n            origin=origin,\n            direction=direction,\n            modality=\"SEG\",\n        )\n\n        # Align to reference if provided\n        if reference_image is not None:\n            result = _align_to_reference(result, reference_image)\n\n        return result\n    else:\n        # Return dict of individual segment masks\n        result_dict: dict[int, Image] = {}\n\n        for seg_num in target_segments:\n            mask_array = _extract_single_segment(seg, pixel_array, seg_num, n_frames)\n\n            # Reorder axes from (Z, Y, X) to (X, Y, Z)\n            mask_array = np.transpose(mask_array, (2, 1, 0))\n\n            mask_image = Image(\n                array=mask_array.astype(np.uint8),\n                spacing=spacing,\n                origin=origin,\n                direction=direction,\n                modality=\"SEG\",\n            )\n\n            # Align to reference if provided\n            if reference_image is not None:\n                mask_image = _align_to_reference(mask_image, reference_image)\n\n            result_dict[seg_num] = mask_image\n\n        return result_dict\n</code></pre>"},{"location":"api/loader/#pictologics.loaders.seg_loader.get_segment_info","title":"<code>get_segment_info(path)</code>","text":"<p>Get information about segments in a DICOM SEG file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the DICOM SEG file.</p> required <p>Returns:</p> Type Description <code>list[dict[str, str | int]]</code> <p>List of dicts with segment information:</p> <code>list[dict[str, str | int]]</code> <ul> <li>segment_number: int</li> </ul> <code>list[dict[str, str | int]]</code> <ul> <li>segment_label: str</li> </ul> <code>list[dict[str, str | int]]</code> <ul> <li>segment_description: str (if available)</li> </ul> <code>list[dict[str, str | int]]</code> <ul> <li>algorithm_type: str (if available)</li> </ul> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the file is not a valid DICOM SEG object.</p> Source code in <code>pictologics/loaders/seg_loader.py</code> <pre><code>def get_segment_info(path: str | Path) -&gt; list[dict[str, str | int]]:\n    \"\"\"Get information about segments in a DICOM SEG file.\n\n    Args:\n        path: Path to the DICOM SEG file.\n\n    Returns:\n        List of dicts with segment information:\n        - segment_number: int\n        - segment_label: str\n        - segment_description: str (if available)\n        - algorithm_type: str (if available)\n\n    Raises:\n        ValueError: If the file is not a valid DICOM SEG object.\n    \"\"\"\n    import highdicom as hd\n\n    path_obj = Path(path)\n    if not path_obj.exists():\n        raise FileNotFoundError(f\"SEG file not found: {path}\")\n\n    try:\n        seg = hd.seg.segread(str(path_obj))\n    except Exception as e:\n        raise ValueError(f\"Failed to load DICOM SEG file: {e}\") from e\n\n    if not hasattr(seg, \"SegmentSequence\"):\n        raise ValueError(f\"File is not a valid DICOM SEG object: {path}\")\n\n    segments = []\n    for segment in seg.SegmentSequence:\n        info: dict[str, str | int] = {\n            \"segment_number\": segment.SegmentNumber,\n            \"segment_label\": getattr(segment, \"SegmentLabel\", \"\"),\n        }\n\n        if hasattr(segment, \"SegmentDescription\"):\n            info[\"segment_description\"] = segment.SegmentDescription\n\n        if hasattr(segment, \"SegmentAlgorithmType\"):\n            info[\"algorithm_type\"] = segment.SegmentAlgorithmType\n\n        segments.append(info)\n\n    return segments\n</code></pre>"},{"location":"api/pipeline/","title":"Pipeline API","text":""},{"location":"api/pipeline/#pictologics.pipeline","title":"<code>pictologics.pipeline</code>","text":""},{"location":"api/pipeline/#pictologics.pipeline--radiomics-pipeline-module","title":"Radiomics Pipeline Module","text":"<p>This module provides a flexible, configurable pipeline for executing radiomic feature extraction workflows. It allows users to define sequences of preprocessing steps and feature extraction tasks.</p>"},{"location":"api/pipeline/#pictologics.pipeline--key-features","title":"Key Features:","text":"<ul> <li>Configurable Workflows: Define steps like resampling, resegmentation, filtering,   discretisation, and feature extraction in a declarative manner.</li> <li>State Management: Tracks the state of the image and masks (morphological and intensity)   throughout the pipeline.</li> <li>Logging: Records execution details, parameters, and errors for reproducibility.</li> <li>Batch Processing: Can process multiple configurations on the same input data.</li> </ul>"},{"location":"api/pipeline/#pictologics.pipeline.EmptyROIMaskError","title":"<code>EmptyROIMaskError</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>Raised when preprocessing yields an empty ROI mask.</p> Source code in <code>pictologics/pipeline.py</code> <pre><code>class EmptyROIMaskError(ValueError):\n    \"\"\"Raised when preprocessing yields an empty ROI mask.\"\"\"\n</code></pre>"},{"location":"api/pipeline/#pictologics.pipeline.PipelineState","title":"<code>PipelineState</code>  <code>dataclass</code>","text":"<p>Holds the current state of the image and masks during pipeline execution.</p> Source code in <code>pictologics/pipeline.py</code> <pre><code>@dataclass\nclass PipelineState:\n    \"\"\"\n    Holds the current state of the image and masks during pipeline execution.\n    \"\"\"\n\n    image: Image  # May be discretised after discretise step\n    raw_image: Image  # Always the non-discretised image (for intensity/morphology)\n    morph_mask: Image\n    intensity_mask: Image\n    is_discretised: bool = False\n    n_bins: Optional[int] = None\n    bin_width: Optional[float] = None\n    discretisation_method: Optional[str] = None\n    discretisation_min: Optional[float] = None\n    discretisation_max: Optional[float] = None\n    mask_was_generated: bool = False\n</code></pre>"},{"location":"api/pipeline/#pictologics.pipeline.RadiomicsPipeline","title":"<code>RadiomicsPipeline</code>","text":"<p>A flexible, configurable pipeline for radiomic feature extraction. Allows defining multiple processing configurations (sequences of steps) to be run on data.</p> Source code in <code>pictologics/pipeline.py</code> <pre><code>class RadiomicsPipeline:\n    \"\"\"\n    A flexible, configurable pipeline for radiomic feature extraction.\n    Allows defining multiple processing configurations (sequences of steps) to be run on data.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self._configs: dict[str, list[dict[str, Any]]] = {}\n        self._log: list[dict[str, Any]] = []\n        self._load_predefined_configs()\n\n    def _load_predefined_configs(self) -&gt; None:\n        \"\"\"\n        Load predefined, commonly used pipeline configurations.\n        \"\"\"\n        # Common resampling parameters\n        resample_05mm = {\n            \"step\": \"resample\",\n            \"params\": {\"new_spacing\": (0.5, 0.5, 0.5), \"interpolation\": \"linear\"},\n        }\n\n        # Common feature extraction parameters (all families)\n        extract_all = {\n            \"step\": \"extract_features\",\n            \"params\": {\n                \"families\": [\"intensity\", \"morphology\", \"texture\", \"histogram\", \"ivh\"],\n                # Performance-friendly defaults: spatial/local intensity extras can be\n                # extremely slow on larger ROIs. Users can enable explicitly in custom configs.\n                \"include_spatial_intensity\": False,\n                \"include_local_intensity\": False,\n            },\n        }\n\n        # --- FBN Configurations ---\n\n        # Steps1: 0.5mm, FBN 8\n        self.add_config(\n            \"standard_fbn_8\",\n            [\n                resample_05mm,\n                {\"step\": \"discretise\", \"params\": {\"method\": \"FBN\", \"n_bins\": 8}},\n                extract_all,\n            ],\n        )\n\n        # Steps2: 0.5mm, FBN 16\n        self.add_config(\n            \"standard_fbn_16\",\n            [\n                resample_05mm,\n                {\"step\": \"discretise\", \"params\": {\"method\": \"FBN\", \"n_bins\": 16}},\n                extract_all,\n            ],\n        )\n\n        # Steps3: 0.5mm, FBN 32\n        self.add_config(\n            \"standard_fbn_32\",\n            [\n                resample_05mm,\n                {\"step\": \"discretise\", \"params\": {\"method\": \"FBN\", \"n_bins\": 32}},\n                extract_all,\n            ],\n        )\n\n        # --- FBS Configurations ---\n\n        # Steps4: 0.5mm, FBS 8.0\n        self.add_config(\n            \"standard_fbs_8\",\n            [\n                resample_05mm,\n                {\"step\": \"discretise\", \"params\": {\"method\": \"FBS\", \"bin_width\": 8.0}},\n                extract_all,\n            ],\n        )\n\n        # Steps5: 0.5mm, FBS 16.0\n        self.add_config(\n            \"standard_fbs_16\",\n            [\n                resample_05mm,\n                {\"step\": \"discretise\", \"params\": {\"method\": \"FBS\", \"bin_width\": 16.0}},\n                extract_all,\n            ],\n        )\n\n        # Steps6: 0.5mm, FBS 32.0\n        self.add_config(\n            \"standard_fbs_32\",\n            [\n                resample_05mm,\n                {\"step\": \"discretise\", \"params\": {\"method\": \"FBS\", \"bin_width\": 32.0}},\n                extract_all,\n            ],\n        )\n\n    def get_all_standard_config_names(self) -&gt; list[str]:\n        \"\"\"\n        Returns the list of all standard configuration names.\n        \"\"\"\n        return [\n            \"standard_fbn_8\",\n            \"standard_fbn_16\",\n            \"standard_fbn_32\",\n            \"standard_fbs_8\",\n            \"standard_fbs_16\",\n            \"standard_fbs_32\",\n        ]\n\n    def add_config(self, name: str, steps: list[dict[str, Any]]) -&gt; \"RadiomicsPipeline\":\n        \"\"\"\n        Add a processing configuration.\n\n        Args:\n            name: Unique name for this configuration.\n            steps: List of steps. Each step is a dict with 'step' (name) and 'params' (dict).\n                   Supported steps:\n                   - 'resample': params: new_spacing (required), interpolation (optional)\n                   - 'resegment': params: range_min, range_max\n                   - 'filter_outliers': params: sigma\n                   - 'keep_largest_component': params: None\n                   - 'round_intensities': params: None\n                   - 'discretise': params: method, n_bins/bin_width, etc.\n                   - 'extract_features': params: families (list), etc.\n                     Note: Texture features require a prior 'discretise' step.\n                     IVH features are configured via 'ivh_params' dict.\n        \"\"\"\n        if not isinstance(steps, list):\n            raise ValueError(\"Configuration must be a list of steps\")\n\n        for step in steps:\n            if not isinstance(step, dict):\n                raise ValueError(\"Each step must be a dictionary\")\n            if \"step\" not in step:\n                raise ValueError(\"Each step must have a 'step' key\")\n\n        self._configs[name] = steps\n        return self\n\n    def run(\n        self,\n        image: str | Image,\n        mask: str | Image | None = None,\n        subject_id: Optional[str] = None,\n        config_names: Optional[list[str]] = None,\n    ) -&gt; dict[str, pd.Series]:\n        \"\"\"\n        Run configurations on the provided image and mask.\n\n        Args:\n            image: Path to image or Image object.\n            mask: Optional path to mask or Image object.\n                If omitted (or passed as `None` / empty string), the pipeline will\n                treat the **entire image** as the ROI by generating a full (all-ones)\n                mask matching the input image geometry.\n            subject_id: Optional identifier for the subject.\n            config_names: List of specific configuration names to run.\n                          If None, runs all registered configurations.\n                          Supports \"all_standard\" to run all 6 standard configs.\n\n        Returns:\n            Dictionary mapping config names to pandas Series of features.\n        \"\"\"\n        # 1. Load Data\n        if isinstance(image, str):\n            orig_img = load_image(image)\n            img_source = image\n        else:\n            orig_img = image\n            img_source = \"InMemory\"\n\n        mask_was_generated = False\n        if mask is None or (isinstance(mask, str) and mask.strip() == \"\"):\n            orig_mask = create_full_mask(orig_img)\n            mask_source = \"GeneratedFullMask\"\n            mask_was_generated = True\n        elif isinstance(mask, str):\n            orig_mask = load_image(mask)\n            mask_source = mask\n        else:\n            orig_mask = mask\n            mask_source = \"InMemory\"\n\n        all_results = {}\n\n        # Determine which configs to run\n        if config_names is None:\n            target_configs = list(self._configs.keys())\n        else:\n            target_configs = []\n            for name in config_names:\n                if name == \"all_standard\":\n                    target_configs.extend(self.get_all_standard_config_names())\n                elif name in self._configs:\n                    target_configs.append(name)\n                else:\n                    raise ValueError(f\"Configuration '{name}' not found.\")\n\n        # Run each configuration\n        for config_name in target_configs:\n            steps = self._configs[config_name]\n\n            # Initialize State\n            # We start with fresh copies for each config\n            state = PipelineState(\n                image=orig_img,\n                raw_image=orig_img,  # Track non-discretised image\n                morph_mask=orig_mask,\n                intensity_mask=Image(\n                    array=orig_mask.array.copy(),\n                    spacing=orig_mask.spacing,\n                    origin=orig_mask.origin,\n                    direction=orig_mask.direction,\n                    modality=orig_mask.modality,\n                ),\n                mask_was_generated=mask_was_generated,\n            )\n\n            self._ensure_nonempty_roi(state, context=\"initialization\")\n\n            config_log: dict[str, Any] = {\n                \"timestamp\": datetime.datetime.now().isoformat(),\n                \"subject_id\": subject_id,\n                \"config_name\": config_name,\n                \"image_source\": img_source,\n                \"mask_source\": mask_source,\n                \"steps_executed\": [],\n            }\n\n            config_features = {}\n\n            try:\n                for step_def in steps:\n                    step_name = step_def[\"step\"]\n                    params = step_def.get(\"params\", {})\n\n                    # Execute Step\n                    if step_name == \"extract_features\":\n                        features = self._extract_features(state, params)\n                        config_features.update(features)\n                    else:\n                        self._execute_preprocessing_step(state, step_name, params)\n\n                    # Log\n                    config_log[\"steps_executed\"].append(\n                        {\"step\": step_name, \"params\": params, \"status\": \"completed\"}\n                    )\n\n            except Exception as e:\n                config_log[\"error\"] = str(e)\n                config_log[\"failed_step\"] = step_def\n                print(f\"Error in config '{config_name}', step '{step_def}': {e}\")\n\n                # For empty ROI, fail fast (do not silently return empty/partial features).\n                if isinstance(e, EmptyROIMaskError):\n                    self._log.append(config_log)\n                    raise\n\n            self._log.append(config_log)\n\n            # Create Series\n            series = pd.Series(config_features)\n            if subject_id:\n                series[\"subject_id\"] = subject_id\n            all_results[config_name] = series\n\n        return all_results\n\n    def clear_log(self) -&gt; None:\n        \"\"\"Clear the in-memory processing log.\"\"\"\n        self._log.clear()\n\n    def _ensure_nonempty_roi(self, state: PipelineState, context: str) -&gt; None:\n        \"\"\"Raise a clear error if the ROI is empty.\n\n        The pipeline uses `mask_values=1` semantics throughout (see `apply_mask`).\n        \"\"\"\n        has_intensity_roi = bool(np.any(state.intensity_mask.array == 1))\n        has_morph_roi = bool(np.any(state.morph_mask.array == 1))\n\n        if not has_intensity_roi or not has_morph_roi:\n            raise EmptyROIMaskError(\n                \"ROI is empty after preprocessing \"\n                f\"({context}). Ensure your mask contains at least one voxel with value 1, \"\n                \"or relax resegmentation/outlier filtering thresholds.\"\n            )\n\n    def _execute_preprocessing_step(\n        self, state: PipelineState, step_name: str, params: dict[str, Any]\n    ) -&gt; None:\n        \"\"\"\n        Execute a single preprocessing step and update the state in-place.\n        \"\"\"\n        if step_name == \"resample\":\n            # Params\n            if \"new_spacing\" not in params:\n                raise ValueError(\"Resample step requires 'new_spacing' parameter.\")\n\n            spacing = params[\"new_spacing\"]\n            interp_img = params.get(\"interpolation\", \"linear\")\n            interp_mask = params.get(\"mask_interpolation\", \"nearest\")\n            mask_thresh = params.get(\"mask_threshold\", 0.5)\n            round_intensities_flag = params.get(\"round_intensities\", False)\n\n            # Update Image and raw_image\n            state.image = resample_image(\n                state.image,\n                spacing,\n                interpolation=interp_img,\n                round_intensities=round_intensities_flag,\n            )\n            state.raw_image = (\n                state.image\n            )  # Keep raw_image in sync before discretisation\n\n            # Update Masks\n            thresh_arg = mask_thresh if interp_mask != \"nearest\" else None\n            state.morph_mask = resample_image(\n                state.morph_mask,\n                spacing,\n                interpolation=interp_mask,\n                mask_threshold=thresh_arg,\n            )\n            state.intensity_mask = resample_image(\n                state.intensity_mask,\n                spacing,\n                interpolation=interp_mask,\n                mask_threshold=thresh_arg,\n            )\n\n            self._ensure_nonempty_roi(state, context=\"resample\")\n\n        elif step_name == \"resegment\":\n            range_min = params.get(\"range_min\")\n            range_max = params.get(\"range_max\")\n            state.intensity_mask = resegment_mask(\n                state.image, state.intensity_mask, range_min, range_max\n            )\n\n            # If the mask was auto-generated (mask omitted), treat resegmentation as ROI definition\n            # for both intensity and morphology features.\n            if state.mask_was_generated:\n                state.morph_mask = resegment_mask(\n                    state.image, state.morph_mask, range_min, range_max\n                )\n\n            self._ensure_nonempty_roi(state, context=\"resegment\")\n\n        elif step_name == \"filter_outliers\":\n            sigma = params.get(\"sigma\", 3.0)\n            state.intensity_mask = filter_outliers(\n                state.image, state.intensity_mask, sigma\n            )\n\n            if state.mask_was_generated:\n                state.morph_mask = filter_outliers(state.image, state.morph_mask, sigma)\n\n            self._ensure_nonempty_roi(state, context=\"filter_outliers\")\n\n        elif step_name == \"round_intensities\":\n            state.image = round_intensities(state.image)\n            state.raw_image = (\n                state.image\n            )  # Keep raw_image in sync before discretisation\n\n        elif step_name == \"keep_largest_component\":\n            # apply_to: \"morph\", \"intensity\", or \"both\" (default)\n            apply_to = params.get(\"apply_to\", \"both\")\n            if apply_to in (\"morph\", \"both\"):\n                state.morph_mask = keep_largest_component(state.morph_mask)\n            if apply_to in (\"intensity\", \"both\"):\n                state.intensity_mask = keep_largest_component(state.intensity_mask)\n\n            self._ensure_nonempty_roi(state, context=\"keep_largest_component\")\n\n        elif step_name == \"discretise\":\n            self._ensure_nonempty_roi(state, context=\"discretise\")\n            method = params.get(\"method\", \"FBN\")\n\n            # Avoid passing 'method' twice\n            disc_params = params.copy()\n            if \"method\" in disc_params:\n                del disc_params[\"method\"]\n\n            state.image = cast(\n                Image,\n                discretise_image(\n                    state.image,\n                    method=method,\n                    roi_mask=state.intensity_mask,\n                    **disc_params,\n                ),\n            )\n\n            state.is_discretised = True\n            state.discretisation_method = method\n            state.n_bins = params.get(\"n_bins\")\n            state.bin_width = params.get(\"bin_width\")\n\n            # If FBS, n_bins is dynamic. We can estimate it from the result.\n            if method == \"FBS\":\n                masked_vals = apply_mask(state.image, state.intensity_mask)\n                if len(masked_vals) &gt; 0:\n                    state.n_bins = int(np.max(masked_vals))\n                else:\n                    raise EmptyROIMaskError(\n                        \"ROI is empty after preprocessing (discretise). \"\n                        \"Cannot infer FBS bin count from an empty ROI.\"\n                    )\n\n        else:\n            raise ValueError(f\"Unknown preprocessing step: {step_name}\")\n\n    def _extract_features(\n        self, state: PipelineState, params: dict[str, Any]\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Extract features based on current state.\n        \"\"\"\n        results = {}\n        families = params.get(\n            \"families\", [\"intensity\", \"morphology\", \"texture\", \"histogram\", \"ivh\"]\n        )\n\n        # Optional kwargs pass-through (advanced usage)\n        spatial_intensity_params = params.get(\"spatial_intensity_params\", {})\n        local_intensity_params = params.get(\"local_intensity_params\", {})\n        ivh_params = params.get(\"ivh_params\", {})\n        texture_matrix_params = params.get(\"texture_matrix_params\", {})\n\n        if spatial_intensity_params is None:\n            spatial_intensity_params = {}\n        if local_intensity_params is None:\n            local_intensity_params = {}\n        if ivh_params is None:\n            ivh_params = {}\n        if texture_matrix_params is None:\n            texture_matrix_params = {}\n\n        if not isinstance(spatial_intensity_params, dict):\n            raise ValueError(\"spatial_intensity_params must be a dict\")\n        if not isinstance(local_intensity_params, dict):\n            raise ValueError(\"local_intensity_params must be a dict\")\n        if not isinstance(ivh_params, dict):\n            raise ValueError(\"ivh_params must be a dict\")\n        if not isinstance(texture_matrix_params, dict):\n            raise ValueError(\"texture_matrix_params must be a dict\")\n\n        # Morphology - uses raw_image (non-discretised) for intensity-based features\n        if \"morphology\" in families:\n            results.update(\n                calculate_morphology_features(\n                    state.morph_mask,\n                    state.raw_image,\n                    intensity_mask=state.intensity_mask,\n                )\n            )\n\n        # Intensity - uses raw_image (non-discretised)\n        if \"intensity\" in families:\n            masked_values = apply_mask(state.raw_image, state.intensity_mask)\n            results.update(calculate_intensity_features(masked_values))\n\n            include_spatial = bool(params.get(\"include_spatial_intensity\", False))\n            include_local = bool(params.get(\"include_local_intensity\", False))\n\n            if include_spatial:\n                results.update(\n                    calculate_spatial_intensity_features(\n                        state.raw_image,\n                        state.intensity_mask,\n                        **spatial_intensity_params,\n                    )\n                )\n            if include_local:\n                results.update(\n                    calculate_local_intensity_features(\n                        state.raw_image, state.intensity_mask, **local_intensity_params\n                    )\n                )\n\n        # Optional explicit families (no-op unless requested)\n        if \"spatial_intensity\" in families and \"intensity\" not in families:\n            results.update(\n                calculate_spatial_intensity_features(\n                    state.raw_image, state.intensity_mask, **spatial_intensity_params\n                )\n            )\n\n        if \"local_intensity\" in families and \"intensity\" not in families:\n            results.update(\n                calculate_local_intensity_features(\n                    state.raw_image, state.intensity_mask, **local_intensity_params\n                )\n            )\n\n        # Histogram / IVH\n        if \"histogram\" in families:\n            # Usually on discretised image\n            if not state.is_discretised:\n                warnings.warn(\n                    \"Histogram features requested but image is not discretised. \"\n                    \"Features may be unreliable or fail if integer bins are expected.\",\n                    UserWarning,\n                    stacklevel=2,\n                )\n\n            masked_values = apply_mask(state.image, state.intensity_mask)\n            results.update(calculate_intensity_histogram_features(masked_values))\n\n        if \"ivh\" in families:\n            # IVH computation supports three modes:\n            # 1. ivh_use_continuous=True: Use raw (pre-discretised) intensity values\n            # 2. ivh_discretisation={...}: Apply temporary discretisation just for IVH\n            # 3. Default: Use the pipeline's discretised image (if discretised)\n\n            ivh_use_continuous = params.get(\"ivh_use_continuous\", False)\n            ivh_discretisation = params.get(\"ivh_discretisation\", None)\n\n            # Track discretisation params for IVH calculation\n            ivh_disc_bin_width: Optional[float] = None\n            ivh_disc_min_val: Optional[float] = None\n\n            if ivh_use_continuous:\n                # Use raw intensity values (non-discretised)\n                # This is used for continuous IVH (e.g., IBSI Config D)\n                ivh_values = apply_mask(state.raw_image, state.intensity_mask)\n            elif ivh_discretisation:\n                # Apply temporary discretisation for IVH only\n                # This allows different binning for IVH vs texture features\n                # Uses raw_image as the base to discretise from raw values\n                ivh_disc_params = ivh_discretisation.copy()\n                ivh_method = ivh_disc_params.pop(\"method\", \"FBS\")\n                # Save bin_width and min_val for passing to calculate_ivh_features\n                ivh_disc_bin_width = ivh_disc_params.get(\"bin_width\")\n                ivh_disc_min_val = ivh_disc_params.get(\"min_val\")\n                temp_ivh_disc = discretise_image(\n                    state.raw_image,\n                    method=ivh_method,\n                    roi_mask=state.intensity_mask,\n                    **ivh_disc_params,\n                )\n                ivh_values = apply_mask(temp_ivh_disc, state.intensity_mask)\n            else:\n                # Default: use the current image (which may be discretised)\n                ivh_values = apply_mask(state.image, state.intensity_mask)\n\n            # IVH accepts several optional arguments; support both explicit top-level\n            # keys and an \"ivh_params\" dict for full control.\n            ivh_kwargs: dict[str, Any] = {}\n\n            # If ivh_discretisation was used, pass its bin_width and min_val\n            if ivh_disc_bin_width is not None:\n                ivh_kwargs[\"bin_width\"] = ivh_disc_bin_width\n            if ivh_disc_min_val is not None:\n                ivh_kwargs[\"min_val\"] = ivh_disc_min_val\n\n            # Dict-based params (preferred) - these override discretisation defaults\n            if \"bin_width\" in ivh_params:\n                ivh_kwargs[\"bin_width\"] = ivh_params.get(\"bin_width\")\n            if \"min_val\" in ivh_params:\n                ivh_kwargs[\"min_val\"] = ivh_params.get(\"min_val\")\n            if \"max_val\" in ivh_params:\n                ivh_kwargs[\"max_val\"] = ivh_params.get(\"max_val\")\n            if \"target_range_min\" in ivh_params:\n                ivh_kwargs[\"target_range_min\"] = ivh_params.get(\"target_range_min\")\n            if \"target_range_max\" in ivh_params:\n                ivh_kwargs[\"target_range_max\"] = ivh_params.get(\"target_range_max\")\n\n            # If not provided, and we are discretised (and not using continuous mode),\n            # default bin_width to 1.0 (bin indices)\n            if (\n                not ivh_use_continuous\n                and state.is_discretised\n                and ivh_kwargs.get(\"bin_width\") is None\n                and not ivh_discretisation\n            ):\n                ivh_kwargs[\"bin_width\"] = 1.0\n\n            # Only pass non-None arguments\n            ivh_kwargs = {k: v for k, v in ivh_kwargs.items() if v is not None}\n\n            results.update(calculate_ivh_features(ivh_values, **ivh_kwargs))\n\n        # Texture\n        if \"texture\" in families:\n            if not state.is_discretised:\n                raise ValueError(\n                    \"Texture features requested but image is not discretised. \"\n                    \"You must include a 'discretise' step before extracting texture features.\"\n                )\n\n            disc_image = state.image\n            n_bins = state.n_bins if state.n_bins else 32  # Fallback\n\n            # Calculate Matrices\n            # Use morphological mask for distance map (GLDZM)\n            # Advanced: allow overriding matrix computation parameters via texture_matrix_params.\n            matrix_kwargs: dict[str, Any] = {}\n            if \"ngldm_alpha\" in texture_matrix_params:\n                matrix_kwargs[\"ngldm_alpha\"] = texture_matrix_params.get(\"ngldm_alpha\")\n            if \"ngldm_alpha\" not in matrix_kwargs and \"ngldm_alpha\" in params:\n                matrix_kwargs[\"ngldm_alpha\"] = params.get(\"ngldm_alpha\")\n            matrix_kwargs = {k: v for k, v in matrix_kwargs.items() if v is not None}\n\n            texture_matrices = calculate_all_texture_matrices(\n                disc_image.array,\n                state.intensity_mask.array,\n                n_bins,\n                distance_mask=state.morph_mask.array,\n                **matrix_kwargs,\n            )\n\n            results.update(\n                calculate_glcm_features(\n                    disc_image.array,\n                    state.intensity_mask.array,\n                    n_bins,\n                    glcm_matrix=texture_matrices[\"glcm\"],\n                )\n            )\n            results.update(\n                calculate_glrlm_features(\n                    disc_image.array,\n                    state.intensity_mask.array,\n                    n_bins,\n                    glrlm_matrix=texture_matrices[\"glrlm\"],\n                )\n            )\n            results.update(\n                calculate_glszm_features(\n                    disc_image.array,\n                    state.intensity_mask.array,\n                    n_bins,\n                    glszm_matrix=texture_matrices[\"glszm\"],\n                )\n            )\n            results.update(\n                calculate_gldzm_features(\n                    disc_image.array,\n                    state.intensity_mask.array,\n                    n_bins,\n                    gldzm_matrix=texture_matrices[\"gldzm\"],\n                    distance_mask=state.morph_mask.array,\n                )\n            )\n            results.update(\n                calculate_ngtdm_features(\n                    disc_image.array,\n                    state.intensity_mask.array,\n                    n_bins,\n                    ngtdm_matrices=(\n                        texture_matrices[\"ngtdm_s\"],\n                        texture_matrices[\"ngtdm_n\"],\n                    ),\n                )\n            )\n            results.update(\n                calculate_ngldm_features(\n                    disc_image.array,\n                    state.intensity_mask.array,\n                    n_bins,\n                    ngldm_matrix=texture_matrices[\"ngldm\"],\n                )\n            )\n\n        return results\n\n    def save_log(self, output_path: str) -&gt; None:\n        \"\"\"\n        Save the processing log to a JSON file.\n        \"\"\"\n        if not output_path.endswith(\".json\"):\n            output_path += \".json\"\n\n        with open(output_path, \"w\") as f:\n            json.dump(self._log, f, indent=4, default=str)\n</code></pre>"},{"location":"api/pipeline/#pictologics.pipeline.RadiomicsPipeline.add_config","title":"<code>add_config(name, steps)</code>","text":"<p>Add a processing configuration.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Unique name for this configuration.</p> required <code>steps</code> <code>list[dict[str, Any]]</code> <p>List of steps. Each step is a dict with 'step' (name) and 'params' (dict).    Supported steps:    - 'resample': params: new_spacing (required), interpolation (optional)    - 'resegment': params: range_min, range_max    - 'filter_outliers': params: sigma    - 'keep_largest_component': params: None    - 'round_intensities': params: None    - 'discretise': params: method, n_bins/bin_width, etc.    - 'extract_features': params: families (list), etc.      Note: Texture features require a prior 'discretise' step.      IVH features are configured via 'ivh_params' dict.</p> required Source code in <code>pictologics/pipeline.py</code> <pre><code>def add_config(self, name: str, steps: list[dict[str, Any]]) -&gt; \"RadiomicsPipeline\":\n    \"\"\"\n    Add a processing configuration.\n\n    Args:\n        name: Unique name for this configuration.\n        steps: List of steps. Each step is a dict with 'step' (name) and 'params' (dict).\n               Supported steps:\n               - 'resample': params: new_spacing (required), interpolation (optional)\n               - 'resegment': params: range_min, range_max\n               - 'filter_outliers': params: sigma\n               - 'keep_largest_component': params: None\n               - 'round_intensities': params: None\n               - 'discretise': params: method, n_bins/bin_width, etc.\n               - 'extract_features': params: families (list), etc.\n                 Note: Texture features require a prior 'discretise' step.\n                 IVH features are configured via 'ivh_params' dict.\n    \"\"\"\n    if not isinstance(steps, list):\n        raise ValueError(\"Configuration must be a list of steps\")\n\n    for step in steps:\n        if not isinstance(step, dict):\n            raise ValueError(\"Each step must be a dictionary\")\n        if \"step\" not in step:\n            raise ValueError(\"Each step must have a 'step' key\")\n\n    self._configs[name] = steps\n    return self\n</code></pre>"},{"location":"api/pipeline/#pictologics.pipeline.RadiomicsPipeline.clear_log","title":"<code>clear_log()</code>","text":"<p>Clear the in-memory processing log.</p> Source code in <code>pictologics/pipeline.py</code> <pre><code>def clear_log(self) -&gt; None:\n    \"\"\"Clear the in-memory processing log.\"\"\"\n    self._log.clear()\n</code></pre>"},{"location":"api/pipeline/#pictologics.pipeline.RadiomicsPipeline.get_all_standard_config_names","title":"<code>get_all_standard_config_names()</code>","text":"<p>Returns the list of all standard configuration names.</p> Source code in <code>pictologics/pipeline.py</code> <pre><code>def get_all_standard_config_names(self) -&gt; list[str]:\n    \"\"\"\n    Returns the list of all standard configuration names.\n    \"\"\"\n    return [\n        \"standard_fbn_8\",\n        \"standard_fbn_16\",\n        \"standard_fbn_32\",\n        \"standard_fbs_8\",\n        \"standard_fbs_16\",\n        \"standard_fbs_32\",\n    ]\n</code></pre>"},{"location":"api/pipeline/#pictologics.pipeline.RadiomicsPipeline.run","title":"<code>run(image, mask=None, subject_id=None, config_names=None)</code>","text":"<p>Run configurations on the provided image and mask.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>str | Image</code> <p>Path to image or Image object.</p> required <code>mask</code> <code>str | Image | None</code> <p>Optional path to mask or Image object. If omitted (or passed as <code>None</code> / empty string), the pipeline will treat the entire image as the ROI by generating a full (all-ones) mask matching the input image geometry.</p> <code>None</code> <code>subject_id</code> <code>Optional[str]</code> <p>Optional identifier for the subject.</p> <code>None</code> <code>config_names</code> <code>Optional[list[str]]</code> <p>List of specific configuration names to run.           If None, runs all registered configurations.           Supports \"all_standard\" to run all 6 standard configs.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Series]</code> <p>Dictionary mapping config names to pandas Series of features.</p> Source code in <code>pictologics/pipeline.py</code> <pre><code>def run(\n    self,\n    image: str | Image,\n    mask: str | Image | None = None,\n    subject_id: Optional[str] = None,\n    config_names: Optional[list[str]] = None,\n) -&gt; dict[str, pd.Series]:\n    \"\"\"\n    Run configurations on the provided image and mask.\n\n    Args:\n        image: Path to image or Image object.\n        mask: Optional path to mask or Image object.\n            If omitted (or passed as `None` / empty string), the pipeline will\n            treat the **entire image** as the ROI by generating a full (all-ones)\n            mask matching the input image geometry.\n        subject_id: Optional identifier for the subject.\n        config_names: List of specific configuration names to run.\n                      If None, runs all registered configurations.\n                      Supports \"all_standard\" to run all 6 standard configs.\n\n    Returns:\n        Dictionary mapping config names to pandas Series of features.\n    \"\"\"\n    # 1. Load Data\n    if isinstance(image, str):\n        orig_img = load_image(image)\n        img_source = image\n    else:\n        orig_img = image\n        img_source = \"InMemory\"\n\n    mask_was_generated = False\n    if mask is None or (isinstance(mask, str) and mask.strip() == \"\"):\n        orig_mask = create_full_mask(orig_img)\n        mask_source = \"GeneratedFullMask\"\n        mask_was_generated = True\n    elif isinstance(mask, str):\n        orig_mask = load_image(mask)\n        mask_source = mask\n    else:\n        orig_mask = mask\n        mask_source = \"InMemory\"\n\n    all_results = {}\n\n    # Determine which configs to run\n    if config_names is None:\n        target_configs = list(self._configs.keys())\n    else:\n        target_configs = []\n        for name in config_names:\n            if name == \"all_standard\":\n                target_configs.extend(self.get_all_standard_config_names())\n            elif name in self._configs:\n                target_configs.append(name)\n            else:\n                raise ValueError(f\"Configuration '{name}' not found.\")\n\n    # Run each configuration\n    for config_name in target_configs:\n        steps = self._configs[config_name]\n\n        # Initialize State\n        # We start with fresh copies for each config\n        state = PipelineState(\n            image=orig_img,\n            raw_image=orig_img,  # Track non-discretised image\n            morph_mask=orig_mask,\n            intensity_mask=Image(\n                array=orig_mask.array.copy(),\n                spacing=orig_mask.spacing,\n                origin=orig_mask.origin,\n                direction=orig_mask.direction,\n                modality=orig_mask.modality,\n            ),\n            mask_was_generated=mask_was_generated,\n        )\n\n        self._ensure_nonempty_roi(state, context=\"initialization\")\n\n        config_log: dict[str, Any] = {\n            \"timestamp\": datetime.datetime.now().isoformat(),\n            \"subject_id\": subject_id,\n            \"config_name\": config_name,\n            \"image_source\": img_source,\n            \"mask_source\": mask_source,\n            \"steps_executed\": [],\n        }\n\n        config_features = {}\n\n        try:\n            for step_def in steps:\n                step_name = step_def[\"step\"]\n                params = step_def.get(\"params\", {})\n\n                # Execute Step\n                if step_name == \"extract_features\":\n                    features = self._extract_features(state, params)\n                    config_features.update(features)\n                else:\n                    self._execute_preprocessing_step(state, step_name, params)\n\n                # Log\n                config_log[\"steps_executed\"].append(\n                    {\"step\": step_name, \"params\": params, \"status\": \"completed\"}\n                )\n\n        except Exception as e:\n            config_log[\"error\"] = str(e)\n            config_log[\"failed_step\"] = step_def\n            print(f\"Error in config '{config_name}', step '{step_def}': {e}\")\n\n            # For empty ROI, fail fast (do not silently return empty/partial features).\n            if isinstance(e, EmptyROIMaskError):\n                self._log.append(config_log)\n                raise\n\n        self._log.append(config_log)\n\n        # Create Series\n        series = pd.Series(config_features)\n        if subject_id:\n            series[\"subject_id\"] = subject_id\n        all_results[config_name] = series\n\n    return all_results\n</code></pre>"},{"location":"api/pipeline/#pictologics.pipeline.RadiomicsPipeline.save_log","title":"<code>save_log(output_path)</code>","text":"<p>Save the processing log to a JSON file.</p> Source code in <code>pictologics/pipeline.py</code> <pre><code>def save_log(self, output_path: str) -&gt; None:\n    \"\"\"\n    Save the processing log to a JSON file.\n    \"\"\"\n    if not output_path.endswith(\".json\"):\n        output_path += \".json\"\n\n    with open(output_path, \"w\") as f:\n        json.dump(self._log, f, indent=4, default=str)\n</code></pre>"},{"location":"api/preprocessing/","title":"Preprocessing API","text":""},{"location":"api/preprocessing/#pictologics.preprocessing","title":"<code>pictologics.preprocessing</code>","text":""},{"location":"api/preprocessing/#pictologics.preprocessing--image-preprocessing-module","title":"Image Preprocessing Module","text":"<p>This module provides a collection of preprocessing functions essential for radiomics analysis. These functions are designed to be IBSI-compliant where applicable.</p>"},{"location":"api/preprocessing/#pictologics.preprocessing--key-features","title":"Key Features:","text":"<ul> <li>Resampling: Voxel resampling using 'Align grid centers' (IBSI compliant).</li> <li>Discretisation: Fixed Bin Number (FBN) and Fixed Bin Size (FBS) algorithms.</li> <li>Filtering: Outlier filtering (mean +/- sigma).</li> <li>Mask Operations: Resegmentation (thresholding), ROI extraction, Largest Connected Component.</li> <li>Utilities: Rounding intensities, applying masks.</li> </ul>"},{"location":"api/preprocessing/#pictologics.preprocessing.apply_mask","title":"<code>apply_mask(image, mask, mask_values=1)</code>","text":"<p>Apply mask to image and return flattened array of voxel values.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image | ndarray</code> <p>Image object or numpy array.</p> required <code>mask</code> <code>Image | ndarray</code> <p>Image object (mask) or numpy array.</p> required <code>mask_values</code> <code>int | list[int] | None</code> <p>Value(s) in the mask to consider as ROI. Default is 1.          Can be a single integer or a list of integers.</p> <code>1</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>1D numpy array of values within the mask.</p> Source code in <code>pictologics/preprocessing.py</code> <pre><code>def apply_mask(\n    image: Image | np.ndarray,\n    mask: Image | np.ndarray,\n    mask_values: int | list[int] | None = 1,\n) -&gt; np.ndarray:\n    \"\"\"\n    Apply mask to image and return flattened array of voxel values.\n\n    Args:\n        image: Image object or numpy array.\n        mask: Image object (mask) or numpy array.\n        mask_values: Value(s) in the mask to consider as ROI. Default is 1.\n                     Can be a single integer or a list of integers.\n\n    Returns:\n        1D numpy array of values within the mask.\n    \"\"\"\n    # Handle inputs\n    img_arr = image.array if isinstance(image, Image) else image\n    mask_arr = mask.array if isinstance(mask, Image) else mask\n\n    # Ensure shapes match\n    if img_arr.shape != mask_arr.shape:\n        raise ValueError(\n            f\"Image shape {img_arr.shape} and mask shape {mask_arr.shape} do not match\"\n        )\n\n    # Handle mask values\n    if mask_values is None:\n        mask_values = [1]\n    elif isinstance(mask_values, int):\n        mask_values = [mask_values]\n\n    # Create boolean mask\n    roi_mask = np.isin(mask_arr, mask_values)\n\n    if not np.any(roi_mask):\n        return np.array([])\n\n    # Apply mask\n    return img_arr[roi_mask]\n</code></pre>"},{"location":"api/preprocessing/#pictologics.preprocessing.discretise_image","title":"<code>discretise_image(image, method, roi_mask=None, n_bins=None, bin_width=None, min_val=None, max_val=None, cutoffs=None)</code>","text":"<p>Discretise image intensities.</p> <p>Supports IBSI-compliant Fixed Bin Number (FBN) and Fixed Bin Size (FBS).</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image | ndarray</code> <p>Input Image object or numpy array.</p> required <code>method</code> <code>str</code> <p>'FBN' (Fixed Bin Number), 'FBS' (Fixed Bin Size), or 'FIXED_CUTOFFS'.</p> required <code>roi_mask</code> <code>Image | ndarray | None</code> <p>Optional mask to define the ROI for determining min/max values.</p> <code>None</code> <code>n_bins</code> <code>Optional[int]</code> <p>Number of bins (required for FBN).</p> <code>None</code> <code>bin_width</code> <code>Optional[float]</code> <p>Bin width (required for FBS).</p> <code>None</code> <code>min_val</code> <code>Optional[float]</code> <p>Minimum value for discretisation.      For FBS, defaults to ROI minimum (or global minimum).      For FBN, defaults to ROI minimum.</p> <code>None</code> <code>max_val</code> <code>Optional[float]</code> <p>Maximum value for discretisation (FBN only).      Defaults to ROI maximum.</p> <code>None</code> <code>cutoffs</code> <code>Optional[list[float]]</code> <p>List of cutoffs (required for FIXED_CUTOFFS).</p> <code>None</code> <p>Returns:</p> Type Description <code>Image | ndarray</code> <p>Discretised Image object or numpy array (depending on input).</p> <code>Image | ndarray</code> <p>Values are 1-based indices.</p> Source code in <code>pictologics/preprocessing.py</code> <pre><code>def discretise_image(\n    image: Image | np.ndarray,\n    method: str,\n    roi_mask: Image | np.ndarray | None = None,\n    n_bins: Optional[int] = None,\n    bin_width: Optional[float] = None,\n    min_val: Optional[float] = None,\n    max_val: Optional[float] = None,\n    cutoffs: Optional[list[float]] = None,\n) -&gt; Image | np.ndarray:\n    \"\"\"\n    Discretise image intensities.\n\n    Supports IBSI-compliant Fixed Bin Number (FBN) and Fixed Bin Size (FBS).\n\n    Args:\n        image: Input Image object or numpy array.\n        method: 'FBN' (Fixed Bin Number), 'FBS' (Fixed Bin Size), or 'FIXED_CUTOFFS'.\n        roi_mask: Optional mask to define the ROI for determining min/max values.\n        n_bins: Number of bins (required for FBN).\n        bin_width: Bin width (required for FBS).\n        min_val: Minimum value for discretisation.\n                 For FBS, defaults to ROI minimum (or global minimum).\n                 For FBN, defaults to ROI minimum.\n        max_val: Maximum value for discretisation (FBN only).\n                 Defaults to ROI maximum.\n        cutoffs: List of cutoffs (required for FIXED_CUTOFFS).\n\n    Returns:\n        Discretised Image object or numpy array (depending on input).\n        Values are 1-based indices.\n    \"\"\"\n    # Handle input type\n    if isinstance(image, Image):\n        array = image.array\n        is_image_obj = True\n    else:\n        array = image\n        is_image_obj = False\n\n    # Determine ROI values for default min/max\n    if roi_mask is not None:\n        if isinstance(roi_mask, Image):\n            mask_arr = roi_mask.array\n        else:\n            mask_arr = roi_mask\n\n        if mask_arr.shape != array.shape:\n            raise ValueError(\n                f\"Shape mismatch: Image {array.shape} vs Mask {mask_arr.shape}\"\n            )\n\n        # Extract ROI values (ignoring NaNs)\n        roi_values = array[(mask_arr &gt; 0) &amp; (~np.isnan(array))]\n    else:\n        roi_values = array[~np.isnan(array)]\n\n    # Initialize result\n    discretised = np.zeros(array.shape, dtype=int)\n\n    # We process all non-NaN pixels in the image\n    valid_mask = ~np.isnan(array)\n    values = array[valid_mask]\n\n    if values.size == 0:\n        if is_image_obj:\n            # Create new Image with discretised array\n            return Image(\n                array=discretised,\n                spacing=image.spacing,  # type: ignore\n                origin=image.origin,  # type: ignore\n                direction=image.direction,  # type: ignore\n                modality=image.modality,  # type: ignore\n            )\n        return discretised\n\n    if method == \"FBN\":\n        if n_bins is None:\n            raise ValueError(\"n_bins required for FBN\")\n        if n_bins &lt;= 0:\n            raise ValueError(\"n_bins must be positive\")\n\n        # Determine min/max\n        current_min = min_val\n        if current_min is None:\n            current_min = np.min(roi_values) if roi_values.size &gt; 0 else np.min(values)\n\n        current_max = max_val\n        if current_max is None:\n            current_max = np.max(roi_values) if roi_values.size &gt; 0 else np.max(values)\n\n        if current_max &lt;= current_min:\n            # Edge case: flat region or invalid range\n            discretised[valid_mask] = 1\n        else:\n            # IBSI FBN: floor(N_g * (X - X_min) / (X_max - X_min)) + 1\n            temp_discretised = (\n                np.floor(n_bins * (values - current_min) / (current_max - current_min))\n                + 1\n            )\n\n            # Handle max value case (it falls into N_g + 1 with this formula)\n            # Also clip outliers\n            temp_discretised[values &gt;= current_max] = n_bins\n            temp_discretised = np.clip(temp_discretised, 1, n_bins)\n\n            discretised[valid_mask] = temp_discretised.astype(int)\n\n    elif method == \"FBS\":\n        if bin_width is None:\n            raise ValueError(\"bin_width required for FBS\")\n        if bin_width &lt;= 0:\n            raise ValueError(\"bin_width must be positive\")\n\n        current_min = min_val\n        if current_min is None:\n            current_min = np.min(roi_values) if roi_values.size &gt; 0 else np.min(values)\n\n        # IBSI FBS: floor((X - X_min) / w_b) + 1\n        temp_discretised = np.floor((values - current_min) / bin_width) + 1\n\n        # Ensure minimum bin is 1\n        temp_discretised[temp_discretised &lt; 1] = 1\n        discretised[valid_mask] = temp_discretised.astype(int)\n\n    elif method == \"FIXED_CUTOFFS\":\n        if cutoffs is None:\n            raise ValueError(\"cutoffs required for FIXED_CUTOFFS\")\n\n        temp_discretised = np.digitize(values, bins=np.array(cutoffs))\n        discretised[valid_mask] = temp_discretised.astype(int)\n\n    else:\n        raise ValueError(f\"Unknown discretisation method: {method}\")\n\n    if is_image_obj:\n        return Image(\n            array=discretised,\n            spacing=image.spacing,  # type: ignore\n            origin=image.origin,  # type: ignore\n            direction=image.direction,  # type: ignore\n            modality=image.modality,  # type: ignore\n        )\n    return discretised\n</code></pre>"},{"location":"api/preprocessing/#pictologics.preprocessing.extract_roi","title":"<code>extract_roi(image, mask, mask_values=1)</code>","text":"<p>Extract ROI from image. Voxels outside the mask are set to NaN. IBSI 'ROI extraction'.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>Image object.</p> required <code>mask</code> <code>Image</code> <p>Image object (mask).</p> required <code>mask_values</code> <code>int | list[int] | None</code> <p>Value(s) in the mask to consider as ROI. Default is 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>Image</code> <p>New Image object with non-ROI voxels set to NaN.</p> Source code in <code>pictologics/preprocessing.py</code> <pre><code>def extract_roi(\n    image: Image,\n    mask: Image,\n    mask_values: int | list[int] | None = 1,\n) -&gt; Image:\n    \"\"\"\n    Extract ROI from image. Voxels outside the mask are set to NaN.\n    IBSI 'ROI extraction'.\n\n    Args:\n        image: Image object.\n        mask: Image object (mask).\n        mask_values: Value(s) in the mask to consider as ROI. Default is 1.\n\n    Returns:\n        New Image object with non-ROI voxels set to NaN.\n    \"\"\"\n    if image.array.shape != mask.array.shape:\n        raise ValueError(\"Image and mask must have the same shape.\")\n\n    # Handle mask values\n    if mask_values is None:\n        mask_values = [1]\n    elif isinstance(mask_values, int):\n        mask_values = [mask_values]\n\n    roi_mask = np.isin(mask.array, mask_values)\n\n    new_array = image.array.astype(float).copy()\n    new_array[~roi_mask] = np.nan\n\n    return Image(\n        array=new_array,\n        spacing=image.spacing,\n        origin=image.origin,\n        direction=image.direction,\n        modality=image.modality,\n    )\n</code></pre>"},{"location":"api/preprocessing/#pictologics.preprocessing.filter_outliers","title":"<code>filter_outliers(image, mask, sigma=3.0)</code>","text":"<p>Exclude outliers from the mask based on mean +/- sigma * std. IBSI 3.6.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>Image object.</p> required <code>mask</code> <code>Image</code> <p>Image object (mask).</p> required <code>sigma</code> <code>float</code> <p>Number of standard deviations.</p> <code>3.0</code> <p>Returns:</p> Type Description <code>Image</code> <p>New Image object (mask) with outliers removed.</p> Source code in <code>pictologics/preprocessing.py</code> <pre><code>def filter_outliers(image: Image, mask: Image, sigma: float = 3.0) -&gt; Image:\n    \"\"\"\n    Exclude outliers from the mask based on mean +/- sigma * std.\n    IBSI 3.6.\n\n    Args:\n        image: Image object.\n        mask: Image object (mask).\n        sigma: Number of standard deviations.\n\n    Returns:\n        New Image object (mask) with outliers removed.\n    \"\"\"\n    # Extract values within the mask\n    values = apply_mask(image, mask)\n\n    if values.size == 0:\n        return mask\n\n    mean_val = np.mean(values)\n    # IBSI uses population std (no bias correction, ddof=0)\n    std_val = np.std(values, ddof=0)\n\n    lower_bound = mean_val - sigma * std_val\n    upper_bound = mean_val + sigma * std_val\n\n    # Create outlier mask\n    # Keep values within [lower, upper]\n    valid_mask = (image.array &gt;= lower_bound) &amp; (image.array &lt;= upper_bound)\n\n    # Update original mask\n    new_mask_array = mask.array.copy()\n\n    # Ensure boolean or integer type for bitwise operation\n    # Assuming mask.array is binary (0/1) or boolean\n    if new_mask_array.dtype == bool:\n        new_mask_array = new_mask_array &amp; valid_mask\n    else:\n        new_mask_array = (new_mask_array * valid_mask).astype(np.uint8)\n\n    return Image(\n        array=new_mask_array,\n        spacing=mask.spacing,\n        origin=mask.origin,\n        direction=mask.direction,\n        modality=mask.modality,\n    )\n</code></pre>"},{"location":"api/preprocessing/#pictologics.preprocessing.keep_largest_component","title":"<code>keep_largest_component(mask)</code>","text":"<p>Keep only the largest connected component in the mask.</p> Source code in <code>pictologics/preprocessing.py</code> <pre><code>def keep_largest_component(mask: Image) -&gt; Image:\n    \"\"\"\n    Keep only the largest connected component in the mask.\n    \"\"\"\n    mask_array = mask.array\n    labeled_mask, num_features = label(mask_array)\n    if num_features &lt;= 1:\n        return mask\n\n    max_size = 0\n    max_label = 0\n    for i in range(1, num_features + 1):\n        size = np.sum(labeled_mask == i)\n        if size &gt; max_size:\n            max_size = size\n            max_label = i\n\n    new_array = (labeled_mask == max_label).astype(np.uint8)\n\n    return Image(\n        array=new_array,\n        spacing=mask.spacing,\n        origin=mask.origin,\n        direction=mask.direction,\n        modality=mask.modality,\n    )\n</code></pre>"},{"location":"api/preprocessing/#pictologics.preprocessing.resample_image","title":"<code>resample_image(image, new_spacing, interpolation='linear', boundary_mode='nearest', round_intensities=False, mask_threshold=None)</code>","text":"<p>Resample image to new voxel spacing using IBSI-compliant 'Align grid centers' method.</p> <p>Uses scipy.ndimage.affine_transform for memory efficiency.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>Input Image object.</p> required <code>new_spacing</code> <code>tuple[float, float, float]</code> <p>Target spacing (x, y, z). Must be positive.</p> required <code>interpolation</code> <code>str</code> <p>Interpolation method. 'nearest': Nearest neighbour (order 0). 'linear': Trilinear (order 1). 'cubic': Tricubic spline (order 3).</p> <code>'linear'</code> <code>boundary_mode</code> <code>str</code> <p>Padding mode for extrapolation. 'nearest' (default): Replicates edge values (aaaa|abcd|dddd). 'constant': Pads with constant value (0). 'reflect': Reflects at boundary. 'wrap': Wraps around.</p> <code>'nearest'</code> <code>round_intensities</code> <code>bool</code> <p>If True, round resulting intensities to nearest integer.</p> <code>False</code> <code>mask_threshold</code> <code>Optional[float]</code> <p>If provided, treat output as a binary mask.             Values &gt;= threshold become 1, others 0.             Commonly 0.5 for partial volume correction.</p> <code>None</code> <p>Returns:</p> Type Description <code>Image</code> <p>Resampled Image object.</p> Source code in <code>pictologics/preprocessing.py</code> <pre><code>def resample_image(\n    image: Image,\n    new_spacing: tuple[float, float, float],\n    interpolation: str = \"linear\",\n    boundary_mode: str = \"nearest\",\n    round_intensities: bool = False,\n    mask_threshold: Optional[float] = None,\n) -&gt; Image:\n    \"\"\"\n    Resample image to new voxel spacing using IBSI-compliant 'Align grid centers' method.\n\n    Uses scipy.ndimage.affine_transform for memory efficiency.\n\n    Args:\n        image: Input Image object.\n        new_spacing: Target spacing (x, y, z). Must be positive.\n        interpolation: Interpolation method.\n            'nearest': Nearest neighbour (order 0).\n            'linear': Trilinear (order 1).\n            'cubic': Tricubic spline (order 3).\n        boundary_mode: Padding mode for extrapolation.\n            'nearest' (default): Replicates edge values (aaaa|abcd|dddd).\n            'constant': Pads with constant value (0).\n            'reflect': Reflects at boundary.\n            'wrap': Wraps around.\n        round_intensities: If True, round resulting intensities to nearest integer.\n        mask_threshold: If provided, treat output as a binary mask.\n                        Values &gt;= threshold become 1, others 0.\n                        Commonly 0.5 for partial volume correction.\n\n    Returns:\n        Resampled Image object.\n    \"\"\"\n    if any(s &lt;= 0 for s in new_spacing):\n        raise ValueError(f\"New spacing must be positive, got {new_spacing}\")\n\n    # Map interpolation string to spline order\n    interpolation_map = {\n        \"nearest\": 0,\n        \"linear\": 1,\n        \"cubic\": 3,\n    }\n\n    if interpolation not in interpolation_map:\n        raise ValueError(\n            f\"Unknown interpolation method: {interpolation}. \"\n            f\"Supported: {list(interpolation_map.keys())}\"\n        )\n\n    order = interpolation_map[interpolation]\n\n    # Calculate new shape\n    # IBSI: nb = ceil(na * sa / sb)\n    original_spacing = np.array(image.spacing)\n    target_spacing = np.array(new_spacing)\n\n    # Scale factor for dimensions (how many new voxels per old voxel)\n    # dim_scale = s_old / s_new\n    dim_scale = original_spacing / target_spacing\n\n    new_shape = np.ceil(image.array.shape * dim_scale).astype(int)\n\n    # Calculate affine transform parameters\n    # We map Output Coordinate (x_out) -&gt; Input Coordinate (x_in)\n    # x_in = matrix * x_out + offset\n\n    # Scale factor for coordinates (step size in input space per step in output space)\n    # step_in = s_new / s_old\n    coord_scale = target_spacing / original_spacing\n    matrix = coord_scale  # Diagonal matrix elements\n\n    # Calculate offset for 'Align Grid Centers\n    center_orig = (np.array(image.array.shape) - 1) / 2.0\n    center_new = (new_shape - 1) / 2.0\n\n    offset = center_orig - matrix * center_new\n\n    resampled_array = affine_transform(\n        image.array,\n        matrix=matrix,\n        offset=offset,\n        output_shape=new_shape,\n        order=order,\n        mode=boundary_mode,\n    )\n\n    # Post-processing\n    if mask_threshold is not None:\n        # Binarize mask\n        resampled_array = (resampled_array &gt;= mask_threshold).astype(np.uint8)\n    elif round_intensities:\n        # Round intensities\n        resampled_array = np.round(resampled_array)\n\n    # Update origin to maintain center alignment\n    # O_new = O_old + 0.5 * ( (N_old-1)*S_old - (N_new-1)*S_new )\n    extent_orig = (np.array(image.array.shape) - 1) * original_spacing\n    extent_new = (new_shape - 1) * target_spacing\n    origin_shift = 0.5 * (extent_orig - extent_new)\n    new_origin = tuple(np.array(image.origin) + origin_shift)\n\n    return Image(\n        array=resampled_array,\n        spacing=new_spacing,\n        origin=new_origin,\n        direction=image.direction,\n        modality=image.modality,\n    )\n</code></pre>"},{"location":"api/preprocessing/#pictologics.preprocessing.resegment_mask","title":"<code>resegment_mask(image, mask, range_min=None, range_max=None)</code>","text":"<p>Update mask to exclude voxels where image intensity is outside the specified range. Used for IBSI re-segmentation (e.g. [-1000, 400] HU).</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>Image object.</p> required <code>mask</code> <code>Image</code> <p>Image object (mask).</p> required <code>range_min</code> <code>Optional[float]</code> <p>Minimum intensity value (inclusive). If None, no lower bound.</p> <code>None</code> <code>range_max</code> <code>Optional[float]</code> <p>Maximum intensity value (inclusive). If None, no upper bound.</p> <code>None</code> <p>Returns:</p> Type Description <code>Image</code> <p>Updated Image object (mask) with re-segmentation applied.</p> Source code in <code>pictologics/preprocessing.py</code> <pre><code>def resegment_mask(\n    image: Image,\n    mask: Image,\n    range_min: Optional[float] = None,\n    range_max: Optional[float] = None,\n) -&gt; Image:\n    \"\"\"\n    Update mask to exclude voxels where image intensity is outside the specified range.\n    Used for IBSI re-segmentation (e.g. [-1000, 400] HU).\n\n    Args:\n        image: Image object.\n        mask: Image object (mask).\n        range_min: Minimum intensity value (inclusive). If None, no lower bound.\n        range_max: Maximum intensity value (inclusive). If None, no upper bound.\n\n    Returns:\n        Updated Image object (mask) with re-segmentation applied.\n    \"\"\"\n    if image.array.shape != mask.array.shape:\n        raise ValueError(\"Image and mask must have the same shape for re-segmentation.\")\n\n    new_mask_array = mask.array.copy()\n\n    # Identify outliers\n    outliers = np.zeros(image.array.shape, dtype=bool)\n\n    if range_min is not None:\n        outliers |= image.array &lt; range_min\n\n    if range_max is not None:\n        outliers |= image.array &gt; range_max\n\n    # Set mask to 0 where outliers exist\n    new_mask_array[outliers] = 0\n\n    return Image(\n        array=new_mask_array,\n        spacing=mask.spacing,\n        origin=mask.origin,\n        direction=mask.direction,\n        modality=mask.modality,\n    )\n</code></pre>"},{"location":"api/preprocessing/#pictologics.preprocessing.round_intensities","title":"<code>round_intensities(image)</code>","text":"<p>Round image intensities to the nearest integer.</p> Source code in <code>pictologics/preprocessing.py</code> <pre><code>def round_intensities(image: Image) -&gt; Image:\n    \"\"\"\n    Round image intensities to the nearest integer.\n    \"\"\"\n    new_array = np.round(image.array)\n    return Image(\n        array=new_array,\n        spacing=image.spacing,\n        origin=image.origin,\n        direction=image.direction,\n        modality=image.modality,\n    )\n</code></pre>"},{"location":"api/results/","title":"Results API","text":""},{"location":"api/results/#pictologics.results","title":"<code>pictologics.results</code>","text":""},{"location":"api/results/#pictologics.results--results-module","title":"Results Module","text":"<p>This module provides utilities for formatting and saving radiomic feature extraction results. It supports multiple output formats (wide, long) and file formats (CSV, JSON).</p>"},{"location":"api/results/#pictologics.results--key-functions","title":"Key Functions:","text":"<ul> <li>format_results: Convert pipeline output to various formats (dict, pandas DataFrame, JSON).</li> <li>save_results: Save results to CSV or JSON files with automatic format detection.</li> </ul>"},{"location":"api/results/#pictologics.results.format_results","title":"<code>format_results(results, fmt='wide', meta=None, output_type='dict', config_col='config')</code>","text":"<p>Format the output of RadiomicsPipeline.run() into a structured format.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>dict[str, Series]</code> <p>Dictionary mapping configuration names to pandas Series of features      (the standard output of RadiomicsPipeline.run).</p> required <code>fmt</code> <code>str</code> <p>\"wide\" or \"long\".  - \"wide\": Flattens keys to '{config}__{feature}'. Returns 1 row (dict/df).  - \"long\": Tidy format with columns for config, feature_name, and value.</p> <code>'wide'</code> <code>meta</code> <code>dict[str, Any] | None</code> <p>Optional dictionary of metadata to prepend to the result (e.g., subject ID).</p> <code>None</code> <code>output_type</code> <code>str</code> <p>Format of the returned object: \"dict\", \"pandas\", or \"json\".</p> <code>'dict'</code> <code>config_col</code> <code>str</code> <p>Name of the column holding the configuration name (only used if fmt=\"long\").</p> <code>'config'</code> <p>Returns:</p> Type Description <code>dict[str, Any] | DataFrame | str | list[dict[str, Any]]</code> <p>Formatted data in the specified output_type.</p> Source code in <code>pictologics/results.py</code> <pre><code>def format_results(\n    results: dict[str, pd.Series],\n    fmt: str = \"wide\",\n    meta: dict[str, Any] | None = None,\n    output_type: str = \"dict\",\n    config_col: str = \"config\",\n) -&gt; dict[str, Any] | pd.DataFrame | str | list[dict[str, Any]]:\n    \"\"\"\n    Format the output of RadiomicsPipeline.run() into a structured format.\n\n    Args:\n        results: Dictionary mapping configuration names to pandas Series of features\n                 (the standard output of RadiomicsPipeline.run).\n        fmt: \"wide\" or \"long\".\n             - \"wide\": Flattens keys to '{config}__{feature}'. Returns 1 row (dict/df).\n             - \"long\": Tidy format with columns for config, feature_name, and value.\n        meta: Optional dictionary of metadata to prepend to the result (e.g., subject ID).\n        output_type: Format of the returned object: \"dict\", \"pandas\", or \"json\".\n        config_col: Name of the column holding the configuration name (only used if fmt=\"long\").\n\n    Returns:\n        Formatted data in the specified output_type.\n    \"\"\"\n    if meta is None:\n        meta = {}\n\n    if fmt == \"wide\":\n        # Wide format: { \"meta_key\": val, \"config__feature\": val }\n        formatted_data = meta.copy()\n        for config_name, series in results.items():\n            for feature_name, value in series.items():\n                col_name = f\"{config_name}__{feature_name}\"\n                formatted_data[col_name] = value\n\n        if output_type == \"dict\":\n            return formatted_data\n        elif output_type == \"pandas\":\n            return pd.DataFrame([formatted_data])\n        elif output_type == \"json\":\n            return json.dumps(formatted_data)\n        else:\n            raise ValueError(f\"Unknown output_type: {output_type}\")\n\n    elif fmt == \"long\":\n        # Long format: Rows of [meta_cols..., config, feature_name, value]\n        rows = []\n        for config_name, series in results.items():\n            for feature_name, value in series.items():\n                row = meta.copy()\n                row[config_col] = config_name\n                row[\"feature_name\"] = feature_name\n                row[\"value\"] = value\n                rows.append(row)\n\n        if not rows:\n            # Handle empty results case\n            # For pure python output, empty list is fine.\n            # For pandas, we need a dataframe with columns.\n            if output_type != \"pandas\":\n                if output_type == \"dict\":\n                    return []\n                elif output_type == \"json\":\n                    return \"[]\"\n\n            df = pd.DataFrame(\n                columns=list(meta.keys()) + [config_col, \"feature_name\", \"value\"]\n            )\n            return df  # Columns are already in order\n\n        # Reorder keys/columns\n        # Determine strict order\n        meta_keys = list(meta.keys())\n        standard_cols = [config_col, \"feature_name\", \"value\"]\n        # Ensure we don't duplicate keys\n        cols_order = meta_keys + [c for c in standard_cols if c not in meta_keys]\n\n        # If output is dict/json, reorder the dictionaries directly\n        if output_type in (\"dict\", \"json\"):\n            # Ensure each row has keys in the desired order\n            ordered_rows = []\n            for r in rows:\n                new_r = {k: r.get(k) for k in cols_order if k in r}\n\n                ordered_rows.append(new_r)\n\n            if output_type == \"dict\":\n                return ordered_rows\n            else:  # json\n                return json.dumps(ordered_rows)\n\n        # Output type is 'pandas'\n        df = pd.DataFrame(rows)\n        # Verify which columns actually exist in the dataframe\n        existing_cols = list(df.columns)\n        final_order = [c for c in cols_order if c in existing_cols] + [\n            c for c in existing_cols if c not in cols_order\n        ]\n        df = df.reindex(columns=final_order)\n\n        return df\n\n    else:\n        raise ValueError(f\"Unknown format: {fmt}. Use 'wide' or 'long'.\")\n</code></pre>"},{"location":"api/results/#pictologics.results.save_results","title":"<code>save_results(data, path, file_format=None)</code>","text":"<p>Save results to a file (CSV, JSON, etc.), automatically handling merging of lists.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict[str, Any] | list[dict[str, Any]] | DataFrame | list[DataFrame] | str | list[str]</code> <p>The data to save. Supported types:   - Dict or List[Dict]   - DataFrame or List[DataFrame]   - JSON string or List[JSON strings]</p> required <code>path</code> <code>str | Path</code> <p>Output file path.</p> required <code>file_format</code> <code>str | None</code> <p>\"csv\" or \"json\". If None, inferred from file extension.</p> <code>None</code> Source code in <code>pictologics/results.py</code> <pre><code>def save_results(\n    data: (\n        dict[str, Any]\n        | list[dict[str, Any]]\n        | pd.DataFrame\n        | list[pd.DataFrame]\n        | str\n        | list[str]\n    ),\n    path: str | Path,\n    file_format: str | None = None,\n) -&gt; None:\n    \"\"\"\n    Save results to a file (CSV, JSON, etc.), automatically handling merging of lists.\n\n    Args:\n        data: The data to save. Supported types:\n              - Dict or List[Dict]\n              - DataFrame or List[DataFrame]\n              - JSON string or List[JSON strings]\n        path: Output file path.\n        file_format: \"csv\" or \"json\". If None, inferred from file extension.\n    \"\"\"\n    path = Path(path)\n    if file_format is None:\n        if path.suffix.lower() == \".csv\":\n            file_format = \"csv\"\n        elif path.suffix.lower() == \".json\":\n            file_format = \"json\"\n        else:\n            file_format = \"csv\"\n\n    # If format is JSON and data is already a dict or list of dicts, bypass pandas\n    # to avoid overhead and potential C-extension conflicts in coverage/threading.\n    if file_format == \"json\":\n        # Check if data is already in a compatible format\n        is_dict = isinstance(data, dict)\n        is_list_of_dicts = isinstance(data, list) and (\n            not data or isinstance(data[0], dict)\n        )\n\n        if is_dict:\n            with open(path, \"w\") as f:\n                json.dump([data], f, indent=2)\n            return\n\n        if is_list_of_dicts:\n            with open(path, \"w\") as f:\n                json.dump(data, f, indent=2)\n            return\n\n    # Normalize input to a single DataFrame\n    try:\n        final_df = _normalize_to_dataframe(data)\n    except Exception as e:\n        # If normalization fails but we want to debug, re-raise\n        raise e\n\n    # Export\n    if file_format == \"csv\":\n        final_df.to_csv(path, index=False)\n    elif file_format == \"json\":\n        # Use standard json library to avoid potential pandas C-extension issues during coverage\n        with open(path, \"w\") as f:\n            json.dump(final_df.to_dict(orient=\"records\"), f, indent=2)\n    else:\n        raise ValueError(f\"Unsupported export format: {file_format}\")\n</code></pre>"},{"location":"api/utilities/","title":"Utilities API","text":""},{"location":"api/utilities/#pictologics.utilities.dicom_database","title":"<code>pictologics.utilities.dicom_database</code>","text":""},{"location":"api/utilities/#pictologics.utilities.dicom_database--dicom-database-module","title":"DICOM Database Module","text":"<p>This module provides dataclass-based hierarchical organization of DICOM files with completeness validation and multi-level DataFrame exports.</p> <p>The implementation supports parallel processing for improved performance on large datasets, with stateless file processing and immutable intermediate results.</p>"},{"location":"api/utilities/#pictologics.utilities.dicom_database.DicomInstance","title":"<code>DicomInstance</code>  <code>dataclass</code>","text":"<p>Represents a single DICOM file/instance.</p> <p>Attributes:</p> Name Type Description <code>sop_instance_uid</code> <code>str</code> <p>Unique identifier for this instance.</p> <code>file_path</code> <code>Path</code> <p>Absolute path to the DICOM file.</p> <code>instance_number</code> <code>Optional[int]</code> <p>Instance number within the series.</p> <code>image_position_patient</code> <code>Optional[tuple[float, float, float]]</code> <p>(x, y, z) position in patient coordinates.</p> <code>image_orientation_patient</code> <code>Optional[tuple[float, ...]]</code> <p>Direction cosines for row and column.</p> <code>slice_location</code> <code>Optional[float]</code> <p>Slice location value from DICOM header.</p> <code>acquisition_datetime</code> <code>Optional[str]</code> <p>Combined acquisition date and time.</p> <code>projection_score</code> <code>Optional[float]</code> <p>Calculated projection onto slice normal for sorting.</p> <code>metadata</code> <code>dict[str, Any]</code> <p>Additional extracted metadata tags.</p> Source code in <code>pictologics/utilities/dicom_database.py</code> <pre><code>@dataclass\nclass DicomInstance:\n    \"\"\"Represents a single DICOM file/instance.\n\n    Attributes:\n        sop_instance_uid: Unique identifier for this instance.\n        file_path: Absolute path to the DICOM file.\n        instance_number: Instance number within the series.\n        image_position_patient: (x, y, z) position in patient coordinates.\n        image_orientation_patient: Direction cosines for row and column.\n        slice_location: Slice location value from DICOM header.\n        acquisition_datetime: Combined acquisition date and time.\n        projection_score: Calculated projection onto slice normal for sorting.\n        metadata: Additional extracted metadata tags.\n    \"\"\"\n\n    sop_instance_uid: str\n    file_path: Path\n    instance_number: Optional[int] = None\n    image_position_patient: Optional[tuple[float, float, float]] = None\n    image_orientation_patient: Optional[tuple[float, ...]] = None\n    slice_location: Optional[float] = None\n    acquisition_datetime: Optional[str] = None\n    projection_score: Optional[float] = None\n    metadata: dict[str, Any] = field(default_factory=dict)\n    tags: dict[str, Any] = field(default_factory=dict)\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_database.DicomSeries","title":"<code>DicomSeries</code>  <code>dataclass</code>","text":"<p>Represents a DICOM series containing multiple instances.</p> <p>Attributes:</p> Name Type Description <code>series_instance_uid</code> <code>str</code> <p>Unique identifier for this series.</p> <code>series_number</code> <code>Optional[int]</code> <p>Series number within the study.</p> <code>series_description</code> <code>Optional[str]</code> <p>Description of the series.</p> <code>modality</code> <code>Optional[str]</code> <p>Imaging modality (CT, MR, etc.).</p> <code>frame_of_reference_uid</code> <code>Optional[str]</code> <p>Frame of reference UID.</p> <code>instances</code> <code>list[DicomInstance]</code> <p>List of DicomInstance objects in this series.</p> <code>common_metadata</code> <code>dict[str, Any]</code> <p>Metadata tags identical across all instances.</p> Source code in <code>pictologics/utilities/dicom_database.py</code> <pre><code>@dataclass\nclass DicomSeries:\n    \"\"\"Represents a DICOM series containing multiple instances.\n\n    Attributes:\n        series_instance_uid: Unique identifier for this series.\n        series_number: Series number within the study.\n        series_description: Description of the series.\n        modality: Imaging modality (CT, MR, etc.).\n        frame_of_reference_uid: Frame of reference UID.\n        instances: List of DicomInstance objects in this series.\n        common_metadata: Metadata tags identical across all instances.\n    \"\"\"\n\n    series_instance_uid: str\n    series_number: Optional[int] = None\n    series_description: Optional[str] = None\n    modality: Optional[str] = None\n    frame_of_reference_uid: Optional[str] = None\n    instances: list[DicomInstance] = field(default_factory=list)\n    common_metadata: dict[str, Any] = field(default_factory=dict)\n\n    def get_sorted_instances(self) -&gt; list[DicomInstance]:\n        \"\"\"Return instances sorted by spatial position (projection score).\n\n        Uses the same methodology as pictologics.loader for spatial sorting.\n        Falls back to instance number if projection scores are not available.\n        \"\"\"\n        if all(inst.projection_score is not None for inst in self.instances):\n            return sorted(self.instances, key=lambda x: x.projection_score or 0)\n        return sorted(\n            self.instances, key=lambda x: x.instance_number if x.instance_number else 0\n        )\n\n    def check_completeness(self, spacing_tolerance: float = 0.1) -&gt; dict[str, Any]:\n        \"\"\"Check if the series has all expected slices.\n\n        Uses geometric validation based on ImagePositionPatient projection\n        to detect missing slices and gaps.\n\n        Args:\n            spacing_tolerance: Tolerance for gap detection (default 10%).\n\n        Returns:\n            Dictionary with completeness information.\n        \"\"\"\n        result: dict[str, Any] = {\n            \"series_uid\": self.series_instance_uid,\n            \"total_instances\": len(self.instances),\n            \"expected_instances\": len(self.instances),\n            \"is_complete\": True,\n            \"has_gaps\": False,\n            \"gap_indices\": [],\n            \"gap_positions\": [],\n            \"spacing_mm\": None,\n            \"spacing_std\": None,\n            \"spacing_uniform\": True,\n            \"first_slice_position\": None,\n            \"last_slice_position\": None,\n            \"frame_of_reference_uid\": self.frame_of_reference_uid,\n            \"warnings\": [],\n        }\n\n        if len(self.instances) &lt; 2:\n            result[\"warnings\"].append(\"Series has fewer than 2 instances\")\n            return result\n\n        # Get sorted instances by projection score\n        sorted_instances = self.get_sorted_instances()\n\n        # Check if we have projection scores for geometric validation\n        projection_scores = [\n            inst.projection_score\n            for inst in sorted_instances\n            if inst.projection_score is not None\n        ]\n\n        if len(projection_scores) &lt; 2:\n            result[\"warnings\"].append(\n                \"Insufficient spatial data for geometric completeness check\"\n            )\n            # Fall back to instance number validation\n            instance_numbers = [\n                inst.instance_number\n                for inst in sorted_instances\n                if inst.instance_number is not None\n            ]\n            if len(instance_numbers) &gt;= 2:\n                instance_numbers_sorted = sorted(instance_numbers)\n                expected_range = set(\n                    range(instance_numbers_sorted[0], instance_numbers_sorted[-1] + 1)\n                )\n                missing = expected_range - set(instance_numbers)\n                if missing:\n                    result[\"is_complete\"] = False\n                    result[\"has_gaps\"] = True\n                    result[\"gap_indices\"] = sorted(missing)\n                    result[\"expected_instances\"] = len(expected_range)\n            return result\n\n        # Calculate spacings between consecutive slices\n        spacings = np.diff(projection_scores)\n        median_spacing = float(np.median(np.abs(spacings)))\n        spacing_std = float(np.std(np.abs(spacings)))\n\n        result[\"spacing_mm\"] = median_spacing\n        result[\"spacing_std\"] = spacing_std\n        result[\"first_slice_position\"] = projection_scores[0]\n        result[\"last_slice_position\"] = projection_scores[-1]\n\n        # Check for uniform spacing\n        if median_spacing &gt; 0:\n            spacing_cv = spacing_std / median_spacing  # Coefficient of variation\n            result[\"spacing_uniform\"] = spacing_cv &lt; spacing_tolerance\n\n        # Detect gaps (spacing significantly larger than expected)\n        gap_threshold = median_spacing * (1 + spacing_tolerance)\n        gap_indices = []\n        gap_positions = []\n\n        for i, spacing in enumerate(np.abs(spacings)):\n            if spacing &gt; gap_threshold * 1.5:  # Gap detected\n                gap_indices.append(i + 1)\n                gap_positions.append(projection_scores[i])\n\n        if gap_indices:\n            result[\"has_gaps\"] = True\n            result[\"gap_indices\"] = gap_indices\n            result[\"gap_positions\"] = gap_positions\n\n            # Estimate expected instances based on position range and median spacing\n            position_range = abs(projection_scores[-1] - projection_scores[0])\n            if median_spacing &gt; 0:\n                expected = int(round(position_range / median_spacing)) + 1\n                result[\"expected_instances\"] = expected\n                result[\"is_complete\"] = False\n\n        return result\n\n    def get_instance_uids(self) -&gt; list[str]:\n        \"\"\"Get list of all instance SOPInstanceUIDs.\"\"\"\n        return [inst.sop_instance_uid for inst in self.instances]\n\n    def get_file_paths(self) -&gt; list[str]:\n        \"\"\"Get list of all instance file paths as strings.\"\"\"\n        return [str(inst.file_path) for inst in self.instances]\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_database.DicomSeries.check_completeness","title":"<code>check_completeness(spacing_tolerance=0.1)</code>","text":"<p>Check if the series has all expected slices.</p> <p>Uses geometric validation based on ImagePositionPatient projection to detect missing slices and gaps.</p> <p>Parameters:</p> Name Type Description Default <code>spacing_tolerance</code> <code>float</code> <p>Tolerance for gap detection (default 10%).</p> <code>0.1</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with completeness information.</p> Source code in <code>pictologics/utilities/dicom_database.py</code> <pre><code>def check_completeness(self, spacing_tolerance: float = 0.1) -&gt; dict[str, Any]:\n    \"\"\"Check if the series has all expected slices.\n\n    Uses geometric validation based on ImagePositionPatient projection\n    to detect missing slices and gaps.\n\n    Args:\n        spacing_tolerance: Tolerance for gap detection (default 10%).\n\n    Returns:\n        Dictionary with completeness information.\n    \"\"\"\n    result: dict[str, Any] = {\n        \"series_uid\": self.series_instance_uid,\n        \"total_instances\": len(self.instances),\n        \"expected_instances\": len(self.instances),\n        \"is_complete\": True,\n        \"has_gaps\": False,\n        \"gap_indices\": [],\n        \"gap_positions\": [],\n        \"spacing_mm\": None,\n        \"spacing_std\": None,\n        \"spacing_uniform\": True,\n        \"first_slice_position\": None,\n        \"last_slice_position\": None,\n        \"frame_of_reference_uid\": self.frame_of_reference_uid,\n        \"warnings\": [],\n    }\n\n    if len(self.instances) &lt; 2:\n        result[\"warnings\"].append(\"Series has fewer than 2 instances\")\n        return result\n\n    # Get sorted instances by projection score\n    sorted_instances = self.get_sorted_instances()\n\n    # Check if we have projection scores for geometric validation\n    projection_scores = [\n        inst.projection_score\n        for inst in sorted_instances\n        if inst.projection_score is not None\n    ]\n\n    if len(projection_scores) &lt; 2:\n        result[\"warnings\"].append(\n            \"Insufficient spatial data for geometric completeness check\"\n        )\n        # Fall back to instance number validation\n        instance_numbers = [\n            inst.instance_number\n            for inst in sorted_instances\n            if inst.instance_number is not None\n        ]\n        if len(instance_numbers) &gt;= 2:\n            instance_numbers_sorted = sorted(instance_numbers)\n            expected_range = set(\n                range(instance_numbers_sorted[0], instance_numbers_sorted[-1] + 1)\n            )\n            missing = expected_range - set(instance_numbers)\n            if missing:\n                result[\"is_complete\"] = False\n                result[\"has_gaps\"] = True\n                result[\"gap_indices\"] = sorted(missing)\n                result[\"expected_instances\"] = len(expected_range)\n        return result\n\n    # Calculate spacings between consecutive slices\n    spacings = np.diff(projection_scores)\n    median_spacing = float(np.median(np.abs(spacings)))\n    spacing_std = float(np.std(np.abs(spacings)))\n\n    result[\"spacing_mm\"] = median_spacing\n    result[\"spacing_std\"] = spacing_std\n    result[\"first_slice_position\"] = projection_scores[0]\n    result[\"last_slice_position\"] = projection_scores[-1]\n\n    # Check for uniform spacing\n    if median_spacing &gt; 0:\n        spacing_cv = spacing_std / median_spacing  # Coefficient of variation\n        result[\"spacing_uniform\"] = spacing_cv &lt; spacing_tolerance\n\n    # Detect gaps (spacing significantly larger than expected)\n    gap_threshold = median_spacing * (1 + spacing_tolerance)\n    gap_indices = []\n    gap_positions = []\n\n    for i, spacing in enumerate(np.abs(spacings)):\n        if spacing &gt; gap_threshold * 1.5:  # Gap detected\n            gap_indices.append(i + 1)\n            gap_positions.append(projection_scores[i])\n\n    if gap_indices:\n        result[\"has_gaps\"] = True\n        result[\"gap_indices\"] = gap_indices\n        result[\"gap_positions\"] = gap_positions\n\n        # Estimate expected instances based on position range and median spacing\n        position_range = abs(projection_scores[-1] - projection_scores[0])\n        if median_spacing &gt; 0:\n            expected = int(round(position_range / median_spacing)) + 1\n            result[\"expected_instances\"] = expected\n            result[\"is_complete\"] = False\n\n    return result\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_database.DicomSeries.get_file_paths","title":"<code>get_file_paths()</code>","text":"<p>Get list of all instance file paths as strings.</p> Source code in <code>pictologics/utilities/dicom_database.py</code> <pre><code>def get_file_paths(self) -&gt; list[str]:\n    \"\"\"Get list of all instance file paths as strings.\"\"\"\n    return [str(inst.file_path) for inst in self.instances]\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_database.DicomSeries.get_instance_uids","title":"<code>get_instance_uids()</code>","text":"<p>Get list of all instance SOPInstanceUIDs.</p> Source code in <code>pictologics/utilities/dicom_database.py</code> <pre><code>def get_instance_uids(self) -&gt; list[str]:\n    \"\"\"Get list of all instance SOPInstanceUIDs.\"\"\"\n    return [inst.sop_instance_uid for inst in self.instances]\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_database.DicomSeries.get_sorted_instances","title":"<code>get_sorted_instances()</code>","text":"<p>Return instances sorted by spatial position (projection score).</p> <p>Uses the same methodology as pictologics.loader for spatial sorting. Falls back to instance number if projection scores are not available.</p> Source code in <code>pictologics/utilities/dicom_database.py</code> <pre><code>def get_sorted_instances(self) -&gt; list[DicomInstance]:\n    \"\"\"Return instances sorted by spatial position (projection score).\n\n    Uses the same methodology as pictologics.loader for spatial sorting.\n    Falls back to instance number if projection scores are not available.\n    \"\"\"\n    if all(inst.projection_score is not None for inst in self.instances):\n        return sorted(self.instances, key=lambda x: x.projection_score or 0)\n    return sorted(\n        self.instances, key=lambda x: x.instance_number if x.instance_number else 0\n    )\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_database.DicomStudy","title":"<code>DicomStudy</code>  <code>dataclass</code>","text":"<p>Represents a DICOM study containing multiple series.</p> <p>Attributes:</p> Name Type Description <code>study_instance_uid</code> <code>str</code> <p>Unique identifier for this study.</p> <code>study_date</code> <code>Optional[str]</code> <p>Date of the study.</p> <code>study_time</code> <code>Optional[str]</code> <p>Time of the study.</p> <code>study_description</code> <code>Optional[str]</code> <p>Description of the study.</p> <code>series</code> <code>list[DicomSeries]</code> <p>List of DicomSeries objects in this study.</p> <code>common_metadata</code> <code>dict[str, Any]</code> <p>Metadata tags identical across all series.</p> Source code in <code>pictologics/utilities/dicom_database.py</code> <pre><code>@dataclass\nclass DicomStudy:\n    \"\"\"Represents a DICOM study containing multiple series.\n\n    Attributes:\n        study_instance_uid: Unique identifier for this study.\n        study_date: Date of the study.\n        study_time: Time of the study.\n        study_description: Description of the study.\n        series: List of DicomSeries objects in this study.\n        common_metadata: Metadata tags identical across all series.\n    \"\"\"\n\n    study_instance_uid: str\n    study_date: Optional[str] = None\n    study_time: Optional[str] = None\n    study_description: Optional[str] = None\n    series: list[DicomSeries] = field(default_factory=list)\n    common_metadata: dict[str, Any] = field(default_factory=dict)\n\n    def get_instance_uids(self) -&gt; list[str]:\n        \"\"\"Get list of all instance SOPInstanceUIDs in this study.\"\"\"\n        uids = []\n        for s in self.series:\n            uids.extend(s.get_instance_uids())\n        return uids\n\n    def get_file_paths(self) -&gt; list[str]:\n        \"\"\"Get list of all instance file paths in this study.\"\"\"\n        paths = []\n        for s in self.series:\n            paths.extend(s.get_file_paths())\n        return paths\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_database.DicomStudy.get_file_paths","title":"<code>get_file_paths()</code>","text":"<p>Get list of all instance file paths in this study.</p> Source code in <code>pictologics/utilities/dicom_database.py</code> <pre><code>def get_file_paths(self) -&gt; list[str]:\n    \"\"\"Get list of all instance file paths in this study.\"\"\"\n    paths = []\n    for s in self.series:\n        paths.extend(s.get_file_paths())\n    return paths\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_database.DicomStudy.get_instance_uids","title":"<code>get_instance_uids()</code>","text":"<p>Get list of all instance SOPInstanceUIDs in this study.</p> Source code in <code>pictologics/utilities/dicom_database.py</code> <pre><code>def get_instance_uids(self) -&gt; list[str]:\n    \"\"\"Get list of all instance SOPInstanceUIDs in this study.\"\"\"\n    uids = []\n    for s in self.series:\n        uids.extend(s.get_instance_uids())\n    return uids\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_database.DicomPatient","title":"<code>DicomPatient</code>  <code>dataclass</code>","text":"<p>Represents a DICOM patient containing multiple studies.</p> <p>Attributes:</p> Name Type Description <code>patient_id</code> <code>str</code> <p>Patient identifier.</p> <code>patients_name</code> <code>Optional[str]</code> <p>Patient's name.</p> <code>patients_birth_date</code> <code>Optional[str]</code> <p>Patient's birth date.</p> <code>patients_sex</code> <code>Optional[str]</code> <p>Patient's sex.</p> <code>studies</code> <code>list[DicomStudy]</code> <p>List of DicomStudy objects for this patient.</p> <code>common_metadata</code> <code>dict[str, Any]</code> <p>Metadata tags identical across all studies.</p> Source code in <code>pictologics/utilities/dicom_database.py</code> <pre><code>@dataclass\nclass DicomPatient:\n    \"\"\"Represents a DICOM patient containing multiple studies.\n\n    Attributes:\n        patient_id: Patient identifier.\n        patients_name: Patient's name.\n        patients_birth_date: Patient's birth date.\n        patients_sex: Patient's sex.\n        studies: List of DicomStudy objects for this patient.\n        common_metadata: Metadata tags identical across all studies.\n    \"\"\"\n\n    patient_id: str\n    patients_name: Optional[str] = None\n    patients_birth_date: Optional[str] = None\n    patients_sex: Optional[str] = None\n    studies: list[DicomStudy] = field(default_factory=list)\n    common_metadata: dict[str, Any] = field(default_factory=dict)\n\n    def get_instance_uids(self) -&gt; list[str]:\n        \"\"\"Get list of all instance SOPInstanceUIDs for this patient.\"\"\"\n        uids = []\n        for study in self.studies:\n            uids.extend(study.get_instance_uids())\n        return uids\n\n    def get_file_paths(self) -&gt; list[str]:\n        \"\"\"Get list of all instance file paths for this patient.\"\"\"\n        paths = []\n        for study in self.studies:\n            paths.extend(study.get_file_paths())\n        return paths\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_database.DicomPatient.get_file_paths","title":"<code>get_file_paths()</code>","text":"<p>Get list of all instance file paths for this patient.</p> Source code in <code>pictologics/utilities/dicom_database.py</code> <pre><code>def get_file_paths(self) -&gt; list[str]:\n    \"\"\"Get list of all instance file paths for this patient.\"\"\"\n    paths = []\n    for study in self.studies:\n        paths.extend(study.get_file_paths())\n    return paths\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_database.DicomPatient.get_instance_uids","title":"<code>get_instance_uids()</code>","text":"<p>Get list of all instance SOPInstanceUIDs for this patient.</p> Source code in <code>pictologics/utilities/dicom_database.py</code> <pre><code>def get_instance_uids(self) -&gt; list[str]:\n    \"\"\"Get list of all instance SOPInstanceUIDs for this patient.\"\"\"\n    uids = []\n    for study in self.studies:\n        uids.extend(study.get_instance_uids())\n    return uids\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_database.DicomDatabase","title":"<code>DicomDatabase</code>  <code>dataclass</code>","text":"<p>Top-level database containing all patients.</p> <p>This class provides the main interface for building a DICOM database from folders and exporting to various formats.</p> <p>Attributes:</p> Name Type Description <code>patients</code> <code>list[DicomPatient]</code> <p>List of DicomPatient objects.</p> <code>spacing_tolerance</code> <code>float</code> <p>Tolerance for gap detection in completeness checks.</p> Source code in <code>pictologics/utilities/dicom_database.py</code> <pre><code>@dataclass\nclass DicomDatabase:\n    \"\"\"Top-level database containing all patients.\n\n    This class provides the main interface for building a DICOM database\n    from folders and exporting to various formats.\n\n    Attributes:\n        patients: List of DicomPatient objects.\n        spacing_tolerance: Tolerance for gap detection in completeness checks.\n    \"\"\"\n\n    patients: list[DicomPatient] = field(default_factory=list)\n    spacing_tolerance: float = 0.1\n\n    @classmethod\n    def from_folders(\n        cls,\n        paths: list[str | Path],\n        recursive: bool = True,\n        spacing_tolerance: float = 0.1,\n        show_progress: bool = True,\n        extract_private_tags: bool = True,\n        num_workers: Optional[int] = None,\n        split_multiseries: bool = True,\n    ) -&gt; \"DicomDatabase\":\n        \"\"\"Build a database from folder paths.\n\n        Args:\n            paths: List of folder paths to scan.\n            recursive: Whether to scan subdirectories.\n            spacing_tolerance: Tolerance for gap detection (default 10%).\n            show_progress: Whether to display progress bars.\n            extract_private_tags: Whether to extract vendor-specific private tags.\n            num_workers: Number of parallel workers. None=auto (cpu_count-1),\n                        1=sequential (no multiprocessing).\n            split_multiseries: Whether to split multi-phase series (e.g. cardiac)\n                              into separate series based on tags or spatial duplicates.\n\n        Returns:\n            DicomDatabase instance populated with all discovered DICOM files.\n        \"\"\"\n        # Convert paths to Path objects\n        path_objs = [Path(p) for p in paths]\n\n        # Determine number of workers\n        workers = _get_num_workers(num_workers)\n\n        # Step 1: Discover all DICOM files\n        dicom_files = _scan_dicom_files(path_objs, recursive, show_progress, workers)\n\n        if not dicom_files:\n            return cls(patients=[], spacing_tolerance=spacing_tolerance)\n\n        # Step 2: Extract metadata from each file (parallel if workers &gt; 1)\n        file_metadata = _extract_all_metadata(\n            dicom_files, show_progress, extract_private_tags, workers\n        )\n\n        # Step 3: Build hierarchy from flat metadata list\n        patients = _build_hierarchy(file_metadata, spacing_tolerance, split_multiseries)\n\n        # Step 4: Sort the hierarchy for consistent output\n        patients = _sort_hierarchy(patients)\n\n        return cls(patients=patients, spacing_tolerance=spacing_tolerance)\n\n    # ========================================================================\n    # DataFrame Export Methods\n    # ========================================================================\n\n    def get_patients_df(self, include_instance_lists: bool = False) -&gt; pd.DataFrame:\n        \"\"\"Export patient-level summary DataFrame.\n\n        Args:\n            include_instance_lists: Whether to include InstanceSOPUIDs and\n                InstanceFilePaths columns. Defaults to False to reduce memory.\n\n        Returns:\n            DataFrame with patient information and aggregated statistics.\n        \"\"\"\n        rows = []\n        for patient in self.patients:\n            row: Dict[str, Any] = {\n                \"PatientID\": patient.patient_id,\n                \"PatientsName\": patient.patients_name,\n                \"PatientsBirthDate\": patient.patients_birth_date,\n                \"PatientsSex\": patient.patients_sex,\n                \"NumStudies\": len(patient.studies),\n                \"NumSeries\": sum(len(study.series) for study in patient.studies),\n                \"NumInstances\": sum(\n                    len(series.instances)\n                    for study in patient.studies\n                    for series in study.series\n                ),\n            }\n            if include_instance_lists:\n                row[\"InstanceSOPUIDs\"] = patient.get_instance_uids()\n                row[\"InstanceFilePaths\"] = patient.get_file_paths()\n\n            # Add study date range\n            study_dates = [\n                study.study_date for study in patient.studies if study.study_date\n            ]\n            if study_dates:\n                row[\"EarliestStudyDate\"] = min(study_dates)\n                row[\"LatestStudyDate\"] = max(study_dates)\n            else:\n                row[\"EarliestStudyDate\"] = None\n                row[\"LatestStudyDate\"] = None\n\n            # Add common metadata from patient level\n            for key, value in patient.common_metadata.items():\n                if key not in row:\n                    row[key] = value\n\n            rows.append(row)\n\n        return pd.DataFrame(rows)\n\n    def get_studies_df(\n        self,\n        patient_id: Optional[str] = None,\n        include_instance_lists: bool = False,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Export study-level summary DataFrame.\n\n        Args:\n            patient_id: Optional filter by patient ID.\n            include_instance_lists: Whether to include InstanceSOPUIDs and\n                InstanceFilePaths columns. Defaults to False to reduce memory.\n\n        Returns:\n            DataFrame with study information.\n        \"\"\"\n        rows = []\n        for patient in self.patients:\n            if patient_id and patient.patient_id != patient_id:\n                continue\n\n            for study in patient.studies:\n                row: Dict[str, Any] = {\n                    # Patient info\n                    \"PatientID\": patient.patient_id,\n                    \"PatientsName\": patient.patients_name,\n                    \"PatientsBirthDate\": patient.patients_birth_date,\n                    \"PatientsSex\": patient.patients_sex,\n                    # Study info\n                    \"StudyInstanceUID\": study.study_instance_uid,\n                    \"StudyDate\": study.study_date,\n                    \"StudyTime\": study.study_time,\n                    \"StudyDescription\": study.study_description,\n                    \"NumSeries\": len(study.series),\n                    \"NumInstances\": sum(\n                        len(series.instances) for series in study.series\n                    ),\n                }\n                if include_instance_lists:\n                    row[\"InstanceSOPUIDs\"] = study.get_instance_uids()\n                    row[\"InstanceFilePaths\"] = study.get_file_paths()\n\n                # Collect modalities present\n                modalities = list(set(s.modality for s in study.series if s.modality))\n                row[\"ModalitiesPresent\"] = modalities\n\n                # Add common metadata\n                for key, value in patient.common_metadata.items():\n                    if key not in row:\n                        row[key] = value\n                for key, value in study.common_metadata.items():\n                    if key not in row:\n                        row[key] = value\n\n                rows.append(row)\n\n        return pd.DataFrame(rows)\n\n    def get_series_df(\n        self,\n        patient_id: Optional[str] = None,\n        study_uid: Optional[str] = None,\n        include_instance_lists: bool = False,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Export series-level summary DataFrame with completeness info.\n\n        Args:\n            patient_id: Optional filter by patient ID.\n            study_uid: Optional filter by study UID.\n            include_instance_lists: Whether to include InstanceSOPUIDs and\n                InstanceFilePaths columns. Defaults to False to reduce memory.\n\n        Returns:\n            DataFrame with series information including completeness validation.\n        \"\"\"\n        rows = []\n        for patient in self.patients:\n            if patient_id and patient.patient_id != patient_id:\n                continue\n\n            for study in patient.studies:\n                if study_uid and study.study_instance_uid != study_uid:\n                    continue\n\n                for series in study.series:\n                    completeness = series.check_completeness(self.spacing_tolerance)\n\n                    row = {\n                        # Patient info\n                        \"PatientID\": patient.patient_id,\n                        \"PatientsName\": patient.patients_name,\n                        # Study info\n                        \"StudyInstanceUID\": study.study_instance_uid,\n                        \"StudyDate\": study.study_date,\n                        \"StudyDescription\": study.study_description,\n                        # Series info\n                        \"SeriesInstanceUID\": series.series_instance_uid,\n                        \"SeriesNumber\": series.series_number,\n                        \"SeriesDescription\": series.series_description,\n                        \"Modality\": series.modality,\n                        \"FrameOfReferenceUID\": series.frame_of_reference_uid,\n                        # Completeness\n                        \"NumInstances\": completeness[\"total_instances\"],\n                        \"ExpectedInstances\": completeness[\"expected_instances\"],\n                        \"IsComplete\": completeness[\"is_complete\"],\n                        \"HasGaps\": completeness[\"has_gaps\"],\n                        \"GapIndices\": completeness[\"gap_indices\"],\n                        \"SpacingMM\": completeness[\"spacing_mm\"],\n                        \"SpacingUniform\": completeness[\"spacing_uniform\"],\n                        \"FirstSlicePosition\": completeness[\"first_slice_position\"],\n                        \"LastSlicePosition\": completeness[\"last_slice_position\"],\n                        \"CompletenessWarnings\": completeness[\"warnings\"],\n                    }\n                    if include_instance_lists:\n                        row[\"InstanceSOPUIDs\"] = series.get_instance_uids()\n                        row[\"InstanceFilePaths\"] = series.get_file_paths()\n\n                    # Add common metadata from all levels\n                    for key, value in patient.common_metadata.items():\n                        if key not in row:\n                            row[key] = value\n                    for key, value in study.common_metadata.items():\n                        if key not in row:\n                            row[key] = value\n                    for key, value in series.common_metadata.items():\n                        if key not in row:\n                            row[key] = value\n\n                    rows.append(row)\n\n        return pd.DataFrame(rows)\n\n    def get_instances_df(\n        self,\n        patient_id: Optional[str] = None,\n        study_uid: Optional[str] = None,\n        series_uid: Optional[str] = None,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Export instance-level detail DataFrame.\n\n        Args:\n            patient_id: Optional filter by patient ID.\n            study_uid: Optional filter by study UID.\n            series_uid: Optional filter by series UID.\n\n        Returns:\n            DataFrame with complete instance information.\n        \"\"\"\n        rows = []\n        for patient in self.patients:\n            if patient_id and patient.patient_id != patient_id:\n                continue\n\n            for study in patient.studies:\n                if study_uid and study.study_instance_uid != study_uid:\n                    continue\n\n                for series in study.series:\n                    if series_uid and series.series_instance_uid != series_uid:\n                        continue\n\n                    for instance in series.instances:\n                        row: dict[str, Any] = {\n                            # Hierarchy IDs\n                            \"PatientID\": patient.patient_id,\n                            \"StudyInstanceUID\": study.study_instance_uid,\n                            \"SeriesInstanceUID\": series.series_instance_uid,\n                            \"SOPInstanceUID\": instance.sop_instance_uid,\n                            # Instance info\n                            \"FilePath\": str(instance.file_path),\n                            \"InstanceNumber\": instance.instance_number,\n                            \"SliceLocation\": instance.slice_location,\n                            \"ProjectionScore\": instance.projection_score,\n                            \"AcquisitionDateTime\": instance.acquisition_datetime,\n                        }\n\n                        # Image position\n                        if instance.image_position_patient:\n                            row[\"ImagePositionPatient_X\"] = (\n                                instance.image_position_patient[0]\n                            )\n                            row[\"ImagePositionPatient_Y\"] = (\n                                instance.image_position_patient[1]\n                            )\n                            row[\"ImagePositionPatient_Z\"] = (\n                                instance.image_position_patient[2]\n                            )\n                        else:\n                            row[\"ImagePositionPatient_X\"] = None\n                            row[\"ImagePositionPatient_Y\"] = None\n                            row[\"ImagePositionPatient_Z\"] = None\n\n                        # Image orientation\n                        row[\"ImageOrientationPatient\"] = (\n                            instance.image_orientation_patient\n                        )\n\n                        # Add parent-level metadata\n                        row[\"PatientsName\"] = patient.patients_name\n                        row[\"StudyDate\"] = study.study_date\n                        row[\"StudyDescription\"] = study.study_description\n                        row[\"SeriesNumber\"] = series.series_number\n                        row[\"SeriesDescription\"] = series.series_description\n                        row[\"Modality\"] = series.modality\n\n                        # Add instance-specific metadata\n                        for key, value in instance.metadata.items():\n                            if key not in row:\n                                row[key] = value\n\n                        rows.append(row)\n\n        return pd.DataFrame(rows)\n\n    # ========================================================================\n    # Export Methods\n    # ========================================================================\n\n    def export_csv(\n        self,\n        base_path: str,\n        levels: Optional[list[str]] = None,\n        include_instance_lists: bool = False,\n    ) -&gt; dict[str, str]:\n        \"\"\"Export DataFrames to separate CSV files.\n\n        Args:\n            base_path: Base path for output files (without extension).\n            levels: List of levels to export ('patients', 'studies', 'series',\n                   'instances'). Defaults to all levels.\n            include_instance_lists: Whether to include InstanceSOPUIDs and\n                InstanceFilePaths columns. Defaults to False to reduce file size.\n\n        Returns:\n            Dictionary mapping level names to created file paths.\n        \"\"\"\n        if levels is None:\n            levels = [\"patients\", \"studies\", \"series\", \"instances\"]\n\n        created_files = {}\n\n        for level in levels:\n            if level == \"patients\":\n                df = self.get_patients_df(include_instance_lists=include_instance_lists)\n            elif level == \"studies\":\n                df = self.get_studies_df(include_instance_lists=include_instance_lists)\n            elif level == \"series\":\n                df = self.get_series_df(include_instance_lists=include_instance_lists)\n            elif level == \"instances\":\n                df = self.get_instances_df()\n            else:\n                continue\n\n            file_path = f\"{base_path}_{level}.csv\"\n            # Convert list columns to JSON strings for CSV compatibility\n            for col in df.columns:\n                if df[col].apply(lambda x: isinstance(x, list)).any():\n                    df[col] = df[col].apply(\n                        lambda x: json.dumps(x) if isinstance(x, list) else x\n                    )\n            df.to_csv(file_path, index=False)\n            created_files[level] = file_path\n\n        return created_files\n\n    def export_json(\n        self,\n        json_path: str,\n        include_instance_lists: bool = True,\n    ) -&gt; str:\n        \"\"\"Export full hierarchy to JSON.\n\n        Args:\n            json_path: Path for the output JSON file.\n            include_instance_lists: Whether to include per-instance file paths\n                in the JSON output. Defaults to True for full export.\n\n        Returns:\n            Path to the created file.\n        \"\"\"\n        data: dict[str, list[Any]] = {\"patients\": []}\n\n        for patient in self.patients:\n            patient_dict: dict[str, Any] = {\n                \"patient_id\": patient.patient_id,\n                \"patients_name\": patient.patients_name,\n                \"patients_birth_date\": patient.patients_birth_date,\n                \"patients_sex\": patient.patients_sex,\n                \"common_metadata\": patient.common_metadata,\n                \"studies\": [],\n            }\n            if include_instance_lists:\n                patient_dict[\"instance_uids\"] = patient.get_instance_uids()\n                patient_dict[\"file_paths\"] = patient.get_file_paths()\n\n            for study in patient.studies:\n                study_dict: dict[str, Any] = {\n                    \"study_instance_uid\": study.study_instance_uid,\n                    \"study_date\": study.study_date,\n                    \"study_time\": study.study_time,\n                    \"study_description\": study.study_description,\n                    \"common_metadata\": study.common_metadata,\n                    \"series\": [],\n                }\n\n                for series in study.series:\n                    completeness = series.check_completeness(self.spacing_tolerance)\n                    series_dict: dict[str, Any] = {\n                        \"series_instance_uid\": series.series_instance_uid,\n                        \"series_number\": series.series_number,\n                        \"series_description\": series.series_description,\n                        \"modality\": series.modality,\n                        \"frame_of_reference_uid\": series.frame_of_reference_uid,\n                        \"common_metadata\": series.common_metadata,\n                        \"completeness\": completeness,\n                        \"instances\": [],\n                    }\n\n                    for instance in series.instances:\n                        instance_dict: dict[str, Any] = {\n                            \"sop_instance_uid\": instance.sop_instance_uid,\n                            \"instance_number\": instance.instance_number,\n                            \"image_position_patient\": instance.image_position_patient,\n                            \"slice_location\": instance.slice_location,\n                            \"projection_score\": instance.projection_score,\n                            \"metadata\": instance.metadata,\n                        }\n                        if include_instance_lists:\n                            instance_dict[\"file_path\"] = str(instance.file_path)\n                        series_dict[\"instances\"].append(instance_dict)\n\n                    study_dict[\"series\"].append(series_dict)\n\n                patient_dict[\"studies\"].append(study_dict)\n\n            data[\"patients\"].append(patient_dict)\n\n        with open(json_path, \"w\") as f:\n            json.dump(data, f, indent=2, default=str)\n\n        return json_path\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_database.DicomDatabase.export_csv","title":"<code>export_csv(base_path, levels=None, include_instance_lists=False)</code>","text":"<p>Export DataFrames to separate CSV files.</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>Base path for output files (without extension).</p> required <code>levels</code> <code>Optional[list[str]]</code> <p>List of levels to export ('patients', 'studies', 'series',    'instances'). Defaults to all levels.</p> <code>None</code> <code>include_instance_lists</code> <code>bool</code> <p>Whether to include InstanceSOPUIDs and InstanceFilePaths columns. Defaults to False to reduce file size.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dictionary mapping level names to created file paths.</p> Source code in <code>pictologics/utilities/dicom_database.py</code> <pre><code>def export_csv(\n    self,\n    base_path: str,\n    levels: Optional[list[str]] = None,\n    include_instance_lists: bool = False,\n) -&gt; dict[str, str]:\n    \"\"\"Export DataFrames to separate CSV files.\n\n    Args:\n        base_path: Base path for output files (without extension).\n        levels: List of levels to export ('patients', 'studies', 'series',\n               'instances'). Defaults to all levels.\n        include_instance_lists: Whether to include InstanceSOPUIDs and\n            InstanceFilePaths columns. Defaults to False to reduce file size.\n\n    Returns:\n        Dictionary mapping level names to created file paths.\n    \"\"\"\n    if levels is None:\n        levels = [\"patients\", \"studies\", \"series\", \"instances\"]\n\n    created_files = {}\n\n    for level in levels:\n        if level == \"patients\":\n            df = self.get_patients_df(include_instance_lists=include_instance_lists)\n        elif level == \"studies\":\n            df = self.get_studies_df(include_instance_lists=include_instance_lists)\n        elif level == \"series\":\n            df = self.get_series_df(include_instance_lists=include_instance_lists)\n        elif level == \"instances\":\n            df = self.get_instances_df()\n        else:\n            continue\n\n        file_path = f\"{base_path}_{level}.csv\"\n        # Convert list columns to JSON strings for CSV compatibility\n        for col in df.columns:\n            if df[col].apply(lambda x: isinstance(x, list)).any():\n                df[col] = df[col].apply(\n                    lambda x: json.dumps(x) if isinstance(x, list) else x\n                )\n        df.to_csv(file_path, index=False)\n        created_files[level] = file_path\n\n    return created_files\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_database.DicomDatabase.export_json","title":"<code>export_json(json_path, include_instance_lists=True)</code>","text":"<p>Export full hierarchy to JSON.</p> <p>Parameters:</p> Name Type Description Default <code>json_path</code> <code>str</code> <p>Path for the output JSON file.</p> required <code>include_instance_lists</code> <code>bool</code> <p>Whether to include per-instance file paths in the JSON output. Defaults to True for full export.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>Path to the created file.</p> Source code in <code>pictologics/utilities/dicom_database.py</code> <pre><code>def export_json(\n    self,\n    json_path: str,\n    include_instance_lists: bool = True,\n) -&gt; str:\n    \"\"\"Export full hierarchy to JSON.\n\n    Args:\n        json_path: Path for the output JSON file.\n        include_instance_lists: Whether to include per-instance file paths\n            in the JSON output. Defaults to True for full export.\n\n    Returns:\n        Path to the created file.\n    \"\"\"\n    data: dict[str, list[Any]] = {\"patients\": []}\n\n    for patient in self.patients:\n        patient_dict: dict[str, Any] = {\n            \"patient_id\": patient.patient_id,\n            \"patients_name\": patient.patients_name,\n            \"patients_birth_date\": patient.patients_birth_date,\n            \"patients_sex\": patient.patients_sex,\n            \"common_metadata\": patient.common_metadata,\n            \"studies\": [],\n        }\n        if include_instance_lists:\n            patient_dict[\"instance_uids\"] = patient.get_instance_uids()\n            patient_dict[\"file_paths\"] = patient.get_file_paths()\n\n        for study in patient.studies:\n            study_dict: dict[str, Any] = {\n                \"study_instance_uid\": study.study_instance_uid,\n                \"study_date\": study.study_date,\n                \"study_time\": study.study_time,\n                \"study_description\": study.study_description,\n                \"common_metadata\": study.common_metadata,\n                \"series\": [],\n            }\n\n            for series in study.series:\n                completeness = series.check_completeness(self.spacing_tolerance)\n                series_dict: dict[str, Any] = {\n                    \"series_instance_uid\": series.series_instance_uid,\n                    \"series_number\": series.series_number,\n                    \"series_description\": series.series_description,\n                    \"modality\": series.modality,\n                    \"frame_of_reference_uid\": series.frame_of_reference_uid,\n                    \"common_metadata\": series.common_metadata,\n                    \"completeness\": completeness,\n                    \"instances\": [],\n                }\n\n                for instance in series.instances:\n                    instance_dict: dict[str, Any] = {\n                        \"sop_instance_uid\": instance.sop_instance_uid,\n                        \"instance_number\": instance.instance_number,\n                        \"image_position_patient\": instance.image_position_patient,\n                        \"slice_location\": instance.slice_location,\n                        \"projection_score\": instance.projection_score,\n                        \"metadata\": instance.metadata,\n                    }\n                    if include_instance_lists:\n                        instance_dict[\"file_path\"] = str(instance.file_path)\n                    series_dict[\"instances\"].append(instance_dict)\n\n                study_dict[\"series\"].append(series_dict)\n\n            patient_dict[\"studies\"].append(study_dict)\n\n        data[\"patients\"].append(patient_dict)\n\n    with open(json_path, \"w\") as f:\n        json.dump(data, f, indent=2, default=str)\n\n    return json_path\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_database.DicomDatabase.from_folders","title":"<code>from_folders(paths, recursive=True, spacing_tolerance=0.1, show_progress=True, extract_private_tags=True, num_workers=None, split_multiseries=True)</code>  <code>classmethod</code>","text":"<p>Build a database from folder paths.</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>list[str | Path]</code> <p>List of folder paths to scan.</p> required <code>recursive</code> <code>bool</code> <p>Whether to scan subdirectories.</p> <code>True</code> <code>spacing_tolerance</code> <code>float</code> <p>Tolerance for gap detection (default 10%).</p> <code>0.1</code> <code>show_progress</code> <code>bool</code> <p>Whether to display progress bars.</p> <code>True</code> <code>extract_private_tags</code> <code>bool</code> <p>Whether to extract vendor-specific private tags.</p> <code>True</code> <code>num_workers</code> <code>Optional[int]</code> <p>Number of parallel workers. None=auto (cpu_count-1),         1=sequential (no multiprocessing).</p> <code>None</code> <code>split_multiseries</code> <code>bool</code> <p>Whether to split multi-phase series (e.g. cardiac)               into separate series based on tags or spatial duplicates.</p> <code>True</code> <p>Returns:</p> Type Description <code>'DicomDatabase'</code> <p>DicomDatabase instance populated with all discovered DICOM files.</p> Source code in <code>pictologics/utilities/dicom_database.py</code> <pre><code>@classmethod\ndef from_folders(\n    cls,\n    paths: list[str | Path],\n    recursive: bool = True,\n    spacing_tolerance: float = 0.1,\n    show_progress: bool = True,\n    extract_private_tags: bool = True,\n    num_workers: Optional[int] = None,\n    split_multiseries: bool = True,\n) -&gt; \"DicomDatabase\":\n    \"\"\"Build a database from folder paths.\n\n    Args:\n        paths: List of folder paths to scan.\n        recursive: Whether to scan subdirectories.\n        spacing_tolerance: Tolerance for gap detection (default 10%).\n        show_progress: Whether to display progress bars.\n        extract_private_tags: Whether to extract vendor-specific private tags.\n        num_workers: Number of parallel workers. None=auto (cpu_count-1),\n                    1=sequential (no multiprocessing).\n        split_multiseries: Whether to split multi-phase series (e.g. cardiac)\n                          into separate series based on tags or spatial duplicates.\n\n    Returns:\n        DicomDatabase instance populated with all discovered DICOM files.\n    \"\"\"\n    # Convert paths to Path objects\n    path_objs = [Path(p) for p in paths]\n\n    # Determine number of workers\n    workers = _get_num_workers(num_workers)\n\n    # Step 1: Discover all DICOM files\n    dicom_files = _scan_dicom_files(path_objs, recursive, show_progress, workers)\n\n    if not dicom_files:\n        return cls(patients=[], spacing_tolerance=spacing_tolerance)\n\n    # Step 2: Extract metadata from each file (parallel if workers &gt; 1)\n    file_metadata = _extract_all_metadata(\n        dicom_files, show_progress, extract_private_tags, workers\n    )\n\n    # Step 3: Build hierarchy from flat metadata list\n    patients = _build_hierarchy(file_metadata, spacing_tolerance, split_multiseries)\n\n    # Step 4: Sort the hierarchy for consistent output\n    patients = _sort_hierarchy(patients)\n\n    return cls(patients=patients, spacing_tolerance=spacing_tolerance)\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_database.DicomDatabase.get_instances_df","title":"<code>get_instances_df(patient_id=None, study_uid=None, series_uid=None)</code>","text":"<p>Export instance-level detail DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>patient_id</code> <code>Optional[str]</code> <p>Optional filter by patient ID.</p> <code>None</code> <code>study_uid</code> <code>Optional[str]</code> <p>Optional filter by study UID.</p> <code>None</code> <code>series_uid</code> <code>Optional[str]</code> <p>Optional filter by series UID.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with complete instance information.</p> Source code in <code>pictologics/utilities/dicom_database.py</code> <pre><code>def get_instances_df(\n    self,\n    patient_id: Optional[str] = None,\n    study_uid: Optional[str] = None,\n    series_uid: Optional[str] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"Export instance-level detail DataFrame.\n\n    Args:\n        patient_id: Optional filter by patient ID.\n        study_uid: Optional filter by study UID.\n        series_uid: Optional filter by series UID.\n\n    Returns:\n        DataFrame with complete instance information.\n    \"\"\"\n    rows = []\n    for patient in self.patients:\n        if patient_id and patient.patient_id != patient_id:\n            continue\n\n        for study in patient.studies:\n            if study_uid and study.study_instance_uid != study_uid:\n                continue\n\n            for series in study.series:\n                if series_uid and series.series_instance_uid != series_uid:\n                    continue\n\n                for instance in series.instances:\n                    row: dict[str, Any] = {\n                        # Hierarchy IDs\n                        \"PatientID\": patient.patient_id,\n                        \"StudyInstanceUID\": study.study_instance_uid,\n                        \"SeriesInstanceUID\": series.series_instance_uid,\n                        \"SOPInstanceUID\": instance.sop_instance_uid,\n                        # Instance info\n                        \"FilePath\": str(instance.file_path),\n                        \"InstanceNumber\": instance.instance_number,\n                        \"SliceLocation\": instance.slice_location,\n                        \"ProjectionScore\": instance.projection_score,\n                        \"AcquisitionDateTime\": instance.acquisition_datetime,\n                    }\n\n                    # Image position\n                    if instance.image_position_patient:\n                        row[\"ImagePositionPatient_X\"] = (\n                            instance.image_position_patient[0]\n                        )\n                        row[\"ImagePositionPatient_Y\"] = (\n                            instance.image_position_patient[1]\n                        )\n                        row[\"ImagePositionPatient_Z\"] = (\n                            instance.image_position_patient[2]\n                        )\n                    else:\n                        row[\"ImagePositionPatient_X\"] = None\n                        row[\"ImagePositionPatient_Y\"] = None\n                        row[\"ImagePositionPatient_Z\"] = None\n\n                    # Image orientation\n                    row[\"ImageOrientationPatient\"] = (\n                        instance.image_orientation_patient\n                    )\n\n                    # Add parent-level metadata\n                    row[\"PatientsName\"] = patient.patients_name\n                    row[\"StudyDate\"] = study.study_date\n                    row[\"StudyDescription\"] = study.study_description\n                    row[\"SeriesNumber\"] = series.series_number\n                    row[\"SeriesDescription\"] = series.series_description\n                    row[\"Modality\"] = series.modality\n\n                    # Add instance-specific metadata\n                    for key, value in instance.metadata.items():\n                        if key not in row:\n                            row[key] = value\n\n                    rows.append(row)\n\n    return pd.DataFrame(rows)\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_database.DicomDatabase.get_patients_df","title":"<code>get_patients_df(include_instance_lists=False)</code>","text":"<p>Export patient-level summary DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>include_instance_lists</code> <code>bool</code> <p>Whether to include InstanceSOPUIDs and InstanceFilePaths columns. Defaults to False to reduce memory.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with patient information and aggregated statistics.</p> Source code in <code>pictologics/utilities/dicom_database.py</code> <pre><code>def get_patients_df(self, include_instance_lists: bool = False) -&gt; pd.DataFrame:\n    \"\"\"Export patient-level summary DataFrame.\n\n    Args:\n        include_instance_lists: Whether to include InstanceSOPUIDs and\n            InstanceFilePaths columns. Defaults to False to reduce memory.\n\n    Returns:\n        DataFrame with patient information and aggregated statistics.\n    \"\"\"\n    rows = []\n    for patient in self.patients:\n        row: Dict[str, Any] = {\n            \"PatientID\": patient.patient_id,\n            \"PatientsName\": patient.patients_name,\n            \"PatientsBirthDate\": patient.patients_birth_date,\n            \"PatientsSex\": patient.patients_sex,\n            \"NumStudies\": len(patient.studies),\n            \"NumSeries\": sum(len(study.series) for study in patient.studies),\n            \"NumInstances\": sum(\n                len(series.instances)\n                for study in patient.studies\n                for series in study.series\n            ),\n        }\n        if include_instance_lists:\n            row[\"InstanceSOPUIDs\"] = patient.get_instance_uids()\n            row[\"InstanceFilePaths\"] = patient.get_file_paths()\n\n        # Add study date range\n        study_dates = [\n            study.study_date for study in patient.studies if study.study_date\n        ]\n        if study_dates:\n            row[\"EarliestStudyDate\"] = min(study_dates)\n            row[\"LatestStudyDate\"] = max(study_dates)\n        else:\n            row[\"EarliestStudyDate\"] = None\n            row[\"LatestStudyDate\"] = None\n\n        # Add common metadata from patient level\n        for key, value in patient.common_metadata.items():\n            if key not in row:\n                row[key] = value\n\n        rows.append(row)\n\n    return pd.DataFrame(rows)\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_database.DicomDatabase.get_series_df","title":"<code>get_series_df(patient_id=None, study_uid=None, include_instance_lists=False)</code>","text":"<p>Export series-level summary DataFrame with completeness info.</p> <p>Parameters:</p> Name Type Description Default <code>patient_id</code> <code>Optional[str]</code> <p>Optional filter by patient ID.</p> <code>None</code> <code>study_uid</code> <code>Optional[str]</code> <p>Optional filter by study UID.</p> <code>None</code> <code>include_instance_lists</code> <code>bool</code> <p>Whether to include InstanceSOPUIDs and InstanceFilePaths columns. Defaults to False to reduce memory.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with series information including completeness validation.</p> Source code in <code>pictologics/utilities/dicom_database.py</code> <pre><code>def get_series_df(\n    self,\n    patient_id: Optional[str] = None,\n    study_uid: Optional[str] = None,\n    include_instance_lists: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"Export series-level summary DataFrame with completeness info.\n\n    Args:\n        patient_id: Optional filter by patient ID.\n        study_uid: Optional filter by study UID.\n        include_instance_lists: Whether to include InstanceSOPUIDs and\n            InstanceFilePaths columns. Defaults to False to reduce memory.\n\n    Returns:\n        DataFrame with series information including completeness validation.\n    \"\"\"\n    rows = []\n    for patient in self.patients:\n        if patient_id and patient.patient_id != patient_id:\n            continue\n\n        for study in patient.studies:\n            if study_uid and study.study_instance_uid != study_uid:\n                continue\n\n            for series in study.series:\n                completeness = series.check_completeness(self.spacing_tolerance)\n\n                row = {\n                    # Patient info\n                    \"PatientID\": patient.patient_id,\n                    \"PatientsName\": patient.patients_name,\n                    # Study info\n                    \"StudyInstanceUID\": study.study_instance_uid,\n                    \"StudyDate\": study.study_date,\n                    \"StudyDescription\": study.study_description,\n                    # Series info\n                    \"SeriesInstanceUID\": series.series_instance_uid,\n                    \"SeriesNumber\": series.series_number,\n                    \"SeriesDescription\": series.series_description,\n                    \"Modality\": series.modality,\n                    \"FrameOfReferenceUID\": series.frame_of_reference_uid,\n                    # Completeness\n                    \"NumInstances\": completeness[\"total_instances\"],\n                    \"ExpectedInstances\": completeness[\"expected_instances\"],\n                    \"IsComplete\": completeness[\"is_complete\"],\n                    \"HasGaps\": completeness[\"has_gaps\"],\n                    \"GapIndices\": completeness[\"gap_indices\"],\n                    \"SpacingMM\": completeness[\"spacing_mm\"],\n                    \"SpacingUniform\": completeness[\"spacing_uniform\"],\n                    \"FirstSlicePosition\": completeness[\"first_slice_position\"],\n                    \"LastSlicePosition\": completeness[\"last_slice_position\"],\n                    \"CompletenessWarnings\": completeness[\"warnings\"],\n                }\n                if include_instance_lists:\n                    row[\"InstanceSOPUIDs\"] = series.get_instance_uids()\n                    row[\"InstanceFilePaths\"] = series.get_file_paths()\n\n                # Add common metadata from all levels\n                for key, value in patient.common_metadata.items():\n                    if key not in row:\n                        row[key] = value\n                for key, value in study.common_metadata.items():\n                    if key not in row:\n                        row[key] = value\n                for key, value in series.common_metadata.items():\n                    if key not in row:\n                        row[key] = value\n\n                rows.append(row)\n\n    return pd.DataFrame(rows)\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_database.DicomDatabase.get_studies_df","title":"<code>get_studies_df(patient_id=None, include_instance_lists=False)</code>","text":"<p>Export study-level summary DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>patient_id</code> <code>Optional[str]</code> <p>Optional filter by patient ID.</p> <code>None</code> <code>include_instance_lists</code> <code>bool</code> <p>Whether to include InstanceSOPUIDs and InstanceFilePaths columns. Defaults to False to reduce memory.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with study information.</p> Source code in <code>pictologics/utilities/dicom_database.py</code> <pre><code>def get_studies_df(\n    self,\n    patient_id: Optional[str] = None,\n    include_instance_lists: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"Export study-level summary DataFrame.\n\n    Args:\n        patient_id: Optional filter by patient ID.\n        include_instance_lists: Whether to include InstanceSOPUIDs and\n            InstanceFilePaths columns. Defaults to False to reduce memory.\n\n    Returns:\n        DataFrame with study information.\n    \"\"\"\n    rows = []\n    for patient in self.patients:\n        if patient_id and patient.patient_id != patient_id:\n            continue\n\n        for study in patient.studies:\n            row: Dict[str, Any] = {\n                # Patient info\n                \"PatientID\": patient.patient_id,\n                \"PatientsName\": patient.patients_name,\n                \"PatientsBirthDate\": patient.patients_birth_date,\n                \"PatientsSex\": patient.patients_sex,\n                # Study info\n                \"StudyInstanceUID\": study.study_instance_uid,\n                \"StudyDate\": study.study_date,\n                \"StudyTime\": study.study_time,\n                \"StudyDescription\": study.study_description,\n                \"NumSeries\": len(study.series),\n                \"NumInstances\": sum(\n                    len(series.instances) for series in study.series\n                ),\n            }\n            if include_instance_lists:\n                row[\"InstanceSOPUIDs\"] = study.get_instance_uids()\n                row[\"InstanceFilePaths\"] = study.get_file_paths()\n\n            # Collect modalities present\n            modalities = list(set(s.modality for s in study.series if s.modality))\n            row[\"ModalitiesPresent\"] = modalities\n\n            # Add common metadata\n            for key, value in patient.common_metadata.items():\n                if key not in row:\n                    row[key] = value\n            for key, value in study.common_metadata.items():\n                if key not in row:\n                    row[key] = value\n\n            rows.append(row)\n\n    return pd.DataFrame(rows)\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_utils","title":"<code>pictologics.utilities.dicom_utils</code>","text":"<p>DICOM Utility Functions.</p> <p>This module provides shared utility functions for working with DICOM files, including multi-phase series detection and splitting logic used by both the DicomDatabase and the image loader.</p>"},{"location":"api/utilities/#pictologics.utilities.dicom_utils.DicomPhaseInfo","title":"<code>DicomPhaseInfo</code>  <code>dataclass</code>","text":"<p>Information about a detected phase in a DICOM series.</p> <p>Attributes:</p> Name Type Description <code>index</code> <code>int</code> <p>Zero-based index of this phase.</p> <code>num_slices</code> <code>int</code> <p>Number of slices/instances in this phase.</p> <code>file_paths</code> <code>list[Path]</code> <p>List of file paths belonging to this phase.</p> <code>label</code> <code>Optional[str]</code> <p>Human-readable label (e.g., \"Phase 0%\", \"Echo 1\").</p> <code>split_tag</code> <code>Optional[str]</code> <p>The DICOM tag used to detect this phase, or \"spatial\" if detected via duplicate positions.</p> <code>split_value</code> <code>Optional[Any]</code> <p>The value of the split tag for this phase.</p> Source code in <code>pictologics/utilities/dicom_utils.py</code> <pre><code>@dataclass\nclass DicomPhaseInfo:\n    \"\"\"Information about a detected phase in a DICOM series.\n\n    Attributes:\n        index: Zero-based index of this phase.\n        num_slices: Number of slices/instances in this phase.\n        file_paths: List of file paths belonging to this phase.\n        label: Human-readable label (e.g., \"Phase 0%\", \"Echo 1\").\n        split_tag: The DICOM tag used to detect this phase, or \"spatial\"\n            if detected via duplicate positions.\n        split_value: The value of the split tag for this phase.\n    \"\"\"\n\n    index: int\n    num_slices: int\n    file_paths: list[Path]\n    label: Optional[str] = None\n    split_tag: Optional[str] = None\n    split_value: Optional[Any] = None\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_utils.get_dicom_phases","title":"<code>get_dicom_phases(path, recursive=False)</code>","text":"<p>Discover phases in a DICOM series directory.</p> <p>Scans a directory for DICOM files and detects if the series contains multiple phases (e.g., cardiac phases, temporal positions, echo numbers). This is useful before calling <code>load_image()</code> with a specific <code>dataset_index</code>.</p> <p>Multi-phase detection uses the same logic as :class:<code>DicomDatabase</code> to ensure consistent behavior across the library.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to directory containing DICOM files.</p> required <code>recursive</code> <code>bool</code> <p>If True, recursively searches subdirectories. Default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[DicomPhaseInfo]</code> <p>List of :class:<code>DicomPhaseInfo</code> objects describing each detected phase.</p> <code>list[DicomPhaseInfo]</code> <p>For single-phase series, returns a list with one element.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the path does not exist.</p> <code>ValueError</code> <p>If no DICOM files are found.</p> <p>Examples:</p> <p>Discover phases before loading:</p> <pre><code>&gt;&gt;&gt; from pictologics.utilities import get_dicom_phases\n&gt;&gt;&gt; from pictologics import load_image\n&gt;&gt;&gt;\n&gt;&gt;&gt; phases = get_dicom_phases(\"cardiac_ct/\")\n&gt;&gt;&gt; print(f\"Found {len(phases)} phases:\")\n&gt;&gt;&gt; for phase in phases:\n...     print(f\"  Phase {phase.index}: {phase.num_slices} slices - {phase.label}\")\nFound 10 phases:\n  Phase 0: 64 slices - Phase 0%\n  Phase 1: 64 slices - Phase 10%\n  ...\n</code></pre> <p>Load a specific phase:</p> <pre><code>&gt;&gt;&gt; # Load the 5th phase (40%)\n&gt;&gt;&gt; img = load_image(\"cardiac_ct/\", dataset_index=4)\n</code></pre> <p>Check if series is multi-phase:</p> <pre><code>&gt;&gt;&gt; phases = get_dicom_phases(\"ct_scan/\")\n&gt;&gt;&gt; if len(phases) &gt; 1:\n...     print(\"Multi-phase series detected!\")\n... else:\n...     print(\"Single-phase series\")\n</code></pre> See Also <ul> <li>:func:<code>load_image</code>: Main image loading function with <code>dataset_index</code> support.</li> <li>:class:<code>DicomDatabase</code>: Full DICOM database parsing with automatic phase splitting.</li> </ul> Source code in <code>pictologics/utilities/dicom_utils.py</code> <pre><code>def get_dicom_phases(\n    path: str,\n    recursive: bool = False,\n) -&gt; list[DicomPhaseInfo]:\n    \"\"\"Discover phases in a DICOM series directory.\n\n    Scans a directory for DICOM files and detects if the series contains\n    multiple phases (e.g., cardiac phases, temporal positions, echo numbers).\n    This is useful before calling ``load_image()`` with a specific ``dataset_index``.\n\n    Multi-phase detection uses the same logic as :class:`DicomDatabase` to ensure\n    consistent behavior across the library.\n\n    Args:\n        path: Path to directory containing DICOM files.\n        recursive: If True, recursively searches subdirectories. Default False.\n\n    Returns:\n        List of :class:`DicomPhaseInfo` objects describing each detected phase.\n        For single-phase series, returns a list with one element.\n\n    Raises:\n        FileNotFoundError: If the path does not exist.\n        ValueError: If no DICOM files are found.\n\n    Examples:\n        Discover phases before loading:\n\n        &gt;&gt;&gt; from pictologics.utilities import get_dicom_phases\n        &gt;&gt;&gt; from pictologics import load_image\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; phases = get_dicom_phases(\"cardiac_ct/\")\n        &gt;&gt;&gt; print(f\"Found {len(phases)} phases:\")\n        &gt;&gt;&gt; for phase in phases:\n        ...     print(f\"  Phase {phase.index}: {phase.num_slices} slices - {phase.label}\")\n        Found 10 phases:\n          Phase 0: 64 slices - Phase 0%\n          Phase 1: 64 slices - Phase 10%\n          ...\n\n        Load a specific phase:\n\n        &gt;&gt;&gt; # Load the 5th phase (40%)\n        &gt;&gt;&gt; img = load_image(\"cardiac_ct/\", dataset_index=4)\n\n        Check if series is multi-phase:\n\n        &gt;&gt;&gt; phases = get_dicom_phases(\"ct_scan/\")\n        &gt;&gt;&gt; if len(phases) &gt; 1:\n        ...     print(\"Multi-phase series detected!\")\n        ... else:\n        ...     print(\"Single-phase series\")\n\n    See Also:\n        - :func:`load_image`: Main image loading function with ``dataset_index`` support.\n        - :class:`DicomDatabase`: Full DICOM database parsing with automatic phase splitting.\n    \"\"\"\n    path_obj = Path(path)\n    if not path_obj.exists():\n        raise FileNotFoundError(f\"Path does not exist: {path}\")\n\n    # Collect DICOM files\n    if path_obj.is_file():\n        if pydicom.misc.is_dicom(path_obj):\n            dicom_files = [path_obj]\n        else:\n            raise ValueError(f\"File is not a DICOM file: {path}\")\n    else:\n        if recursive:\n            candidates = list(path_obj.rglob(\"*\"))\n        else:\n            candidates = list(path_obj.iterdir())\n\n        dicom_files = [\n            f for f in candidates if f.is_file() and pydicom.misc.is_dicom(f)\n        ]\n\n    if not dicom_files:\n        raise ValueError(f\"No DICOM files found in: {path}\")\n\n    # Extract metadata for phase detection\n    file_metadata: list[dict[str, Any]] = []\n    for f in dicom_files:\n        try:\n            dcm = pydicom.dcmread(f, stop_before_pixels=True)\n            meta: dict[str, Any] = {\n                \"file_path\": f,\n                \"InstanceNumber\": getattr(dcm, \"InstanceNumber\", None),\n            }\n\n            # Extract position\n            try:\n                ipp = dcm.ImagePositionPatient\n                meta[\"ImagePositionPatient\"] = (\n                    float(ipp[0]),\n                    float(ipp[1]),\n                    float(ipp[2]),\n                )\n            except (AttributeError, IndexError, TypeError):\n                meta[\"ImagePositionPatient\"] = None\n\n            # Extract multi-phase tags\n            for tag in MULTI_PHASE_TAGS:\n                val = getattr(dcm, tag, None)\n                if val is not None:\n                    meta[tag] = val\n\n            file_metadata.append(meta)\n        except Exception:\n            continue\n\n    if not file_metadata:\n        raise ValueError(f\"Could not read any DICOM files from: {path}\")\n\n    # Split into phases\n    phases = split_dicom_phases(file_metadata)\n\n    # Determine which tag was used for splitting\n    split_tag = None\n    if len(phases) &gt; 1:\n        # Check which tag has different values across phases\n        for tag in MULTI_PHASE_TAGS:\n            first_val = phases[0][0].get(tag) if phases[0] else None\n            if first_val is not None:\n                # Check if other phases have different values\n                for phase in phases[1:]:\n                    if phase and phase[0].get(tag) != first_val:\n                        split_tag = tag\n                        break\n            if split_tag:\n                break\n        if not split_tag:\n            split_tag = \"spatial\"  # Fallback was used\n\n    # Build DicomPhaseInfo objects\n    result: list[DicomPhaseInfo] = []\n    for i, phase_meta in enumerate(phases):\n        file_paths = [m[\"file_path\"] for m in phase_meta]\n        split_value = phase_meta[0].get(split_tag) if split_tag and phase_meta else None\n\n        # Generate label\n        if split_tag == \"NominalPercentageOfCardiacPhase\":\n            label = f\"Phase {split_value}%\" if split_value is not None else f\"Phase {i}\"\n        elif split_tag == \"TemporalPositionIdentifier\":\n            label = (\n                f\"Temporal {split_value}\" if split_value is not None else f\"Time {i}\"\n            )\n        elif split_tag == \"EchoNumber\":\n            label = f\"Echo {split_value}\" if split_value is not None else f\"Echo {i}\"\n        elif split_tag == \"AcquisitionNumber\":\n            label = (\n                f\"Acquisition {split_value}\" if split_value is not None else f\"Acq {i}\"\n            )\n        elif split_tag == \"TriggerTime\":\n            label = (\n                f\"Trigger {split_value}ms\"\n                if split_value is not None\n                else f\"Trigger {i}\"\n            )\n        elif split_tag == \"spatial\":\n            label = f\"Volume {i + 1}\"\n        else:\n            label = f\"Dataset {i}\"\n\n        result.append(\n            DicomPhaseInfo(\n                index=i,\n                num_slices=len(file_paths),\n                file_paths=file_paths,\n                label=label,\n                split_tag=split_tag,\n                split_value=split_value,\n            )\n        )\n\n    return result\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.dicom_utils.split_dicom_phases","title":"<code>split_dicom_phases(file_metadata)</code>","text":"<p>Split DICOM file metadata into multiple phases/groups.</p> <p>This function detects multi-phase DICOM series (e.g., cardiac phases, multi-echo, dynamic contrast) and splits them into separate groups.</p> <p>The detection strategy is: 1. Check for distinctive DICOM tags (CardiacPhase, TemporalPosition, etc.)    If a tag has &gt;1 unique value, use it to group files. 2. Fallback: Check for duplicate spatial positions (ImagePositionPatient).    If duplicates exist, group by order of appearance.</p> <p>Parameters:</p> Name Type Description Default <code>file_metadata</code> <code>list[dict[str, Any]]</code> <p>List of dictionaries containing at minimum: - 'file_path': Path to the DICOM file - 'ImagePositionPatient': Optional tuple of (x, y, z) - Any of the MULTI_PHASE_TAGS (optional)</p> required <p>Returns:</p> Type Description <code>list[list[dict[str, Any]]]</code> <p>List of lists, where each inner list contains metadata dicts</p> <code>list[list[dict[str, Any]]]</code> <p>for one phase. Single-phase series return [[all_metadata]].</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; metadata = [{'file_path': Path('slice1.dcm'), 'CardiacPhase': 0}, ...]\n&gt;&gt;&gt; phases = split_dicom_phases(metadata)\n&gt;&gt;&gt; print(f\"Found {len(phases)} phases\")\n</code></pre> Source code in <code>pictologics/utilities/dicom_utils.py</code> <pre><code>def split_dicom_phases(\n    file_metadata: list[dict[str, Any]],\n) -&gt; list[list[dict[str, Any]]]:\n    \"\"\"Split DICOM file metadata into multiple phases/groups.\n\n    This function detects multi-phase DICOM series (e.g., cardiac phases,\n    multi-echo, dynamic contrast) and splits them into separate groups.\n\n    The detection strategy is:\n    1. Check for distinctive DICOM tags (CardiacPhase, TemporalPosition, etc.)\n       If a tag has &gt;1 unique value, use it to group files.\n    2. Fallback: Check for duplicate spatial positions (ImagePositionPatient).\n       If duplicates exist, group by order of appearance.\n\n    Args:\n        file_metadata: List of dictionaries containing at minimum:\n            - 'file_path': Path to the DICOM file\n            - 'ImagePositionPatient': Optional tuple of (x, y, z)\n            - Any of the MULTI_PHASE_TAGS (optional)\n\n    Returns:\n        List of lists, where each inner list contains metadata dicts\n        for one phase. Single-phase series return [[all_metadata]].\n\n    Examples:\n        &gt;&gt;&gt; metadata = [{'file_path': Path('slice1.dcm'), 'CardiacPhase': 0}, ...]\n        &gt;&gt;&gt; phases = split_dicom_phases(metadata)\n        &gt;&gt;&gt; print(f\"Found {len(phases)} phases\")\n    \"\"\"\n    if len(file_metadata) &lt; 2:\n        return [file_metadata]\n\n    # 1. Try splitting by multi-phase tags\n    for tag in MULTI_PHASE_TAGS:\n        values: dict[Any, list[dict[str, Any]]] = {}\n        for meta in file_metadata:\n            val = meta.get(tag)\n            if val is not None:\n                values.setdefault(val, []).append(meta)\n\n        # If we have multiple groups and covered all files\n        if len(values) &gt; 1:\n            total_grouped = sum(len(g) for g in values.values())\n            if total_grouped == len(file_metadata):\n                # Sort groups by tag value\n                sorted_keys = sorted(values.keys())\n                return [values[k] for k in sorted_keys]\n\n    # 2. Fallback: Spatial duplication check\n    pos_map: dict[tuple[float, float, float], list[dict[str, Any]]] = {}\n    for meta in file_metadata:\n        pos = meta.get(\"ImagePositionPatient\")\n        if pos:\n            pos_tuple = tuple(pos) if isinstance(pos, (list, tuple)) else pos\n            pos_map.setdefault(pos_tuple, []).append(meta)\n\n    # Check if we have duplicates (any position has &gt;1 instance)\n    if any(len(g) &gt; 1 for g in pos_map.values()):\n        num_phases = max(len(g) for g in pos_map.values())\n        phase_groups: list[list[dict[str, Any]]] = [[] for _ in range(num_phases)]\n\n        # Sort by instance number for consistency\n        sorted_metadata = sorted(\n            file_metadata,\n            key=lambda x: x.get(\"InstanceNumber\", 0) or 0,\n        )\n\n        # Re-map with sorted metadata\n        pos_map_sorted: dict[tuple[float, float, float], list[dict[str, Any]]] = {}\n        for meta in sorted_metadata:\n            pos = meta.get(\"ImagePositionPatient\")\n            if pos:\n                pos_tuple = tuple(pos) if isinstance(pos, (list, tuple)) else pos\n                pos_map_sorted.setdefault(pos_tuple, []).append(meta)\n            else:\n                phase_groups[0].append(meta)\n\n        # Distribute duplicates across phases\n        for _, metas in pos_map_sorted.items():\n            for i, meta in enumerate(metas):\n                if i &lt; num_phases:\n                    phase_groups[i].append(meta)\n                else:\n                    phase_groups[-1].append(meta)  # pragma: no cover\n\n        # Filter empty groups\n        return [g for g in phase_groups if g]\n\n    return [file_metadata]\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.sr_parser","title":"<code>pictologics.utilities.sr_parser</code>","text":""},{"location":"api/utilities/#pictologics.utilities.sr_parser--dicom-structured-report-sr-parser","title":"DICOM Structured Report (SR) Parser","text":"<p>This module provides functionality for parsing DICOM Structured Reports (SR) and extracting measurement data into structured formats (DataFrames, CSV, JSON).</p> <p>Supports TID1500 (Measurement Report) and other common SR templates. Uses highdicom for robust SR parsing and content extraction.</p>"},{"location":"api/utilities/#pictologics.utilities.sr_parser.SRMeasurement","title":"<code>SRMeasurement</code>  <code>dataclass</code>","text":"<p>Represents a single measurement from an SR document.</p> <p>This dataclass captures individual measurement values extracted from DICOM Structured Reports, including the measurement name, value, units, and associated context.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Measurement concept name (e.g., \"Agatston Score\", \"Volume\").</p> <code>value</code> <code>float</code> <p>Numerical measurement value.</p> <code>unit</code> <code>str</code> <p>Unit of measurement (e.g., \"mm\", \"HU\", \"1\" for unitless).</p> <code>finding_type</code> <code>Optional[str]</code> <p>Type of finding this measurement relates to (optional).</p> <code>finding_site</code> <code>Optional[str]</code> <p>Anatomical site of finding (optional).</p> <code>derivation</code> <code>Optional[str]</code> <p>How the measurement was derived (optional).</p> <code>tracking_id</code> <code>Optional[str]</code> <p>Optional tracking identifier for longitudinal studies.</p> <code>metadata</code> <code>dict[str, Any]</code> <p>Additional extracted attributes not captured above.</p> Source code in <code>pictologics/utilities/sr_parser.py</code> <pre><code>@dataclass\nclass SRMeasurement:\n    \"\"\"Represents a single measurement from an SR document.\n\n    This dataclass captures individual measurement values extracted from\n    DICOM Structured Reports, including the measurement name, value,\n    units, and associated context.\n\n    Attributes:\n        name: Measurement concept name (e.g., \"Agatston Score\", \"Volume\").\n        value: Numerical measurement value.\n        unit: Unit of measurement (e.g., \"mm\", \"HU\", \"1\" for unitless).\n        finding_type: Type of finding this measurement relates to (optional).\n        finding_site: Anatomical site of finding (optional).\n        derivation: How the measurement was derived (optional).\n        tracking_id: Optional tracking identifier for longitudinal studies.\n        metadata: Additional extracted attributes not captured above.\n    \"\"\"\n\n    name: str\n    value: float\n    unit: str\n    finding_type: Optional[str] = None\n    finding_site: Optional[str] = None\n    derivation: Optional[str] = None\n    tracking_id: Optional[str] = None\n    metadata: dict[str, Any] = field(default_factory=dict)\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.sr_parser.SRMeasurementGroup","title":"<code>SRMeasurementGroup</code>  <code>dataclass</code>","text":"<p>Represents a group of related measurements.</p> <p>SR documents often organize measurements into groups based on anatomical site, finding type, or other criteria. This dataclass captures such groupings.</p> <p>Attributes:</p> Name Type Description <code>group_id</code> <code>Optional[str]</code> <p>Identifier for this measurement group (optional).</p> <code>finding_type</code> <code>Optional[str]</code> <p>Type of finding for this group (optional).</p> <code>finding_site</code> <code>Optional[str]</code> <p>Anatomical site for this group (optional).</p> <code>measurements</code> <code>list[SRMeasurement]</code> <p>List of SRMeasurement objects in this group.</p> <code>metadata</code> <code>dict[str, Any]</code> <p>Additional group-level attributes.</p> Source code in <code>pictologics/utilities/sr_parser.py</code> <pre><code>@dataclass\nclass SRMeasurementGroup:\n    \"\"\"Represents a group of related measurements.\n\n    SR documents often organize measurements into groups based on\n    anatomical site, finding type, or other criteria. This dataclass\n    captures such groupings.\n\n    Attributes:\n        group_id: Identifier for this measurement group (optional).\n        finding_type: Type of finding for this group (optional).\n        finding_site: Anatomical site for this group (optional).\n        measurements: List of SRMeasurement objects in this group.\n        metadata: Additional group-level attributes.\n    \"\"\"\n\n    group_id: Optional[str] = None\n    finding_type: Optional[str] = None\n    finding_site: Optional[str] = None\n    measurements: list[SRMeasurement] = field(default_factory=list)\n    metadata: dict[str, Any] = field(default_factory=dict)\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.sr_parser.SRDocument","title":"<code>SRDocument</code>  <code>dataclass</code>","text":"<p>Represents a parsed DICOM Structured Report.</p> <p>This class provides the main interface for accessing SR content, following the same pattern as DicomDatabase. It can be constructed from a file using the <code>from_file()</code> class method.</p> <p>Attributes:</p> Name Type Description <code>file_path</code> <code>Path</code> <p>Path to the source SR file.</p> <code>sop_instance_uid</code> <code>str</code> <p>Unique identifier for this SR instance.</p> <code>template_id</code> <code>Optional[str]</code> <p>SR template identifier (e.g., \"1500\" for TID1500).</p> <code>document_title</code> <code>Optional[str]</code> <p>Title of the SR document.</p> <code>measurement_groups</code> <code>list[SRMeasurementGroup]</code> <p>List of SRMeasurementGroup objects.</p> <code>patient_id</code> <code>Optional[str]</code> <p>Patient identifier.</p> <code>study_instance_uid</code> <code>Optional[str]</code> <p>Study UID.</p> <code>series_instance_uid</code> <code>Optional[str]</code> <p>Series UID.</p> <code>content_datetime</code> <code>Optional[str]</code> <p>When the SR was created.</p> <code>metadata</code> <code>dict[str, Any]</code> <p>Additional document-level attributes.</p> <p>Examples:</p> <p>Load and parse an SR document:</p> <pre><code>&gt;&gt;&gt; sr = SRDocument.from_file(\"measurements.dcm\")\n&gt;&gt;&gt; print(f\"Template: {sr.template_id}\")\n&gt;&gt;&gt; print(f\"Groups: {len(sr.measurement_groups)}\")\n</code></pre> <p>Export measurements to DataFrame:</p> <pre><code>&gt;&gt;&gt; df = sr.get_measurements_df()\n&gt;&gt;&gt; print(df[[\"measurement_name\", \"value\", \"unit\"]])\n</code></pre> <p>Export to CSV:</p> <pre><code>&gt;&gt;&gt; sr.export_csv(\"measurements.csv\")\n</code></pre> Source code in <code>pictologics/utilities/sr_parser.py</code> <pre><code>@dataclass\nclass SRDocument:\n    \"\"\"Represents a parsed DICOM Structured Report.\n\n    This class provides the main interface for accessing SR content,\n    following the same pattern as DicomDatabase. It can be constructed\n    from a file using the `from_file()` class method.\n\n    Attributes:\n        file_path: Path to the source SR file.\n        sop_instance_uid: Unique identifier for this SR instance.\n        template_id: SR template identifier (e.g., \"1500\" for TID1500).\n        document_title: Title of the SR document.\n        measurement_groups: List of SRMeasurementGroup objects.\n        patient_id: Patient identifier.\n        study_instance_uid: Study UID.\n        series_instance_uid: Series UID.\n        content_datetime: When the SR was created.\n        metadata: Additional document-level attributes.\n\n    Examples:\n        Load and parse an SR document:\n\n        &gt;&gt;&gt; sr = SRDocument.from_file(\"measurements.dcm\")\n        &gt;&gt;&gt; print(f\"Template: {sr.template_id}\")\n        &gt;&gt;&gt; print(f\"Groups: {len(sr.measurement_groups)}\")\n\n        Export measurements to DataFrame:\n\n        &gt;&gt;&gt; df = sr.get_measurements_df()\n        &gt;&gt;&gt; print(df[[\"measurement_name\", \"value\", \"unit\"]])\n\n        Export to CSV:\n\n        &gt;&gt;&gt; sr.export_csv(\"measurements.csv\")\n    \"\"\"\n\n    file_path: Path\n    sop_instance_uid: str\n    template_id: Optional[str] = None\n    document_title: Optional[str] = None\n    measurement_groups: list[SRMeasurementGroup] = field(default_factory=list)\n    patient_id: Optional[str] = None\n    study_instance_uid: Optional[str] = None\n    series_instance_uid: Optional[str] = None\n    content_datetime: Optional[str] = None\n    metadata: dict[str, Any] = field(default_factory=dict)\n\n    @classmethod\n    def from_file(\n        cls,\n        path: str | Path,\n        extract_private_tags: bool = False,\n    ) -&gt; \"SRDocument\":\n        \"\"\"Load and parse an SR document from file.\n\n        This method reads a DICOM Structured Report file and extracts\n        all measurement content into the hierarchical dataclass structure.\n        Follows the same pattern as DicomDatabase.from_folders().\n\n        Args:\n            path: Path to DICOM SR file.\n            extract_private_tags: Whether to extract vendor-specific tags\n                into the metadata dictionaries. Defaults to False.\n\n        Returns:\n            SRDocument instance with parsed content.\n\n        Raises:\n            FileNotFoundError: If the file does not exist.\n            ValueError: If the file is not a valid DICOM SR object.\n        \"\"\"\n        import pydicom\n\n        path_obj = Path(path)\n        if not path_obj.exists():\n            raise FileNotFoundError(f\"SR file not found: {path}\")\n\n        # Load the DICOM file\n        try:\n            dcm = pydicom.dcmread(str(path_obj))\n        except Exception as e:\n            raise ValueError(f\"Failed to read DICOM file: {e}\") from e\n\n        # Check if it's an SR document\n        sr_sop_classes = [\n            \"1.2.840.10008.5.1.4.1.1.88.11\",  # Basic Text SR\n            \"1.2.840.10008.5.1.4.1.1.88.22\",  # Enhanced SR\n            \"1.2.840.10008.5.1.4.1.1.88.33\",  # Comprehensive SR\n            \"1.2.840.10008.5.1.4.1.1.88.34\",  # Comprehensive 3D SR\n            \"1.2.840.10008.5.1.4.1.1.88.35\",  # Extensible SR\n            \"1.2.840.10008.5.1.4.1.1.88.40\",  # Procedure Log\n        ]\n        sop_class = str(getattr(dcm, \"SOPClassUID\", \"\"))\n        if sop_class not in sr_sop_classes:\n            raise ValueError(\n                f\"File is not a DICOM SR document. SOPClassUID: {sop_class}\"\n            )\n\n        # Extract basic document info\n        sop_instance_uid = str(getattr(dcm, \"SOPInstanceUID\", \"\"))\n        patient_id = str(getattr(dcm, \"PatientID\", \"\")) or None\n        study_uid = str(getattr(dcm, \"StudyInstanceUID\", \"\")) or None\n        series_uid = str(getattr(dcm, \"SeriesInstanceUID\", \"\")) or None\n\n        # Content datetime\n        content_date = getattr(dcm, \"ContentDate\", None)\n        content_time = getattr(dcm, \"ContentTime\", None)\n        if content_date:\n            content_datetime = str(content_date)\n            if content_time:\n                content_datetime += f\"T{content_time}\"\n        else:\n            content_datetime = None\n\n        # Extract document title from ConceptNameCodeSequence\n        doc_title = None\n        if hasattr(dcm, \"ConceptNameCodeSequence\") and dcm.ConceptNameCodeSequence:\n            concept = dcm.ConceptNameCodeSequence[0]\n            doc_title = str(getattr(concept, \"CodeMeaning\", \"\")) or None\n\n        # Extract template ID if present\n        template_id = None\n        if hasattr(dcm, \"ContentTemplateSequence\") and dcm.ContentTemplateSequence:\n            template = dcm.ContentTemplateSequence[0]\n            template_id = str(getattr(template, \"TemplateIdentifier\", \"\")) or None\n\n        # Parse content sequence for measurements\n        measurement_groups = _parse_content_sequence(dcm, extract_private_tags)\n\n        # Build metadata dict\n        metadata: dict[str, Any] = {}\n        if extract_private_tags:\n            # Extract any private tags\n            for elem in dcm:\n                if elem.tag.is_private:\n                    try:\n                        metadata[elem.keyword or str(elem.tag)] = str(elem.value)\n                    except Exception:\n                        pass\n\n        return cls(\n            file_path=path_obj,\n            sop_instance_uid=sop_instance_uid,\n            template_id=template_id,\n            document_title=doc_title,\n            measurement_groups=measurement_groups,\n            patient_id=patient_id,\n            study_instance_uid=study_uid,\n            series_instance_uid=series_uid,\n            content_datetime=content_datetime,\n            metadata=metadata,\n        )\n\n    def get_measurements_df(self) -&gt; pd.DataFrame:\n        \"\"\"Export all measurements as a DataFrame.\n\n        Returns a flat DataFrame with all measurements from all groups,\n        including group context for each measurement.\n\n        Returns:\n            DataFrame with columns:\n            - group_id: Identifier of the measurement group\n            - finding_type: Type of finding\n            - finding_site: Anatomical site\n            - measurement_name: Name of the measurement\n            - value: Numerical value\n            - unit: Unit of measurement\n            - derivation: How it was derived\n            - tracking_id: Tracking identifier\n        \"\"\"\n        rows = []\n        for group in self.measurement_groups:\n            for meas in group.measurements:\n                rows.append(\n                    {\n                        \"group_id\": group.group_id,\n                        \"finding_type\": group.finding_type or meas.finding_type,\n                        \"finding_site\": group.finding_site or meas.finding_site,\n                        \"measurement_name\": meas.name,\n                        \"value\": meas.value,\n                        \"unit\": meas.unit,\n                        \"derivation\": meas.derivation,\n                        \"tracking_id\": meas.tracking_id,\n                    }\n                )\n\n        return pd.DataFrame(rows)\n\n    def get_summary(self) -&gt; dict[str, Any]:\n        \"\"\"Get document summary without full parsing.\n\n        Returns:\n            Dictionary with summary information including:\n            - sop_instance_uid\n            - template_id\n            - document_title\n            - num_groups\n            - num_measurements\n            - patient_id\n            - study_instance_uid\n        \"\"\"\n        total_measurements = sum(len(g.measurements) for g in self.measurement_groups)\n        return {\n            \"sop_instance_uid\": self.sop_instance_uid,\n            \"template_id\": self.template_id,\n            \"document_title\": self.document_title,\n            \"num_groups\": len(self.measurement_groups),\n            \"num_measurements\": total_measurements,\n            \"patient_id\": self.patient_id,\n            \"study_instance_uid\": self.study_instance_uid,\n            \"content_datetime\": self.content_datetime,\n        }\n\n    def export_csv(self, path: str | Path) -&gt; Path:\n        \"\"\"Export measurements to CSV file.\n\n        Args:\n            path: Output path for the CSV file.\n\n        Returns:\n            Path to the created CSV file.\n        \"\"\"\n        path_obj = Path(path)\n        df = self.get_measurements_df()\n        df.to_csv(path_obj, index=False)\n        return path_obj\n\n    def export_json(self, path: str | Path) -&gt; Path:\n        \"\"\"Export full SR content to JSON.\n\n        Exports the complete document structure including all groups,\n        measurements, and metadata.\n\n        Args:\n            path: Output path for the JSON file.\n\n        Returns:\n            Path to the created JSON file.\n        \"\"\"\n        import json\n\n        path_obj = Path(path)\n\n        # Build JSON structure\n        data: dict[str, Any] = {\n            \"sop_instance_uid\": self.sop_instance_uid,\n            \"template_id\": self.template_id,\n            \"document_title\": self.document_title,\n            \"patient_id\": self.patient_id,\n            \"study_instance_uid\": self.study_instance_uid,\n            \"series_instance_uid\": self.series_instance_uid,\n            \"content_datetime\": self.content_datetime,\n            \"metadata\": self.metadata,\n            \"measurement_groups\": [],\n        }\n\n        for group in self.measurement_groups:\n            group_data: dict[str, Any] = {\n                \"group_id\": group.group_id,\n                \"finding_type\": group.finding_type,\n                \"finding_site\": group.finding_site,\n                \"metadata\": group.metadata,\n                \"measurements\": [],\n            }\n            for meas in group.measurements:\n                meas_data = {\n                    \"name\": meas.name,\n                    \"value\": meas.value,\n                    \"unit\": meas.unit,\n                    \"finding_type\": meas.finding_type,\n                    \"finding_site\": meas.finding_site,\n                    \"derivation\": meas.derivation,\n                    \"tracking_id\": meas.tracking_id,\n                    \"metadata\": meas.metadata,\n                }\n                group_data[\"measurements\"].append(meas_data)\n            data[\"measurement_groups\"].append(group_data)\n\n        with open(path_obj, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n        return path_obj\n\n    # ========================================================================\n    # Batch Processing (from_folders)\n    # ========================================================================\n\n    @classmethod\n    def from_folders(\n        cls,\n        paths: list[str | Path],\n        recursive: bool = True,\n        show_progress: bool = True,\n        num_workers: Optional[int] = None,\n        output_dir: Optional[str | Path] = None,\n        export_csv: bool = True,\n        export_json: bool = True,\n        extract_private_tags: bool = False,\n    ) -&gt; \"SRBatch\":\n        \"\"\"Batch process SR files from folders.\n\n        Scans directories for DICOM SR files, parses each one, and optionally\n        exports individual CSV/JSON files plus a combined output and log.\n\n        This method follows the same pattern as DicomDatabase.from_folders().\n\n        Args:\n            paths: List of folder paths to scan for SR files.\n            recursive: Whether to scan subdirectories (default: True).\n            show_progress: Whether to display progress bars (default: True).\n            num_workers: Number of parallel workers. None=auto (cpu_count-1),\n                        1=sequential (no multiprocessing).\n            output_dir: If specified, exports each SR to this directory.\n            export_csv: Export individual CSV files (default: True).\n            export_json: Export individual JSON files (default: True).\n            extract_private_tags: Whether to extract private tags (default: False).\n\n        Returns:\n            SRBatch containing all parsed documents and processing log.\n\n        Examples:\n            Process all SR files in a folder:\n\n            &gt;&gt;&gt; batch = SRDocument.from_folders([\"sr_data/\"])\n            &gt;&gt;&gt; print(f\"Found {len(batch.documents)} SR files\")\n            &gt;&gt;&gt; df = batch.get_combined_measurements_df()\n\n            Export each SR to individual files:\n\n            &gt;&gt;&gt; batch = SRDocument.from_folders(\n            ...     [\"sr_data/\"],\n            ...     output_dir=\"sr_exports/\",\n            ...     export_csv=True,\n            ...     export_json=True\n            ... )\n            &gt;&gt;&gt; batch.export_log(\"sr_exports/processing_log.csv\")\n        \"\"\"\n        import os\n        from concurrent.futures import ProcessPoolExecutor\n\n        from tqdm import tqdm\n\n        # Convert paths to Path objects\n        path_objs = [Path(p) for p in paths]\n\n        # Determine number of workers\n        if num_workers is None:\n            cpu_count = os.cpu_count()\n            num_workers = max(1, (cpu_count - 1) if cpu_count else 1)\n\n        # Step 1: Discover all SR files\n        sr_files: list[Path] = []\n        for path_obj in path_objs:\n            if not path_obj.exists():\n                continue\n            if path_obj.is_file():\n                if is_dicom_sr(path_obj):\n                    sr_files.append(path_obj)\n            else:\n                # Directory\n                iterator = path_obj.rglob(\"*\") if recursive else path_obj.iterdir()\n                for f in iterator:\n                    if f.is_file() and is_dicom_sr(f):\n                        sr_files.append(f)\n\n        if not sr_files:\n            return SRBatch(documents=[], processing_log=[], output_dir=None)\n\n        # Create output directory if specified\n        out_path = Path(output_dir) if output_dir else None\n        if out_path:\n            out_path.mkdir(parents=True, exist_ok=True)\n\n        # Step 2: Process each SR file\n        processing_log: list[dict[str, Any]] = []\n        documents: list[\"SRDocument\"] = []\n\n        # Prepare worker arguments\n        worker_args = [\n            (f, extract_private_tags, out_path, export_csv, export_json)\n            for f in sr_files\n        ]\n\n        if num_workers == 1:\n            # Sequential processing\n            iterator = tqdm(\n                worker_args, desc=\"Processing SR files\", disable=not show_progress\n            )\n            for args in iterator:\n                result = _process_sr_file_worker(args)\n                processing_log.append(result[\"log\"])\n                if result[\"document\"] is not None:\n                    documents.append(result[\"document\"])\n        else:\n            # Parallel processing\n            with ProcessPoolExecutor(max_workers=num_workers) as executor:\n                results = list(\n                    tqdm(\n                        executor.map(_process_sr_file_worker, worker_args),\n                        total=len(worker_args),\n                        desc=\"Processing SR files\",\n                        disable=not show_progress,\n                    )\n                )\n            for result in results:\n                processing_log.append(result[\"log\"])\n                if result[\"document\"] is not None:\n                    documents.append(result[\"document\"])  # pragma: no cover\n\n        return SRBatch(\n            documents=documents,\n            processing_log=processing_log,\n            output_dir=out_path,\n        )\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.sr_parser.SRDocument.export_csv","title":"<code>export_csv(path)</code>","text":"<p>Export measurements to CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Output path for the CSV file.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path to the created CSV file.</p> Source code in <code>pictologics/utilities/sr_parser.py</code> <pre><code>def export_csv(self, path: str | Path) -&gt; Path:\n    \"\"\"Export measurements to CSV file.\n\n    Args:\n        path: Output path for the CSV file.\n\n    Returns:\n        Path to the created CSV file.\n    \"\"\"\n    path_obj = Path(path)\n    df = self.get_measurements_df()\n    df.to_csv(path_obj, index=False)\n    return path_obj\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.sr_parser.SRDocument.export_json","title":"<code>export_json(path)</code>","text":"<p>Export full SR content to JSON.</p> <p>Exports the complete document structure including all groups, measurements, and metadata.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Output path for the JSON file.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path to the created JSON file.</p> Source code in <code>pictologics/utilities/sr_parser.py</code> <pre><code>def export_json(self, path: str | Path) -&gt; Path:\n    \"\"\"Export full SR content to JSON.\n\n    Exports the complete document structure including all groups,\n    measurements, and metadata.\n\n    Args:\n        path: Output path for the JSON file.\n\n    Returns:\n        Path to the created JSON file.\n    \"\"\"\n    import json\n\n    path_obj = Path(path)\n\n    # Build JSON structure\n    data: dict[str, Any] = {\n        \"sop_instance_uid\": self.sop_instance_uid,\n        \"template_id\": self.template_id,\n        \"document_title\": self.document_title,\n        \"patient_id\": self.patient_id,\n        \"study_instance_uid\": self.study_instance_uid,\n        \"series_instance_uid\": self.series_instance_uid,\n        \"content_datetime\": self.content_datetime,\n        \"metadata\": self.metadata,\n        \"measurement_groups\": [],\n    }\n\n    for group in self.measurement_groups:\n        group_data: dict[str, Any] = {\n            \"group_id\": group.group_id,\n            \"finding_type\": group.finding_type,\n            \"finding_site\": group.finding_site,\n            \"metadata\": group.metadata,\n            \"measurements\": [],\n        }\n        for meas in group.measurements:\n            meas_data = {\n                \"name\": meas.name,\n                \"value\": meas.value,\n                \"unit\": meas.unit,\n                \"finding_type\": meas.finding_type,\n                \"finding_site\": meas.finding_site,\n                \"derivation\": meas.derivation,\n                \"tracking_id\": meas.tracking_id,\n                \"metadata\": meas.metadata,\n            }\n            group_data[\"measurements\"].append(meas_data)\n        data[\"measurement_groups\"].append(group_data)\n\n    with open(path_obj, \"w\") as f:\n        json.dump(data, f, indent=2)\n\n    return path_obj\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.sr_parser.SRDocument.from_file","title":"<code>from_file(path, extract_private_tags=False)</code>  <code>classmethod</code>","text":"<p>Load and parse an SR document from file.</p> <p>This method reads a DICOM Structured Report file and extracts all measurement content into the hierarchical dataclass structure. Follows the same pattern as DicomDatabase.from_folders().</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to DICOM SR file.</p> required <code>extract_private_tags</code> <code>bool</code> <p>Whether to extract vendor-specific tags into the metadata dictionaries. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>'SRDocument'</code> <p>SRDocument instance with parsed content.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file does not exist.</p> <code>ValueError</code> <p>If the file is not a valid DICOM SR object.</p> Source code in <code>pictologics/utilities/sr_parser.py</code> <pre><code>@classmethod\ndef from_file(\n    cls,\n    path: str | Path,\n    extract_private_tags: bool = False,\n) -&gt; \"SRDocument\":\n    \"\"\"Load and parse an SR document from file.\n\n    This method reads a DICOM Structured Report file and extracts\n    all measurement content into the hierarchical dataclass structure.\n    Follows the same pattern as DicomDatabase.from_folders().\n\n    Args:\n        path: Path to DICOM SR file.\n        extract_private_tags: Whether to extract vendor-specific tags\n            into the metadata dictionaries. Defaults to False.\n\n    Returns:\n        SRDocument instance with parsed content.\n\n    Raises:\n        FileNotFoundError: If the file does not exist.\n        ValueError: If the file is not a valid DICOM SR object.\n    \"\"\"\n    import pydicom\n\n    path_obj = Path(path)\n    if not path_obj.exists():\n        raise FileNotFoundError(f\"SR file not found: {path}\")\n\n    # Load the DICOM file\n    try:\n        dcm = pydicom.dcmread(str(path_obj))\n    except Exception as e:\n        raise ValueError(f\"Failed to read DICOM file: {e}\") from e\n\n    # Check if it's an SR document\n    sr_sop_classes = [\n        \"1.2.840.10008.5.1.4.1.1.88.11\",  # Basic Text SR\n        \"1.2.840.10008.5.1.4.1.1.88.22\",  # Enhanced SR\n        \"1.2.840.10008.5.1.4.1.1.88.33\",  # Comprehensive SR\n        \"1.2.840.10008.5.1.4.1.1.88.34\",  # Comprehensive 3D SR\n        \"1.2.840.10008.5.1.4.1.1.88.35\",  # Extensible SR\n        \"1.2.840.10008.5.1.4.1.1.88.40\",  # Procedure Log\n    ]\n    sop_class = str(getattr(dcm, \"SOPClassUID\", \"\"))\n    if sop_class not in sr_sop_classes:\n        raise ValueError(\n            f\"File is not a DICOM SR document. SOPClassUID: {sop_class}\"\n        )\n\n    # Extract basic document info\n    sop_instance_uid = str(getattr(dcm, \"SOPInstanceUID\", \"\"))\n    patient_id = str(getattr(dcm, \"PatientID\", \"\")) or None\n    study_uid = str(getattr(dcm, \"StudyInstanceUID\", \"\")) or None\n    series_uid = str(getattr(dcm, \"SeriesInstanceUID\", \"\")) or None\n\n    # Content datetime\n    content_date = getattr(dcm, \"ContentDate\", None)\n    content_time = getattr(dcm, \"ContentTime\", None)\n    if content_date:\n        content_datetime = str(content_date)\n        if content_time:\n            content_datetime += f\"T{content_time}\"\n    else:\n        content_datetime = None\n\n    # Extract document title from ConceptNameCodeSequence\n    doc_title = None\n    if hasattr(dcm, \"ConceptNameCodeSequence\") and dcm.ConceptNameCodeSequence:\n        concept = dcm.ConceptNameCodeSequence[0]\n        doc_title = str(getattr(concept, \"CodeMeaning\", \"\")) or None\n\n    # Extract template ID if present\n    template_id = None\n    if hasattr(dcm, \"ContentTemplateSequence\") and dcm.ContentTemplateSequence:\n        template = dcm.ContentTemplateSequence[0]\n        template_id = str(getattr(template, \"TemplateIdentifier\", \"\")) or None\n\n    # Parse content sequence for measurements\n    measurement_groups = _parse_content_sequence(dcm, extract_private_tags)\n\n    # Build metadata dict\n    metadata: dict[str, Any] = {}\n    if extract_private_tags:\n        # Extract any private tags\n        for elem in dcm:\n            if elem.tag.is_private:\n                try:\n                    metadata[elem.keyword or str(elem.tag)] = str(elem.value)\n                except Exception:\n                    pass\n\n    return cls(\n        file_path=path_obj,\n        sop_instance_uid=sop_instance_uid,\n        template_id=template_id,\n        document_title=doc_title,\n        measurement_groups=measurement_groups,\n        patient_id=patient_id,\n        study_instance_uid=study_uid,\n        series_instance_uid=series_uid,\n        content_datetime=content_datetime,\n        metadata=metadata,\n    )\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.sr_parser.SRDocument.from_folders","title":"<code>from_folders(paths, recursive=True, show_progress=True, num_workers=None, output_dir=None, export_csv=True, export_json=True, extract_private_tags=False)</code>  <code>classmethod</code>","text":"<p>Batch process SR files from folders.</p> <p>Scans directories for DICOM SR files, parses each one, and optionally exports individual CSV/JSON files plus a combined output and log.</p> <p>This method follows the same pattern as DicomDatabase.from_folders().</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>list[str | Path]</code> <p>List of folder paths to scan for SR files.</p> required <code>recursive</code> <code>bool</code> <p>Whether to scan subdirectories (default: True).</p> <code>True</code> <code>show_progress</code> <code>bool</code> <p>Whether to display progress bars (default: True).</p> <code>True</code> <code>num_workers</code> <code>Optional[int]</code> <p>Number of parallel workers. None=auto (cpu_count-1),         1=sequential (no multiprocessing).</p> <code>None</code> <code>output_dir</code> <code>Optional[str | Path]</code> <p>If specified, exports each SR to this directory.</p> <code>None</code> <code>export_csv</code> <code>bool</code> <p>Export individual CSV files (default: True).</p> <code>True</code> <code>export_json</code> <code>bool</code> <p>Export individual JSON files (default: True).</p> <code>True</code> <code>extract_private_tags</code> <code>bool</code> <p>Whether to extract private tags (default: False).</p> <code>False</code> <p>Returns:</p> Type Description <code>'SRBatch'</code> <p>SRBatch containing all parsed documents and processing log.</p> <p>Examples:</p> <p>Process all SR files in a folder:</p> <pre><code>&gt;&gt;&gt; batch = SRDocument.from_folders([\"sr_data/\"])\n&gt;&gt;&gt; print(f\"Found {len(batch.documents)} SR files\")\n&gt;&gt;&gt; df = batch.get_combined_measurements_df()\n</code></pre> <p>Export each SR to individual files:</p> <pre><code>&gt;&gt;&gt; batch = SRDocument.from_folders(\n...     [\"sr_data/\"],\n...     output_dir=\"sr_exports/\",\n...     export_csv=True,\n...     export_json=True\n... )\n&gt;&gt;&gt; batch.export_log(\"sr_exports/processing_log.csv\")\n</code></pre> Source code in <code>pictologics/utilities/sr_parser.py</code> <pre><code>@classmethod\ndef from_folders(\n    cls,\n    paths: list[str | Path],\n    recursive: bool = True,\n    show_progress: bool = True,\n    num_workers: Optional[int] = None,\n    output_dir: Optional[str | Path] = None,\n    export_csv: bool = True,\n    export_json: bool = True,\n    extract_private_tags: bool = False,\n) -&gt; \"SRBatch\":\n    \"\"\"Batch process SR files from folders.\n\n    Scans directories for DICOM SR files, parses each one, and optionally\n    exports individual CSV/JSON files plus a combined output and log.\n\n    This method follows the same pattern as DicomDatabase.from_folders().\n\n    Args:\n        paths: List of folder paths to scan for SR files.\n        recursive: Whether to scan subdirectories (default: True).\n        show_progress: Whether to display progress bars (default: True).\n        num_workers: Number of parallel workers. None=auto (cpu_count-1),\n                    1=sequential (no multiprocessing).\n        output_dir: If specified, exports each SR to this directory.\n        export_csv: Export individual CSV files (default: True).\n        export_json: Export individual JSON files (default: True).\n        extract_private_tags: Whether to extract private tags (default: False).\n\n    Returns:\n        SRBatch containing all parsed documents and processing log.\n\n    Examples:\n        Process all SR files in a folder:\n\n        &gt;&gt;&gt; batch = SRDocument.from_folders([\"sr_data/\"])\n        &gt;&gt;&gt; print(f\"Found {len(batch.documents)} SR files\")\n        &gt;&gt;&gt; df = batch.get_combined_measurements_df()\n\n        Export each SR to individual files:\n\n        &gt;&gt;&gt; batch = SRDocument.from_folders(\n        ...     [\"sr_data/\"],\n        ...     output_dir=\"sr_exports/\",\n        ...     export_csv=True,\n        ...     export_json=True\n        ... )\n        &gt;&gt;&gt; batch.export_log(\"sr_exports/processing_log.csv\")\n    \"\"\"\n    import os\n    from concurrent.futures import ProcessPoolExecutor\n\n    from tqdm import tqdm\n\n    # Convert paths to Path objects\n    path_objs = [Path(p) for p in paths]\n\n    # Determine number of workers\n    if num_workers is None:\n        cpu_count = os.cpu_count()\n        num_workers = max(1, (cpu_count - 1) if cpu_count else 1)\n\n    # Step 1: Discover all SR files\n    sr_files: list[Path] = []\n    for path_obj in path_objs:\n        if not path_obj.exists():\n            continue\n        if path_obj.is_file():\n            if is_dicom_sr(path_obj):\n                sr_files.append(path_obj)\n        else:\n            # Directory\n            iterator = path_obj.rglob(\"*\") if recursive else path_obj.iterdir()\n            for f in iterator:\n                if f.is_file() and is_dicom_sr(f):\n                    sr_files.append(f)\n\n    if not sr_files:\n        return SRBatch(documents=[], processing_log=[], output_dir=None)\n\n    # Create output directory if specified\n    out_path = Path(output_dir) if output_dir else None\n    if out_path:\n        out_path.mkdir(parents=True, exist_ok=True)\n\n    # Step 2: Process each SR file\n    processing_log: list[dict[str, Any]] = []\n    documents: list[\"SRDocument\"] = []\n\n    # Prepare worker arguments\n    worker_args = [\n        (f, extract_private_tags, out_path, export_csv, export_json)\n        for f in sr_files\n    ]\n\n    if num_workers == 1:\n        # Sequential processing\n        iterator = tqdm(\n            worker_args, desc=\"Processing SR files\", disable=not show_progress\n        )\n        for args in iterator:\n            result = _process_sr_file_worker(args)\n            processing_log.append(result[\"log\"])\n            if result[\"document\"] is not None:\n                documents.append(result[\"document\"])\n    else:\n        # Parallel processing\n        with ProcessPoolExecutor(max_workers=num_workers) as executor:\n            results = list(\n                tqdm(\n                    executor.map(_process_sr_file_worker, worker_args),\n                    total=len(worker_args),\n                    desc=\"Processing SR files\",\n                    disable=not show_progress,\n                )\n            )\n        for result in results:\n            processing_log.append(result[\"log\"])\n            if result[\"document\"] is not None:\n                documents.append(result[\"document\"])  # pragma: no cover\n\n    return SRBatch(\n        documents=documents,\n        processing_log=processing_log,\n        output_dir=out_path,\n    )\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.sr_parser.SRDocument.get_measurements_df","title":"<code>get_measurements_df()</code>","text":"<p>Export all measurements as a DataFrame.</p> <p>Returns a flat DataFrame with all measurements from all groups, including group context for each measurement.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with columns:</p> <code>DataFrame</code> <ul> <li>group_id: Identifier of the measurement group</li> </ul> <code>DataFrame</code> <ul> <li>finding_type: Type of finding</li> </ul> <code>DataFrame</code> <ul> <li>finding_site: Anatomical site</li> </ul> <code>DataFrame</code> <ul> <li>measurement_name: Name of the measurement</li> </ul> <code>DataFrame</code> <ul> <li>value: Numerical value</li> </ul> <code>DataFrame</code> <ul> <li>unit: Unit of measurement</li> </ul> <code>DataFrame</code> <ul> <li>derivation: How it was derived</li> </ul> <code>DataFrame</code> <ul> <li>tracking_id: Tracking identifier</li> </ul> Source code in <code>pictologics/utilities/sr_parser.py</code> <pre><code>def get_measurements_df(self) -&gt; pd.DataFrame:\n    \"\"\"Export all measurements as a DataFrame.\n\n    Returns a flat DataFrame with all measurements from all groups,\n    including group context for each measurement.\n\n    Returns:\n        DataFrame with columns:\n        - group_id: Identifier of the measurement group\n        - finding_type: Type of finding\n        - finding_site: Anatomical site\n        - measurement_name: Name of the measurement\n        - value: Numerical value\n        - unit: Unit of measurement\n        - derivation: How it was derived\n        - tracking_id: Tracking identifier\n    \"\"\"\n    rows = []\n    for group in self.measurement_groups:\n        for meas in group.measurements:\n            rows.append(\n                {\n                    \"group_id\": group.group_id,\n                    \"finding_type\": group.finding_type or meas.finding_type,\n                    \"finding_site\": group.finding_site or meas.finding_site,\n                    \"measurement_name\": meas.name,\n                    \"value\": meas.value,\n                    \"unit\": meas.unit,\n                    \"derivation\": meas.derivation,\n                    \"tracking_id\": meas.tracking_id,\n                }\n            )\n\n    return pd.DataFrame(rows)\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.sr_parser.SRDocument.get_summary","title":"<code>get_summary()</code>","text":"<p>Get document summary without full parsing.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with summary information including:</p> <code>dict[str, Any]</code> <ul> <li>sop_instance_uid</li> </ul> <code>dict[str, Any]</code> <ul> <li>template_id</li> </ul> <code>dict[str, Any]</code> <ul> <li>document_title</li> </ul> <code>dict[str, Any]</code> <ul> <li>num_groups</li> </ul> <code>dict[str, Any]</code> <ul> <li>num_measurements</li> </ul> <code>dict[str, Any]</code> <ul> <li>patient_id</li> </ul> <code>dict[str, Any]</code> <ul> <li>study_instance_uid</li> </ul> Source code in <code>pictologics/utilities/sr_parser.py</code> <pre><code>def get_summary(self) -&gt; dict[str, Any]:\n    \"\"\"Get document summary without full parsing.\n\n    Returns:\n        Dictionary with summary information including:\n        - sop_instance_uid\n        - template_id\n        - document_title\n        - num_groups\n        - num_measurements\n        - patient_id\n        - study_instance_uid\n    \"\"\"\n    total_measurements = sum(len(g.measurements) for g in self.measurement_groups)\n    return {\n        \"sop_instance_uid\": self.sop_instance_uid,\n        \"template_id\": self.template_id,\n        \"document_title\": self.document_title,\n        \"num_groups\": len(self.measurement_groups),\n        \"num_measurements\": total_measurements,\n        \"patient_id\": self.patient_id,\n        \"study_instance_uid\": self.study_instance_uid,\n        \"content_datetime\": self.content_datetime,\n    }\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.sr_parser.SRBatch","title":"<code>SRBatch</code>  <code>dataclass</code>","text":"<p>Collection of parsed SR documents from batch processing.</p> <p>This class holds the results of batch SR processing via SRDocument.from_folders(). It provides access to all parsed documents and methods for combined exports.</p> <p>Attributes:</p> Name Type Description <code>documents</code> <code>list[SRDocument]</code> <p>List of successfully parsed SRDocument objects.</p> <code>processing_log</code> <code>list[dict[str, Any]]</code> <p>Log entries for each processed file (success/error).</p> <code>output_dir</code> <code>Optional[Path]</code> <p>Directory where individual exports were written.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; batch = SRDocument.from_folders([\"sr_data/\"], output_dir=\"exports/\")\n&gt;&gt;&gt; print(f\"Processed {len(batch.documents)} SR files\")\n&gt;&gt;&gt; df = batch.get_combined_measurements_df()\n&gt;&gt;&gt; batch.export_log(\"exports/processing_log.csv\")\n</code></pre> Source code in <code>pictologics/utilities/sr_parser.py</code> <pre><code>@dataclass\nclass SRBatch:\n    \"\"\"Collection of parsed SR documents from batch processing.\n\n    This class holds the results of batch SR processing via\n    SRDocument.from_folders(). It provides access to all parsed documents\n    and methods for combined exports.\n\n    Attributes:\n        documents: List of successfully parsed SRDocument objects.\n        processing_log: Log entries for each processed file (success/error).\n        output_dir: Directory where individual exports were written.\n\n    Examples:\n        &gt;&gt;&gt; batch = SRDocument.from_folders([\"sr_data/\"], output_dir=\"exports/\")\n        &gt;&gt;&gt; print(f\"Processed {len(batch.documents)} SR files\")\n        &gt;&gt;&gt; df = batch.get_combined_measurements_df()\n        &gt;&gt;&gt; batch.export_log(\"exports/processing_log.csv\")\n    \"\"\"\n\n    documents: list[SRDocument] = field(default_factory=list)\n    processing_log: list[dict[str, Any]] = field(default_factory=list)\n    output_dir: Optional[Path] = None\n\n    def get_combined_measurements_df(self) -&gt; pd.DataFrame:\n        \"\"\"Combine measurements from all documents into a single DataFrame.\n\n        Each measurement row includes the source document's SOP Instance UID,\n        patient ID, and study UID for traceability.\n\n        Returns:\n            DataFrame with all measurements from all documents.\n        \"\"\"\n        all_rows: list[dict[str, Any]] = []\n\n        for doc in self.documents:\n            for group in doc.measurement_groups:\n                for meas in group.measurements:\n                    all_rows.append(\n                        {\n                            \"sop_instance_uid\": doc.sop_instance_uid,\n                            \"patient_id\": doc.patient_id,\n                            \"study_instance_uid\": doc.study_instance_uid,\n                            \"group_finding_type\": group.finding_type,\n                            \"group_finding_site\": group.finding_site,\n                            \"measurement_name\": meas.name,\n                            \"value\": meas.value,\n                            \"unit\": meas.unit,\n                            \"finding_type\": meas.finding_type,\n                            \"finding_site\": meas.finding_site,\n                            \"derivation\": meas.derivation,\n                            \"tracking_id\": meas.tracking_id,\n                        }\n                    )\n\n        return pd.DataFrame(all_rows)\n\n    def export_combined_csv(self, path: str | Path) -&gt; Path:\n        \"\"\"Export combined measurements to a single CSV file.\n\n        Args:\n            path: Output path for the combined CSV.\n\n        Returns:\n            Path to the created CSV file.\n        \"\"\"\n        path_obj = Path(path)\n        df = self.get_combined_measurements_df()\n        df.to_csv(path_obj, index=False)\n        return path_obj\n\n    def export_log(self, path: str | Path) -&gt; Path:\n        \"\"\"Export processing log to CSV.\n\n        The log contains one row per processed file with status,\n        output paths, and any error messages.\n\n        Args:\n            path: Output path for the log CSV.\n\n        Returns:\n            Path to the created CSV file.\n        \"\"\"\n        path_obj = Path(path)\n        df = pd.DataFrame(self.processing_log)\n        df.to_csv(path_obj, index=False)\n        return path_obj\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.sr_parser.SRBatch.export_combined_csv","title":"<code>export_combined_csv(path)</code>","text":"<p>Export combined measurements to a single CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Output path for the combined CSV.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path to the created CSV file.</p> Source code in <code>pictologics/utilities/sr_parser.py</code> <pre><code>def export_combined_csv(self, path: str | Path) -&gt; Path:\n    \"\"\"Export combined measurements to a single CSV file.\n\n    Args:\n        path: Output path for the combined CSV.\n\n    Returns:\n        Path to the created CSV file.\n    \"\"\"\n    path_obj = Path(path)\n    df = self.get_combined_measurements_df()\n    df.to_csv(path_obj, index=False)\n    return path_obj\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.sr_parser.SRBatch.export_log","title":"<code>export_log(path)</code>","text":"<p>Export processing log to CSV.</p> <p>The log contains one row per processed file with status, output paths, and any error messages.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Output path for the log CSV.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path to the created CSV file.</p> Source code in <code>pictologics/utilities/sr_parser.py</code> <pre><code>def export_log(self, path: str | Path) -&gt; Path:\n    \"\"\"Export processing log to CSV.\n\n    The log contains one row per processed file with status,\n    output paths, and any error messages.\n\n    Args:\n        path: Output path for the log CSV.\n\n    Returns:\n        Path to the created CSV file.\n    \"\"\"\n    path_obj = Path(path)\n    df = pd.DataFrame(self.processing_log)\n    df.to_csv(path_obj, index=False)\n    return path_obj\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.sr_parser.SRBatch.get_combined_measurements_df","title":"<code>get_combined_measurements_df()</code>","text":"<p>Combine measurements from all documents into a single DataFrame.</p> <p>Each measurement row includes the source document's SOP Instance UID, patient ID, and study UID for traceability.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with all measurements from all documents.</p> Source code in <code>pictologics/utilities/sr_parser.py</code> <pre><code>def get_combined_measurements_df(self) -&gt; pd.DataFrame:\n    \"\"\"Combine measurements from all documents into a single DataFrame.\n\n    Each measurement row includes the source document's SOP Instance UID,\n    patient ID, and study UID for traceability.\n\n    Returns:\n        DataFrame with all measurements from all documents.\n    \"\"\"\n    all_rows: list[dict[str, Any]] = []\n\n    for doc in self.documents:\n        for group in doc.measurement_groups:\n            for meas in group.measurements:\n                all_rows.append(\n                    {\n                        \"sop_instance_uid\": doc.sop_instance_uid,\n                        \"patient_id\": doc.patient_id,\n                        \"study_instance_uid\": doc.study_instance_uid,\n                        \"group_finding_type\": group.finding_type,\n                        \"group_finding_site\": group.finding_site,\n                        \"measurement_name\": meas.name,\n                        \"value\": meas.value,\n                        \"unit\": meas.unit,\n                        \"finding_type\": meas.finding_type,\n                        \"finding_site\": meas.finding_site,\n                        \"derivation\": meas.derivation,\n                        \"tracking_id\": meas.tracking_id,\n                    }\n                )\n\n    return pd.DataFrame(all_rows)\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.sr_parser.is_dicom_sr","title":"<code>is_dicom_sr(path)</code>","text":"<p>Check if a DICOM file is a Structured Report.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the potential DICOM file.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the file is a DICOM SR object, False otherwise.</p> Source code in <code>pictologics/utilities/sr_parser.py</code> <pre><code>def is_dicom_sr(path: str | Path) -&gt; bool:\n    \"\"\"Check if a DICOM file is a Structured Report.\n\n    Args:\n        path: Path to the potential DICOM file.\n\n    Returns:\n        True if the file is a DICOM SR object, False otherwise.\n    \"\"\"\n    import pydicom\n\n    try:\n        dcm = pydicom.dcmread(str(path), stop_before_pixels=True)\n        sop_class = str(getattr(dcm, \"SOPClassUID\", \"\"))\n\n        sr_sop_classes = [\n            \"1.2.840.10008.5.1.4.1.1.88.11\",  # Basic Text SR\n            \"1.2.840.10008.5.1.4.1.1.88.22\",  # Enhanced SR\n            \"1.2.840.10008.5.1.4.1.1.88.33\",  # Comprehensive SR\n            \"1.2.840.10008.5.1.4.1.1.88.34\",  # Comprehensive 3D SR\n            \"1.2.840.10008.5.1.4.1.1.88.35\",  # Extensible SR\n            \"1.2.840.10008.5.1.4.1.1.88.40\",  # Procedure Log\n        ]\n\n        return sop_class in sr_sop_classes\n    except Exception:\n        return False\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.visualization","title":"<code>pictologics.utilities.visualization</code>","text":""},{"location":"api/utilities/#pictologics.utilities.visualization--visualization-module","title":"Visualization Module","text":"<p>This module provides utilities for visualizing medical images and segmentation masks. It supports interactive slice scrolling and batch export of images.</p>"},{"location":"api/utilities/#pictologics.utilities.visualization--key-features","title":"Key Features","text":"<ul> <li>Interactive slice viewer with matplotlib</li> <li>Flexible display modes: image-only, mask-only, or overlay</li> <li>Multi-label mask support (up to 20+ labels with distinct colors)</li> <li>Window/Level normalization for CT/MR viewing</li> <li>Configurable output formats (PNG, JPEG, TIFF)</li> <li>Flexible slice selection for batch export</li> </ul>"},{"location":"api/utilities/#pictologics.utilities.visualization--display-modes","title":"Display Modes","text":"<p>The visualization functions support three display modes based on which inputs are provided:</p> <ol> <li> <p>Image + Mask (Overlay Mode):    Both <code>image</code> and <code>mask</code> are provided. The mask is overlaid on the grayscale image    with the specified transparency (alpha) and colormap.</p> </li> <li> <p>Image Only:    Only <code>image</code> is provided (<code>mask=None</code>). The image is displayed as grayscale,    optionally with window/level normalization applied.</p> </li> <li> <p>Mask Only:    Only <code>mask</code> is provided (<code>image=None</code>). The mask can be displayed either:</p> </li> <li>As a colormap visualization (<code>mask_as_colormap=True</code>, default): Each unique      label value gets a distinct color from the specified colormap.</li> <li>As grayscale (<code>mask_as_colormap=False</code>): Values are normalized to 0-255.</li> </ol>"},{"location":"api/utilities/#pictologics.utilities.visualization--windowlevel-normalization","title":"Window/Level Normalization","text":"<p>For medical imaging (CT, MR), window/level controls are essential for proper visualization. When <code>window_center</code> and <code>window_width</code> are specified:</p> <ul> <li>window_center (Level): The center value of the display window (default: 200 HU for soft tissue)</li> <li>window_width (Width): The range of values displayed (default: 600 HU)</li> </ul> <p>Values outside [center - width/2, center + width/2] are clipped to black/white.</p> <p>Common presets: - Soft tissue: Center=40, Width=400 - Bone: Center=400, Width=1800 - Lung: Center=-600, Width=1500 - Brain: Center=40, Width=80</p>"},{"location":"api/utilities/#pictologics.utilities.visualization.visualize_slices","title":"<code>visualize_slices(image=None, mask=None, alpha=0.25, colormap='tab20', axis=2, initial_slice=None, window_title='Slice Viewer', window_center=None, window_width=None, mask_as_colormap=True)</code>","text":"<p>Display interactive slice viewer with scrolling.</p> <p>This function supports three display modes:</p> <ol> <li> <p>Image + Mask (Overlay Mode): Both <code>image</code> and <code>mask</code> are provided.    The mask is overlaid on the grayscale image with transparency.</p> </li> <li> <p>Image Only: Only <code>image</code> is provided. Displays grayscale slices,    optionally with window/level normalization.</p> </li> <li> <p>Mask Only: Only <code>mask</code> is provided. Displays mask visualization    using either a colormap or grayscale display.</p> </li> </ol> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Optional[Image]</code> <p>Optional Pictologics Image object containing the image data.</p> <code>None</code> <code>mask</code> <code>Optional[Image]</code> <p>Optional Pictologics Image object containing the mask data.</p> <code>None</code> <code>alpha</code> <code>float</code> <p>Transparency of mask overlay (0-1). Only used in overlay mode.</p> <code>0.25</code> <code>colormap</code> <code>str</code> <p>Colormap for mask labels. Options: - \"tab10\": 10 distinct colors - \"tab20\": 20 distinct colors (default) - \"Set1\": 9 bold colors - \"Set2\": 8 pastel colors - \"Paired\": 12 paired colors</p> <code>'tab20'</code> <code>axis</code> <code>int</code> <p>Axis along which to slice (0=sagittal, 1=coronal, 2=axial).</p> <code>2</code> <code>initial_slice</code> <code>Optional[int]</code> <p>Initial slice to display (default: middle).</p> <code>None</code> <code>window_title</code> <code>str</code> <p>Title for the viewer window.</p> <code>'Slice Viewer'</code> <code>window_center</code> <code>Optional[float]</code> <p>Window center (level) for normalization. Default: None (min-max).</p> <code>None</code> <code>window_width</code> <code>Optional[float]</code> <p>Window width for normalization. Default: None (min-max).</p> <code>None</code> <code>mask_as_colormap</code> <code>bool</code> <p>If True and mask-only mode, display with colormap. If False, display as grayscale.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither image nor mask is provided, or if shapes don't match when both are provided.</p> Example <pre><code>from pictologics import load_image\nfrom pictologics.utilities import visualize_slices\n\n# View image with mask overlay\nimg = load_image(\"scan.nii.gz\")\nmask = load_image(\"segmentation.nii.gz\")\nvisualize_slices(image=img, mask=mask)\n\n# View image only\nvisualize_slices(image=img, window_center=40, window_width=400)\n\n# View mask only with colormap\nvisualize_slices(mask=mask)\n</code></pre> Source code in <code>pictologics/utilities/visualization.py</code> <pre><code>def visualize_slices(\n    image: Optional[Image] = None,\n    mask: Optional[Image] = None,\n    alpha: float = 0.25,\n    colormap: str = \"tab20\",\n    axis: int = 2,\n    initial_slice: Optional[int] = None,\n    window_title: str = \"Slice Viewer\",\n    window_center: Optional[float] = None,\n    window_width: Optional[float] = None,\n    mask_as_colormap: bool = True,\n) -&gt; None:\n    \"\"\"\n    Display interactive slice viewer with scrolling.\n\n    This function supports three display modes:\n\n    1. **Image + Mask (Overlay Mode)**: Both `image` and `mask` are provided.\n       The mask is overlaid on the grayscale image with transparency.\n\n    2. **Image Only**: Only `image` is provided. Displays grayscale slices,\n       optionally with window/level normalization.\n\n    3. **Mask Only**: Only `mask` is provided. Displays mask visualization\n       using either a colormap or grayscale display.\n\n    Args:\n        image: Optional Pictologics Image object containing the image data.\n        mask: Optional Pictologics Image object containing the mask data.\n        alpha: Transparency of mask overlay (0-1). Only used in overlay mode.\n        colormap: Colormap for mask labels. Options:\n            - \"tab10\": 10 distinct colors\n            - \"tab20\": 20 distinct colors (default)\n            - \"Set1\": 9 bold colors\n            - \"Set2\": 8 pastel colors\n            - \"Paired\": 12 paired colors\n        axis: Axis along which to slice (0=sagittal, 1=coronal, 2=axial).\n        initial_slice: Initial slice to display (default: middle).\n        window_title: Title for the viewer window.\n        window_center: Window center (level) for normalization. Default: None (min-max).\n        window_width: Window width for normalization. Default: None (min-max).\n        mask_as_colormap: If True and mask-only mode, display with colormap.\n            If False, display as grayscale.\n\n    Raises:\n        ValueError: If neither image nor mask is provided, or if shapes don't match\n            when both are provided.\n\n    Example:\n        ```python\n        from pictologics import load_image\n        from pictologics.utilities import visualize_slices\n\n        # View image with mask overlay\n        img = load_image(\"scan.nii.gz\")\n        mask = load_image(\"segmentation.nii.gz\")\n        visualize_slices(image=img, mask=mask)\n\n        # View image only\n        visualize_slices(image=img, window_center=40, window_width=400)\n\n        # View mask only with colormap\n        visualize_slices(mask=mask)\n        ```\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.widgets import Slider\n\n    if image is None and mask is None:\n        raise ValueError(\"At least one of image or mask must be provided.\")\n\n    # Validate shapes if both provided\n    if image is not None and mask is not None:\n        if image.array.shape != mask.array.shape:\n            raise ValueError(\n                f\"Image shape {image.array.shape} does not match \"\n                f\"mask shape {mask.array.shape}\"\n            )\n\n    # Get reference array for shape\n    ref_array = _get_reference_array(image, mask)\n\n    # Get number of slices\n    num_slices = ref_array.shape[axis]\n\n    # Set initial slice\n    if initial_slice is None:\n        initial_slice = num_slices // 2\n\n    # Create figure and axes\n    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n    plt.subplots_adjust(bottom=0.15)\n\n    # Get slice data\n    def get_slice(idx: int) -&gt; tuple[Optional[np.ndarray], Optional[np.ndarray]]:\n        img_slice = None\n        mask_slice = None\n\n        if image is not None:\n            if axis == 0:\n                img_slice = image.array[idx, :, :]\n            elif axis == 1:\n                img_slice = image.array[:, idx, :]\n            else:\n                img_slice = image.array[:, :, idx]\n\n        if mask is not None:\n            if axis == 0:\n                mask_slice = mask.array[idx, :, :]\n            elif axis == 1:\n                mask_slice = mask.array[:, idx, :]\n            else:\n                mask_slice = mask.array[:, :, idx]\n\n        return img_slice, mask_slice\n\n    img_slice, mask_slice = get_slice(initial_slice)\n    rgba = _create_display_rgba(\n        img_slice,\n        mask_slice,\n        alpha,\n        colormap,\n        window_center,\n        window_width,\n        mask_as_colormap,\n    )\n\n    # Display\n    im = ax.imshow(rgba, aspect=\"equal\")\n    ax.set_title(f\"Slice {initial_slice}/{num_slices - 1}\")\n    ax.axis(\"off\")\n\n    # Add slider\n    ax_slider = plt.axes((0.15, 0.05, 0.7, 0.03))\n    slider = Slider(\n        ax=ax_slider,\n        label=\"Slice\",\n        valmin=0,\n        valmax=num_slices - 1,\n        valinit=initial_slice,\n        valstep=1,\n    )\n\n    def update(val: float) -&gt; None:\n        idx = int(val)\n        img_slice, mask_slice = get_slice(idx)\n        rgba = _create_display_rgba(\n            img_slice,\n            mask_slice,\n            alpha,\n            colormap,\n            window_center,\n            window_width,\n            mask_as_colormap,\n        )\n        im.set_data(rgba)\n        ax.set_title(f\"Slice {idx}/{num_slices - 1}\")\n        fig.canvas.draw_idle()\n\n    slider.on_changed(update)\n\n    # Add scroll wheel support\n    def on_scroll(event) -&gt; None:  # type: ignore[no-untyped-def]\n        if event.button == \"up\":\n            new_val = min(slider.val + 1, num_slices - 1)\n        else:\n            new_val = max(slider.val - 1, 0)\n        slider.set_val(new_val)\n\n    fig.canvas.mpl_connect(\"scroll_event\", on_scroll)\n\n    fig.suptitle(window_title)\n    plt.show()\n</code></pre>"},{"location":"api/utilities/#pictologics.utilities.visualization.save_slices","title":"<code>save_slices(output_dir, image=None, mask=None, slice_selection='10%', format='png', dpi=300, alpha=0.25, colormap='tab20', axis=2, filename_prefix='slice', window_center=None, window_width=None, mask_as_colormap=True)</code>","text":"<p>Save image slices to files.</p> <p>This function supports three display modes:</p> <ol> <li> <p>Image + Mask (Overlay Mode): Both <code>image</code> and <code>mask</code> are provided.    The mask is overlaid on the grayscale image with transparency.</p> </li> <li> <p>Image Only: Only <code>image</code> is provided. Saves grayscale slices,    optionally with window/level normalization.</p> </li> <li> <p>Mask Only: Only <code>mask</code> is provided. Saves mask visualization    using either a colormap or grayscale display.</p> </li> </ol> <p>Parameters:</p> Name Type Description Default <code>output_dir</code> <code>str</code> <p>Directory to save output images.</p> required <code>image</code> <code>Optional[Image]</code> <p>Optional Pictologics Image object containing the image data.</p> <code>None</code> <code>mask</code> <code>Optional[Image]</code> <p>Optional Pictologics Image object containing the mask data.</p> <code>None</code> <code>slice_selection</code> <code>Union[str, int, list[int]]</code> <p>Slice selection specification: - \"every_N\" or \"N\": Every Nth slice - \"N%\": Slices at each N% interval (e.g., \"10%\" = ~10 images) - int: Single slice index - list[int]: Specific slice indices</p> <code>'10%'</code> <code>format</code> <code>str</code> <p>Output format (\"png\", \"jpeg\", \"tiff\").</p> <code>'png'</code> <code>dpi</code> <code>int</code> <p>Output resolution in dots per inch.</p> <code>300</code> <code>alpha</code> <code>float</code> <p>Transparency of mask overlay (0-1). Only used in overlay mode.</p> <code>0.25</code> <code>colormap</code> <code>str</code> <p>Colormap for mask labels. Options: - \"tab10\": 10 distinct colors - \"tab20\": 20 distinct colors (default) - \"Set1\": 9 bold colors - \"Set2\": 8 pastel colors - \"Paired\": 12 paired colors</p> <code>'tab20'</code> <code>axis</code> <code>int</code> <p>Axis along which to slice (0=sagittal, 1=coronal, 2=axial).</p> <code>2</code> <code>filename_prefix</code> <code>str</code> <p>Prefix for output filenames.</p> <code>'slice'</code> <code>window_center</code> <code>Optional[float]</code> <p>Window center (level) for normalization. Default: None (min-max).</p> <code>None</code> <code>window_width</code> <code>Optional[float]</code> <p>Window width for normalization. Default: None (min-max).</p> <code>None</code> <code>mask_as_colormap</code> <code>bool</code> <p>If True and mask-only mode, display with colormap. If False, display as grayscale.</p> <code>True</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of paths to saved files.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither image nor mask is provided, or if shapes don't match when both are provided.</p> Example <pre><code>from pictologics import load_image\nfrom pictologics.utilities import save_slices\n\n# Save image with mask overlay\nimg = load_image(\"scan.nii.gz\")\nmask = load_image(\"segmentation.nii.gz\")\nfiles = save_slices(\"output/\", image=img, mask=mask, slice_selection=\"10%\")\n\n# Save image only (no mask)\nfiles = save_slices(\"output/\", image=img, slice_selection=\"10%\")\n\n# Save mask only with colormap\nfiles = save_slices(\"output/\", mask=mask, slice_selection=\"10%\")\n</code></pre> Source code in <code>pictologics/utilities/visualization.py</code> <pre><code>def save_slices(\n    output_dir: str,\n    image: Optional[Image] = None,\n    mask: Optional[Image] = None,\n    slice_selection: Union[str, int, list[int]] = \"10%\",\n    format: str = \"png\",\n    dpi: int = 300,\n    alpha: float = 0.25,\n    colormap: str = \"tab20\",\n    axis: int = 2,\n    filename_prefix: str = \"slice\",\n    window_center: Optional[float] = None,\n    window_width: Optional[float] = None,\n    mask_as_colormap: bool = True,\n) -&gt; list[str]:\n    \"\"\"\n    Save image slices to files.\n\n    This function supports three display modes:\n\n    1. **Image + Mask (Overlay Mode)**: Both `image` and `mask` are provided.\n       The mask is overlaid on the grayscale image with transparency.\n\n    2. **Image Only**: Only `image` is provided. Saves grayscale slices,\n       optionally with window/level normalization.\n\n    3. **Mask Only**: Only `mask` is provided. Saves mask visualization\n       using either a colormap or grayscale display.\n\n    Args:\n        output_dir: Directory to save output images.\n        image: Optional Pictologics Image object containing the image data.\n        mask: Optional Pictologics Image object containing the mask data.\n        slice_selection: Slice selection specification:\n            - \"every_N\" or \"N\": Every Nth slice\n            - \"N%\": Slices at each N% interval (e.g., \"10%\" = ~10 images)\n            - int: Single slice index\n            - list[int]: Specific slice indices\n        format: Output format (\"png\", \"jpeg\", \"tiff\").\n        dpi: Output resolution in dots per inch.\n        alpha: Transparency of mask overlay (0-1). Only used in overlay mode.\n        colormap: Colormap for mask labels. Options:\n            - \"tab10\": 10 distinct colors\n            - \"tab20\": 20 distinct colors (default)\n            - \"Set1\": 9 bold colors\n            - \"Set2\": 8 pastel colors\n            - \"Paired\": 12 paired colors\n        axis: Axis along which to slice (0=sagittal, 1=coronal, 2=axial).\n        filename_prefix: Prefix for output filenames.\n        window_center: Window center (level) for normalization. Default: None (min-max).\n        window_width: Window width for normalization. Default: None (min-max).\n        mask_as_colormap: If True and mask-only mode, display with colormap.\n            If False, display as grayscale.\n\n    Returns:\n        List of paths to saved files.\n\n    Raises:\n        ValueError: If neither image nor mask is provided, or if shapes don't match\n            when both are provided.\n\n    Example:\n        ```python\n        from pictologics import load_image\n        from pictologics.utilities import save_slices\n\n        # Save image with mask overlay\n        img = load_image(\"scan.nii.gz\")\n        mask = load_image(\"segmentation.nii.gz\")\n        files = save_slices(\"output/\", image=img, mask=mask, slice_selection=\"10%\")\n\n        # Save image only (no mask)\n        files = save_slices(\"output/\", image=img, slice_selection=\"10%\")\n\n        # Save mask only with colormap\n        files = save_slices(\"output/\", mask=mask, slice_selection=\"10%\")\n        ```\n    \"\"\"\n    if image is None and mask is None:\n        raise ValueError(\"At least one of image or mask must be provided.\")\n\n    # Validate shapes if both provided\n    if image is not None and mask is not None:\n        if image.array.shape != mask.array.shape:\n            raise ValueError(\n                f\"Image shape {image.array.shape} does not match \"\n                f\"mask shape {mask.array.shape}\"\n            )\n\n    # Get reference array for shape\n    ref_array = _get_reference_array(image, mask)\n\n    # Create output directory\n    out_path = Path(output_dir)\n    out_path.mkdir(parents=True, exist_ok=True)\n\n    # Get number of slices along axis\n    num_slices = ref_array.shape[axis]\n\n    # Parse slice selection\n    slice_indices = _parse_slice_selection(slice_selection, num_slices)\n\n    # Validate format\n    format = format.lower()\n    if format == \"jpg\":\n        format = \"jpeg\"\n    if format not in (\"png\", \"jpeg\", \"tiff\"):\n        format = \"png\"\n\n    # Calculate pixel size based on DPI\n    scale_factor = dpi / 72.0\n\n    saved_files = []\n\n    for idx in slice_indices:\n        # Extract slices\n        img_slice = None\n        mask_slice = None\n\n        if image is not None:\n            if axis == 0:\n                img_slice = image.array[idx, :, :]\n            elif axis == 1:\n                img_slice = image.array[:, idx, :]\n            else:\n                img_slice = image.array[:, :, idx]\n\n        if mask is not None:\n            if axis == 0:\n                mask_slice = mask.array[idx, :, :]\n            elif axis == 1:\n                mask_slice = mask.array[:, idx, :]\n            else:\n                mask_slice = mask.array[:, :, idx]\n\n        # Create display RGBA\n        rgba = _create_display_rgba(\n            img_slice,\n            mask_slice,\n            alpha,\n            colormap,\n            window_center,\n            window_width,\n            mask_as_colormap,\n        )\n\n        # Scale if needed for DPI\n        if scale_factor != 1.0:\n            h, w = rgba.shape[:2]\n            new_h = int(h * scale_factor)\n            new_w = int(w * scale_factor)\n            pil_img = PILImage.fromarray(rgba)\n            pil_img = pil_img.resize((new_w, new_h), PILImage.Resampling.LANCZOS)\n        else:\n            pil_img = PILImage.fromarray(rgba)\n\n        # Convert to RGB for JPEG (no alpha support)\n        if format == \"jpeg\":\n            pil_img = pil_img.convert(\"RGB\")\n\n        # Save\n        ext = {\"png\": \".png\", \"jpeg\": \".jpg\", \"tiff\": \".tiff\"}[format]\n        filename = f\"{filename_prefix}_{idx:04d}{ext}\"\n        filepath = out_path / filename\n        pil_img.save(filepath, dpi=(dpi, dpi))\n        saved_files.append(str(filepath))\n\n    return saved_files\n</code></pre>"},{"location":"api/features/intensity/","title":"Intensity Features API","text":""},{"location":"api/features/intensity/#pictologics.features.intensity","title":"<code>pictologics.features.intensity</code>","text":""},{"location":"api/features/intensity/#pictologics.features.intensity--intensity-feature-extraction-module","title":"Intensity Feature Extraction Module","text":"<p>This module provides functions for calculating First Order Statistics (Intensity) features from medical images. It implements the Image Biomarker Standardisation Initiative (IBSI) compliant algorithms.</p>"},{"location":"api/features/intensity/#pictologics.features.intensity--key-features","title":"Key Features:","text":"<ul> <li>First Order Statistics: Mean, Variance, Skewness, Kurtosis, Percentiles, etc.</li> <li>Intensity Histogram: Features based on discretised intensity histograms.</li> <li>Intensity-Volume Histogram (IVH): Volume fractions and intensity fractions, AUC.</li> <li>Spatial Intensity: Moran's I and Geary's C (spatial autocorrelation) [Optimized].</li> <li>Local Intensity: Local and Global Intensity Peaks.</li> </ul>"},{"location":"api/features/intensity/#pictologics.features.intensity--optimization","title":"Optimization:","text":"<p>Uses <code>numba</code> for JIT compilation, with parallel execution for computationally intensive spatial feature calculations.</p>"},{"location":"api/features/intensity/#pictologics.features.intensity.calculate_intensity_features","title":"<code>calculate_intensity_features(values)</code>","text":"<p>Calculate intensity-based features (First Order Statistics) as defined in IBSI.</p> Source code in <code>pictologics/features/intensity.py</code> <pre><code>def calculate_intensity_features(values: np.ndarray) -&gt; dict[str, float]:\n    \"\"\"\n    Calculate intensity-based features (First Order Statistics) as defined in IBSI.\n    \"\"\"\n    if len(values) == 0:\n        return {}\n\n    features: dict[str, float] = {}\n\n    # 4.1.1 Mean intensity (Q4LE)\n    mean_val = np.mean(values)\n    features[\"mean_intensity_Q4LE\"] = float(mean_val)\n\n    # 4.1.2 Intensity variance (ECT3)\n    var_val = float(np.var(values, ddof=0))\n    features[\"intensity_variance_ECT3\"] = float(var_val)\n\n    # 4.1.3 Intensity skewness (KE2A)\n    if var_val == 0.0:\n        features[\"intensity_skewness_KE2A\"] = np.nan\n        features[\"intensity_kurtosis_IPH6\"] = np.nan\n    else:\n        m2, m3, m4 = _central_moments_2_3_4(values, float(mean_val))\n        denom = m2**1.5\n        if denom != 0.0:\n            features[\"intensity_skewness_KE2A\"] = float(m3 / denom)\n            features[\"intensity_kurtosis_IPH6\"] = float((m4 / (m2 * m2)) - 3.0)\n\n    # 4.1.5 Median intensity (Y12H)\n    median_val = np.median(values)\n    features[\"median_intensity_Y12H\"] = float(median_val)\n\n    # 4.1.6 Minimum intensity (1GSF)\n    min_val = np.min(values)\n    features[\"minimum_intensity_1GSF\"] = float(min_val)\n\n    p10, p25, p75, p90 = np.percentile(values, [10, 25, 75, 90])\n    features[\"10th_intensity_percentile_QG58\"] = float(p10)\n    features[\"90th_intensity_percentile_8DWT\"] = float(p90)\n\n    # 4.1.9 Maximum intensity (84IY)\n    max_val = np.max(values)\n    features[\"maximum_intensity_84IY\"] = float(max_val)\n\n    # 4.1.10 Intensity interquartile range (SALO)\n    features[\"intensity_interquartile_range_SALO\"] = float(p75 - p25)\n\n    # 4.1.11 Intensity range (2OJQ)\n    features[\"intensity_range_2OJQ\"] = float(max_val - min_val)\n\n    # 4.1.12 Mean absolute deviation (4FUA)\n    features[\"intensity_mean_absolute_deviation_4FUA\"] = float(\n        _mean_abs_dev(values, float(mean_val))\n    )\n\n    # 4.1.13 Robust mean absolute deviation (1128)\n    features[\"intensity_robust_mean_absolute_deviation_1128\"] = float(\n        _robust_mean_abs_dev(values, float(p10), float(p90))\n    )\n\n    # 4.1.14 Median absolute deviation (N72L)\n    features[\"intensity_median_absolute_deviation_N72L\"] = float(\n        _mean_abs_dev(values, float(median_val))\n    )\n\n    # 4.1.15 Coefficient of variation (7TET)\n    if mean_val != 0:\n        features[\"intensity_coefficient_of_variation_7TET\"] = float(\n            np.sqrt(var_val) / mean_val\n        )\n    else:\n        features[\"intensity_coefficient_of_variation_7TET\"] = np.nan\n\n    # 4.1.16 Quartile coefficient of dispersion (9S40)\n    if (p75 + p25) != 0:\n        features[\"intensity_quartile_coefficient_of_dispersion_9S40\"] = float(\n            (p75 - p25) / (p75 + p25)\n        )\n    else:\n        features[\"intensity_quartile_coefficient_of_dispersion_9S40\"] = np.nan\n\n    # 4.1.17 Energy (N8CA)\n    energy = float(np.dot(values, values))\n    features[\"intensity_energy_N8CA\"] = energy\n\n    # 4.1.18 Root mean square (5ZWQ)\n    features[\"root_mean_square_intensity_5ZWQ\"] = float(np.sqrt(energy / len(values)))\n\n    return features\n</code></pre>"},{"location":"api/features/intensity/#pictologics.features.intensity.calculate_intensity_histogram_features","title":"<code>calculate_intensity_histogram_features(discretised_values)</code>","text":"<p>Calculate intensity histogram features as defined in IBSI 4.2.</p> Source code in <code>pictologics/features/intensity.py</code> <pre><code>def calculate_intensity_histogram_features(\n    discretised_values: np.ndarray,\n) -&gt; dict[str, float]:\n    \"\"\"Calculate intensity histogram features as defined in IBSI 4.2.\"\"\"\n    if len(discretised_values) == 0:\n        return {}\n\n    features: dict[str, float] = {}\n\n    disc = np.asarray(discretised_values)\n    n = disc.size\n\n    # Support negative values by shifting for bincount compatibility\n    min_val_i = int(np.min(disc))\n    max_val_i = int(np.max(disc))\n\n    shifted = disc.astype(np.int64) - min_val_i\n    counts_full = np.bincount(shifted, minlength=(max_val_i - min_val_i + 1))\n    total = float(n)\n    p = counts_full[counts_full &gt; 0].astype(np.float64) / total\n\n    # 4.2.1 Mean discretised intensity (X6K6)\n    mean_disc = float(np.mean(disc))\n    features[\"mean_discretised_intensity_X6K6\"] = float(mean_disc)\n\n    # 4.2.2 Discretised intensity variance (CH89)\n    var_disc = float(np.var(disc, ddof=0))\n    features[\"discretised_intensity_variance_CH89\"] = float(var_disc)\n\n    # 4.2.3 Discretised intensity skewness (88K1)\n    if var_disc == 0.0:\n        features[\"discretised_intensity_skewness_88K1\"] = np.nan\n        features[\"discretised_intensity_kurtosis_C3I7\"] = np.nan\n    else:\n        m2, m3, m4 = _central_moments_2_3_4(disc, float(mean_disc))\n        denom = m2**1.5\n        if denom != 0.0:\n            features[\"discretised_intensity_skewness_88K1\"] = float(m3 / denom)\n            features[\"discretised_intensity_kurtosis_C3I7\"] = float(\n                (m4 / (m2 * m2)) - 3.0\n            )\n\n    p10, p25, median_val, p75, p90 = np.percentile(disc, [10, 25, 50, 75, 90])\n\n    features[\"median_discretised_intensity_WIFQ\"] = float(median_val)\n    features[\"minimum_discretised_intensity_1PR8\"] = float(min_val_i)\n    features[\"10th_discretised_intensity_percentile_1PR\"] = float(p10)\n    features[\"90th_discretised_intensity_percentile_GPMT\"] = float(p90)\n    features[\"maximum_discretised_intensity_3NCY\"] = float(max_val_i)\n\n    mode_index = int(np.argmax(counts_full))\n    features[\"intensity_histogram_mode_AMMC\"] = float(min_val_i + mode_index)\n\n    features[\"discretised_intensity_interquartile_range_WR0O\"] = float(p75 - p25)\n\n    features[\"discretised_intensity_range_5Z3W\"] = float(\n        features[\"maximum_discretised_intensity_3NCY\"]\n        - features[\"minimum_discretised_intensity_1PR8\"]\n    )\n\n    features[\"intensity_histogram_mean_absolute_deviation_D2ZX\"] = float(\n        _mean_abs_dev(disc, float(mean_disc))\n    )\n\n    features[\"intensity_histogram_robust_mean_absolute_deviation_WRZB\"] = float(\n        _robust_mean_abs_dev(disc, float(p10), float(p90))\n    )\n\n    features[\"intensity_histogram_median_absolute_deviation_4RNL\"] = float(\n        _mean_abs_dev(disc, float(median_val))\n    )\n\n    if mean_disc != 0:\n        features[\"intensity_histogram_coefficient_of_variation_CWYJ\"] = float(\n            np.sqrt(var_disc) / mean_disc\n        )\n    else:\n        features[\"intensity_histogram_coefficient_of_variation_CWYJ\"] = np.nan\n\n    if (p75 + p25) != 0:\n        features[\"intensity_histogram_quartile_coefficient_of_dispersion_SLWD\"] = float(\n            (p75 - p25) / (p75 + p25)\n        )\n    else:\n        features[\"intensity_histogram_quartile_coefficient_of_dispersion_SLWD\"] = np.nan\n\n    # Vectorized entropy/uniformity\n    features[\"discretised_intensity_entropy_TLU2\"] = float(-np.sum(p * np.log2(p)))\n    features[\"discretised_intensity_uniformity_BJ5W\"] = float(np.sum(p * p))\n\n    hist_counts = counts_full.astype(np.float64)\n    if len(hist_counts) &lt; 2:\n        features[\"maximum_histogram_gradient_12CE\"] = np.nan\n        features[\"maximum_histogram_gradient_intensity_8E6O\"] = np.nan\n        features[\"minimum_histogram_gradient_VQB3\"] = np.nan\n        features[\"minimum_histogram_gradient_intensity_RHQZ\"] = np.nan\n    else:\n        gradient = np.gradient(hist_counts)\n        features[\"maximum_histogram_gradient_12CE\"] = float(np.max(gradient))\n        max_grad_idx = int(np.argmax(gradient))\n        features[\"maximum_histogram_gradient_intensity_8E6O\"] = float(\n            min_val_i + max_grad_idx\n        )\n        features[\"minimum_histogram_gradient_VQB3\"] = float(np.min(gradient))\n        min_grad_idx = int(np.argmin(gradient))\n        features[\"minimum_histogram_gradient_intensity_RHQZ\"] = float(\n            min_val_i + min_grad_idx\n        )\n\n    return features\n</code></pre>"},{"location":"api/features/intensity/#pictologics.features.intensity.calculate_ivh_features","title":"<code>calculate_ivh_features(discretised_values, bin_width=None, min_val=None, max_val=None, target_range_min=None, target_range_max=None)</code>","text":"<p>Calculate Intensity-Volume Histogram (IVH) features.</p> <p>Includes Volume Fraction difference and Area Under the IVH Curve (AUC).</p> Source code in <code>pictologics/features/intensity.py</code> <pre><code>def calculate_ivh_features(\n    discretised_values: np.ndarray,\n    bin_width: Optional[float] = None,\n    min_val: Optional[float] = None,\n    max_val: Optional[float] = None,\n    target_range_min: Optional[float] = None,\n    target_range_max: Optional[float] = None,\n) -&gt; dict[str, float]:\n    \"\"\"\n    Calculate Intensity-Volume Histogram (IVH) features.\n\n    Includes Volume Fraction difference and Area Under the IVH Curve (AUC).\n    \"\"\"\n    if len(discretised_values) == 0:\n        return {}\n\n    features: dict[str, float] = {}\n    N = len(discretised_values)\n\n    vals = np.asarray(discretised_values)\n    sorted_vals = np.sort(vals)\n\n    # -------------------------------------------------------------------------\n    # 1. Volume Fractions\n    # -------------------------------------------------------------------------\n    t_min = target_range_min if target_range_min is not None else min_val\n    t_max = target_range_max if target_range_max is not None else max_val\n\n    # Fallback to data min/max if still None\n    if t_min is None or t_max is None:\n        t_min_idx = float(sorted_vals[0])\n        t_max_idx = float(sorted_vals[-1])\n        val_range_idx = t_max_idx - t_min_idx\n\n        def get_volume_fraction_at_intensity_fraction_indices(frac: float) -&gt; float:\n            threshold_idx = t_min_idx + frac * val_range_idx\n            idx = int(np.searchsorted(sorted_vals, threshold_idx, side=\"left\"))\n            count = N - idx\n            return float(count / N)\n\n        features[\"volume_at_intensity_fraction_0.10_BC2M_10\"] = (\n            get_volume_fraction_at_intensity_fraction_indices(0.10)\n        )\n        features[\"volume_at_intensity_fraction_0.90_BC2M_90\"] = (\n            get_volume_fraction_at_intensity_fraction_indices(0.90)\n        )\n\n    else:\n        # We have physical units for the target range.\n        t_range = t_max - t_min\n\n        def get_volume_fraction_at_intensity_fraction_physical(frac: float) -&gt; float:\n            threshold_val = t_min + frac * t_range  # type: ignore\n            if bin_width is not None and min_val is not None:\n                # Convert to index based on FBS\n                mv = min_val\n                bw = bin_width\n                threshold_idx = np.floor((threshold_val - mv) / bw) + 1  # type: ignore\n            else:\n                threshold_idx = threshold_val\n\n            idx = int(np.searchsorted(sorted_vals, threshold_idx, side=\"left\"))\n            count = N - idx\n            return float(count / N)\n\n        features[\"volume_at_intensity_fraction_0.10_BC2M_10\"] = (\n            get_volume_fraction_at_intensity_fraction_physical(0.10)\n        )\n        features[\"volume_at_intensity_fraction_0.90_BC2M_90\"] = (\n            get_volume_fraction_at_intensity_fraction_physical(0.90)\n        )\n\n    features[\n        \"volume_fraction_difference_between_intensity_0.10_and_0.90_fractions_DDTU\"\n    ] = float(\n        features[\"volume_at_intensity_fraction_0.10_BC2M_10\"]\n        - features[\"volume_at_intensity_fraction_0.90_BC2M_90\"]\n    )\n\n    # -------------------------------------------------------------------------\n    # 2. Intensity Fractions\n    # -------------------------------------------------------------------------\n    def get_intensity_at_volume_fraction(vol_frac: float) -&gt; float:\n        # Fast path for standard integer bins (step=1)\n        if (\n            bin_width is not None\n            and min_val is None\n            and bin_width &gt; 0\n            and float(bin_width) == 1.0\n            and np.issubdtype(sorted_vals.dtype, np.integer)\n        ):\n            target_count = int(np.floor(vol_frac * N))\n            if target_count &lt;= 0:\n                return float(sorted_vals[-1])\n\n            # Smallest integer threshold t such that count(vals &gt;= t) &lt;= target_count.\n            # Let k = N - target_count. We need searchsorted(t) &gt;= k.\n            k = N - target_count\n            v = int(sorted_vals[k - 1])\n            t = v + 1\n            vmax = int(sorted_vals[-1])\n            if t &gt; vmax:\n                t = vmax\n            return float(t)\n\n        # Determine candidates\n        if bin_width is not None:\n            g_min = min_val if min_val is not None else np.min(discretised_values)\n            if max_val is not None:\n                g_max = max_val\n            elif min_val is not None:\n                g_max = min_val + np.max(discretised_values) * bin_width\n            else:\n                g_max = np.max(discretised_values)\n\n            if bin_width &gt; 0:\n                num_steps = int(np.round((g_max - g_min) / bin_width))\n                if min_val is not None:\n                    # Candidates are bin centers\n                    idx = np.arange(num_steps, dtype=np.float64)\n                    candidates = g_min + (idx + 0.5) * bin_width\n                else:\n                    idx = np.arange(num_steps + 1, dtype=np.float64)\n                    candidates = g_min + idx * bin_width\n            else:\n                candidates = sorted_vals.astype(np.float64)\n        else:\n            candidates = sorted_vals\n\n        target_count = int(np.floor(vol_frac * N))\n\n        # Binary search\n        low = 0\n        high = len(candidates) - 1\n        ans_idx = -1\n\n        while low &lt;= high:\n            mid = (low + high) // 2\n            val = candidates[mid]\n\n            # Convert physical value to index if in discrete mode\n            if bin_width is not None and min_val is not None and bin_width &gt; 0:\n                check_val = np.floor((val - min_val) / bin_width) + 1\n            else:\n                check_val = val\n\n            idx = np.searchsorted(sorted_vals, check_val, side=\"left\")\n            count = N - idx\n\n            if count &lt;= target_count:\n                ans_idx = mid\n                high = mid - 1\n            else:\n                low = mid + 1\n\n        if ans_idx != -1:\n            return float(candidates[ans_idx])\n        else:\n            return float(candidates[-1])\n\n    features[\"intensity_at_volume_fraction_0.10_GBPN_10\"] = (\n        get_intensity_at_volume_fraction(0.10)\n    )\n    features[\"intensity_at_volume_fraction_0.90_GBPN_90\"] = (\n        get_intensity_at_volume_fraction(0.90)\n    )\n\n    features[\n        \"intensity_fraction_difference_between_volume_0.10_and_0.90_fractions_CNV2\"\n    ] = float(\n        features[\"intensity_at_volume_fraction_0.10_GBPN_10\"]\n        - features[\"intensity_at_volume_fraction_0.90_GBPN_90\"]\n    )\n\n    # -------------------------------------------------------------------------\n    # 3. Area Under the IVH Curve (AUC)\n    # -------------------------------------------------------------------------\n    # IVH Curve: Volume Fraction (phi) vs Intensity (I)\n    # We construct the curve points from the unique values in the data.\n    unique_vals = np.unique(sorted_vals)\n    if len(unique_vals) == 1:\n        # If there is only one discretised intensity, AUC is 0 by definition.\n        features[\"area_under_the_ivh_curve_9CMM\"] = 0.0\n    else:\n        # P(X &gt;= i)\n        # For each unique value, calculate fraction &gt;= value\n\n        # If we have physical mapping, map unique_vals to physical intensities\n        if bin_width is not None and min_val is not None:\n            # Map index to physical center: min_val + (idx - 0.5) * w ?\n            # Standard FBS mapping: index k corresponds to [min + (k-1)w, min + kw)\n            # center = min_val + (k - 1 + 0.5) * w\n            # k is the value in unique_vals\n            intensities_arr = (\n                min_val + (unique_vals.astype(np.float64) - 0.5) * bin_width\n            )\n        else:\n            intensities_arr = unique_vals.astype(np.float64)\n\n        # Calculate volume fractions\n        # searchsorted returns first index where val fits.\n        # Since sorted_vals is sorted, all elements &gt;= val are from searchsorted(val) onwards.\n        indices = np.searchsorted(sorted_vals, unique_vals, side=\"left\")\n        counts = N - indices\n        fractions = counts.astype(np.float64) / float(N)\n\n        # Riemann Sum (Trapezoidal)\n        # Integrate fraction(I) over I.\n        auc = 0.0\n        for k in range(1, len(intensities_arr)):\n            i_curr = intensities_arr[k]\n            i_prev = intensities_arr[k - 1]\n            phi_curr = fractions[k]\n            phi_prev = fractions[k - 1]\n\n            # Trapezoid area\n            width = i_curr - i_prev\n            avg_height = (phi_curr + phi_prev) * 0.5\n            auc += width * avg_height\n\n        features[\"area_under_the_ivh_curve_9CMM\"] = float(auc)\n\n    return features\n</code></pre>"},{"location":"api/features/intensity/#pictologics.features.intensity.calculate_local_intensity_features","title":"<code>calculate_local_intensity_features(image, mask, *, enabled=True)</code>","text":"<p>Calculate local intensity features: Local and Global Intensity Peak (IBSI 4.5).</p> Source code in <code>pictologics/features/intensity.py</code> <pre><code>def calculate_local_intensity_features(\n    image: Image,\n    mask: Image,\n    *,\n    enabled: bool = True,\n) -&gt; dict[str, float]:\n    \"\"\"\n    Calculate local intensity features: Local and Global Intensity Peak (IBSI 4.5).\n    \"\"\"\n    if not enabled:\n        return {}\n\n    features: dict[str, float] = {}\n\n    mask_array = mask.array\n    data = image.array\n    spacing_tuple = (\n        float(image.spacing[0]),\n        float(image.spacing[1]),\n        float(image.spacing[2]),\n    )\n\n    # Radius for 1 cm^3 sphere\n    radius_mm = 6.2035\n\n    # Get ROI indices\n    x_idx, y_idx, z_idx = np.where(mask_array &gt; 0)\n    if len(x_idx) == 0:\n        return features\n\n    mask_indices = np.ascontiguousarray(\n        np.stack([x_idx, y_idx, z_idx], axis=1).astype(np.int32)\n    )\n    offsets = _sphere_offsets_for_radius(spacing_tuple, radius_mm)\n\n    # Calculate local means only for ROI voxels\n    roi_means = _calculate_local_mean_numba(data, mask_indices, offsets)\n\n    # Compute both peaks without allocating ROI intensity arrays.\n    global_peak, local_peak = _calculate_local_peaks_numba(\n        data, mask_indices, roi_means\n    )\n    features[\"global_intensity_peak_0F91\"] = float(global_peak)\n    features[\"local_intensity_peak_VJGA\"] = float(local_peak)\n\n    return features\n</code></pre>"},{"location":"api/features/intensity/#pictologics.features.intensity.calculate_spatial_intensity_features","title":"<code>calculate_spatial_intensity_features(image, mask, *, enabled=True)</code>","text":"<p>Calculate spatial intensity features: Moran's I and Geary's C (IBSI 4.4).</p> Source code in <code>pictologics/features/intensity.py</code> <pre><code>def calculate_spatial_intensity_features(\n    image: Image,\n    mask: Image,\n    *,\n    enabled: bool = True,\n) -&gt; dict[str, float]:\n    \"\"\"\n    Calculate spatial intensity features: Moran's I and Geary's C (IBSI 4.4).\n    \"\"\"\n    if not enabled:\n        return {}\n\n    features: dict[str, float] = {}\n\n    mask_array = mask.array\n    data = image.array\n    sx, sy, sz = (\n        float(image.spacing[0]),\n        float(image.spacing[1]),\n        float(image.spacing[2]),\n    )\n\n    # Get ROI indices (X, Y, Z)\n    x_idx, y_idx, z_idx = np.where(mask_array &gt; 0)\n\n    if len(x_idx) &lt; 2:\n        features[\"morans_i_index_N365\"] = np.nan\n        features[\"gearys_c_measure_NPT7\"] = np.nan\n        return features\n\n    xi = np.ascontiguousarray(x_idx.astype(np.int32))\n    yi = np.ascontiguousarray(y_idx.astype(np.int32))\n    zi = np.ascontiguousarray(z_idx.astype(np.int32))\n\n    intensities = np.ascontiguousarray(data[mask_array &gt; 0].astype(np.float64))\n\n    N = len(intensities)\n    mean_int = np.mean(intensities)\n\n    # Calculate terms using Parallelized Numba Function\n    numer_moran, numer_geary_1, numer_geary_2, sum_weights = (\n        _calculate_spatial_features_numba(\n            xi, yi, zi, intensities, float(mean_int), sx, sy, sz\n        )\n    )\n\n    # Moran's I - N365\n    denom = _sum_sq_centered(intensities, float(mean_int))\n\n    if denom != 0 and sum_weights != 0:\n        moran_i = (N / sum_weights) * (numer_moran / denom)\n        features[\"morans_i_index_N365\"] = float(moran_i)\n    else:\n        features[\"morans_i_index_N365\"] = np.nan\n\n    # Geary's C - NPT7\n    if denom != 0 and sum_weights != 0:\n        numer = 2 * numer_geary_1 - 2 * numer_geary_2\n        geary_c = ((N - 1) / (2 * sum_weights)) * (numer / denom)\n        features[\"gearys_c_measure_NPT7\"] = float(geary_c)\n    else:\n        features[\"gearys_c_measure_NPT7\"] = np.nan\n\n    return features\n</code></pre>"},{"location":"api/features/morphology/","title":"Morphology Features API","text":""},{"location":"api/features/morphology/#pictologics.features.morphology","title":"<code>pictologics.features.morphology</code>","text":""},{"location":"api/features/morphology/#pictologics.features.morphology--morphology-feature-extraction-module","title":"Morphology Feature Extraction Module","text":"<p>This module provides functions for calculating Morphological (Shape and Size) features from medical images. It implements the Image Biomarker Standardisation Initiative (IBSI) compliant algorithms.</p>"},{"location":"api/features/morphology/#pictologics.features.morphology--key-features","title":"Key Features:","text":"<ul> <li>Voxel-based: Volume (voxel counting).</li> <li>Mesh-based: Surface Area, Volume (mesh), Compactness, Sphericity.</li> <li>PCA-based: Major/Minor/Least Axis Length, Elongation, Flatness.</li> <li>Convex Hull: Volume, Area, Max 3D Diameter.</li> <li>Bounding Box: Oriented (OMBB) and Axis-Aligned (AABB) Bounding Boxes.</li> <li>Minimum Volume Enclosing Ellipsoid (MVEE): Volume, Area.</li> <li>Intensity-Weighted: Center of Mass Shift, Integrated Intensity.</li> </ul>"},{"location":"api/features/morphology/#pictologics.features.morphology--optimization","title":"Optimization:","text":"<p>Uses <code>numba</code> for optimizing the Khachiyan algorithm for MVEE calculation.</p>"},{"location":"api/features/morphology/#pictologics.features.morphology.calculate_morphology_features","title":"<code>calculate_morphology_features(mask, image=None, intensity_mask=None)</code>","text":"<p>Calculate morphological features from the ROI mask. Includes both voxel-based and mesh-based features (IBSI compliant).</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>Image</code> <p>Image object containing the binary mask (Morphological Mask).</p> required <code>image</code> <code>Optional[Image]</code> <p>Optional Image object containing intensity data (required for some features).</p> <code>None</code> <code>intensity_mask</code> <code>Optional[Image]</code> <p>Optional Image object containing the intensity mask (e.g. after outlier filtering).             If provided, used for intensity-weighted features (99N0, KLMA).             If None, defaults to <code>mask</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>Dictionary of calculated features.</p> Source code in <code>pictologics/features/morphology.py</code> <pre><code>def calculate_morphology_features(\n    mask: Image, image: Optional[Image] = None, intensity_mask: Optional[Image] = None\n) -&gt; dict[str, float]:\n    \"\"\"\n    Calculate morphological features from the ROI mask.\n    Includes both voxel-based and mesh-based features (IBSI compliant).\n\n    Args:\n        mask: Image object containing the binary mask (Morphological Mask).\n        image: Optional Image object containing intensity data (required for some features).\n        intensity_mask: Optional Image object containing the intensity mask (e.g. after outlier filtering).\n                        If provided, used for intensity-weighted features (99N0, KLMA).\n                        If None, defaults to `mask`.\n\n    Returns:\n        Dictionary of calculated features.\n    \"\"\"\n    features: dict[str, float] = {}\n    i_mask = intensity_mask if intensity_mask is not None else mask\n\n    # 1. Voxel Based Features\n    voxel_volume = np.prod(mask.spacing)\n    n_voxels = np.sum(mask.array)\n    features[\"volume_voxel_counting_YEKZ\"] = float(n_voxels * voxel_volume)\n\n    # 2. Mesh Based Features\n    mesh_feats, verts, faces = _get_mesh_features(mask)\n    features.update(mesh_feats)\n\n    if verts is None or faces is None:\n        return features\n\n    mesh_volume = features.get(\"volume_RNU0\", 0.0)\n    surface_area = features.get(\"surface_area_C0JK\", 0.0)\n\n    # 3. Shape Features\n    features.update(_get_shape_features(surface_area, mesh_volume))\n\n    # 4. PCA Based Features\n    pca_feats, evals, evecs = _get_pca_features(mask, mesh_volume, surface_area)\n    features.update(pca_feats)\n\n    # 5. Convex Hull Features\n    hull_feats, hull = _get_convex_hull_features(verts, mesh_volume, surface_area)\n    features.update(hull_feats)\n\n    # 6. Bounding Box Features\n    features.update(_get_bounding_box_features(verts, evecs, mesh_volume, surface_area))\n\n    # 7. MVEE Features\n    features.update(_get_mvee_features(hull, verts, mesh_volume, surface_area))\n\n    # 8. Intensity Based Features\n    if image is not None:\n        features.update(\n            _get_intensity_morphology_features(mask, image, i_mask, mesh_volume)\n        )\n\n    return features\n</code></pre>"},{"location":"api/features/texture/","title":"Texture Features API","text":""},{"location":"api/features/texture/#pictologics.features.texture","title":"<code>pictologics.features.texture</code>","text":""},{"location":"api/features/texture/#pictologics.features.texture--texture-feature-extraction-module","title":"Texture Feature Extraction Module","text":"<p>This module provides a comprehensive suite of functions for calculating 3D texture features from medical images. It implements the Image Biomarker Standardisation Initiative (IBSI) compliant algorithms for various texture matrices.</p>"},{"location":"api/features/texture/#pictologics.features.texture--key-concepts","title":"Key Concepts:","text":"<p>Texture analysis quantifies the spatial arrangement of grey levels in an image. It assumes that the texture (e.g., \"smooth\", \"coarse\", \"regular\") is contained in the spatial relationship between the grey levels of the voxels.</p>"},{"location":"api/features/texture/#pictologics.features.texture--implemented-matrices","title":"Implemented Matrices:","text":"<ol> <li> <p>GLCM (Grey Level Co-occurrence Matrix):     Counts how often pairs of grey levels occur at a specific distance and direction.     Captures: Contrast, homogeneity, correlation.</p> </li> <li> <p>GLRLM (Grey Level Run Length Matrix):     Counts the lengths of consecutive runs of the same grey level.     Captures: Coarseness, directionality.</p> </li> <li> <p>GLSZM (Grey Level Size Zone Matrix):     Counts the size of zones (connected components) of the same grey level.     Captures: Regional homogeneity, size distribution of texture elements.</p> </li> <li> <p>GLDZM (Grey Level Distance Zone Matrix):     Counts zones based on their distance from the ROI border.     Captures: Spatial distribution relative to the boundary.</p> </li> <li> <p>NGTDM (Neighbourhood Grey Tone Difference Matrix):     Quantifies the difference between a voxel and its neighbours.     Captures: Human perception of texture (coarseness, contrast, busyness).</p> </li> <li> <p>NGLDM (Neighbourhood Grey Level Dependence Matrix):     Captures the dependence of grey levels on their neighbours.     Captures: Dependence, spatial relationships.</p> </li> </ol>"},{"location":"api/features/texture/#pictologics.features.texture--optimization","title":"Optimization:","text":"<p>This module uses <code>numba</code> for Just-In-Time (JIT) compilation to achieve high performance. The core calculations are parallelized and optimized for memory usage. - Single-pass calculation: Multiple matrices are computed in a single pass over the image   to minimize memory access overhead. - Flattened DFS: Zone-based features (GLSZM, GLDZM) use a memory-efficient Depth-First Search   with flattened stack indices.</p>"},{"location":"api/features/texture/#pictologics.features.texture--usage","title":"Usage:","text":"<p>The main entry point is <code>calculate_all_texture_matrices</code>, which computes all raw matrices. Then, specific feature calculation functions (e.g., <code>calculate_glcm_features</code>) can be called using these matrices.</p> Example <p>Example:     <pre><code>import numpy as np\nfrom pictologics.features.texture import calculate_all_texture_matrices, calculate_glcm_features\n\n# Create dummy data\ndata = np.random.randint(1, 33, (50, 50, 50))\nmask = np.ones((50, 50, 50))\n\n# Calculate matrices\nmatrices = calculate_all_texture_matrices(data, mask, n_bins=32)\n\n# Extract features\nglcm_feats = calculate_glcm_features(data, mask, n_bins=32, glcm_matrix=matrices['glcm'])\nprint(glcm_feats['contrast_ACUI'])\n</code></pre></p>"},{"location":"api/features/texture/#pictologics.features.texture.calculate_all_texture_features","title":"<code>calculate_all_texture_features(disc_array, mask_array, n_bins, distance_mask_array=None, ngldm_alpha=0)</code>","text":"<p>Calculate all texture features (GLCM, GLRLM, GLSZM, GLDZM, NGTDM, NGLDM).</p> <p>This is a convenience wrapper that computes all texture matrices and then extracts all available features.</p> <p>Parameters:</p> Name Type Description Default <code>disc_array</code> <code>ndarray</code> <p>Discretised image array.</p> required <code>mask_array</code> <code>ndarray</code> <p>Mask array (ROI).</p> required <code>n_bins</code> <code>int</code> <p>Number of bins.</p> required <code>distance_mask_array</code> <code>Optional[ndarray]</code> <p>Optional mask for GLDZM distance calculation.                  If None, mask_array is used.</p> <code>None</code> <code>ngldm_alpha</code> <code>int</code> <p>The coarseness parameter \u03b1 for NGLDM. Two grey levels are considered dependent if their absolute difference is \u2264 \u03b1. Default is 0 (IBSI standard).</p> <code>0</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>Dictionary of all texture features.</p> Source code in <code>pictologics/features/texture.py</code> <pre><code>def calculate_all_texture_features(\n    disc_array: np.ndarray,\n    mask_array: np.ndarray,\n    n_bins: int,\n    distance_mask_array: Optional[np.ndarray] = None,\n    ngldm_alpha: int = 0,\n) -&gt; dict[str, float]:\n    \"\"\"\n    Calculate all texture features (GLCM, GLRLM, GLSZM, GLDZM, NGTDM, NGLDM).\n\n    This is a convenience wrapper that computes all texture matrices and then\n    extracts all available features.\n\n    Args:\n        disc_array: Discretised image array.\n        mask_array: Mask array (ROI).\n        n_bins: Number of bins.\n        distance_mask_array: Optional mask for GLDZM distance calculation.\n                             If None, mask_array is used.\n        ngldm_alpha: The coarseness parameter \u03b1 for NGLDM. Two grey levels are considered\n            dependent if their absolute difference is \u2264 \u03b1. Default is 0 (IBSI standard).\n\n    Returns:\n        Dictionary of all texture features.\n    \"\"\"\n    results = {}\n\n    # Calculate all matrices once\n    texture_matrices = calculate_all_texture_matrices(\n        disc_array,\n        mask_array,\n        n_bins,\n        distance_mask=distance_mask_array,\n        ngldm_alpha=ngldm_alpha,\n    )\n\n    # GLCM\n    results.update(\n        calculate_glcm_features(\n            disc_array, mask_array, n_bins, glcm_matrix=texture_matrices[\"glcm\"]\n        )\n    )\n\n    # GLRLM\n    results.update(\n        calculate_glrlm_features(\n            disc_array, mask_array, n_bins, glrlm_matrix=texture_matrices[\"glrlm\"]\n        )\n    )\n\n    # GLSZM\n    results.update(\n        calculate_glszm_features(\n            disc_array, mask_array, n_bins, glszm_matrix=texture_matrices[\"glszm\"]\n        )\n    )\n\n    # GLDZM\n    results.update(\n        calculate_gldzm_features(\n            disc_array,\n            mask_array,\n            n_bins,\n            gldzm_matrix=texture_matrices[\"gldzm\"],\n            distance_mask=(\n                distance_mask_array if distance_mask_array is not None else mask_array\n            ),\n        )\n    )\n\n    # NGTDM\n    results.update(\n        calculate_ngtdm_features(\n            disc_array,\n            mask_array,\n            n_bins,\n            ngtdm_matrices=(texture_matrices[\"ngtdm_s\"], texture_matrices[\"ngtdm_n\"]),\n        )\n    )\n    # NGLDM\n    results.update(\n        calculate_ngldm_features(\n            disc_array, mask_array, n_bins, ngldm_matrix=texture_matrices[\"ngldm\"]\n        )\n    )\n\n    return results\n</code></pre>"},{"location":"api/features/texture/#pictologics.features.texture.calculate_all_texture_matrices","title":"<code>calculate_all_texture_matrices(data, mask, n_bins, distance_mask=None, ngldm_alpha=0)</code>","text":"<p>Calculate all texture matrices (GLCM, GLRLM, GLSZM, GLDZM, NGTDM, NGLDM) in an optimized single pass.</p> <p>This function serves as the computational backbone for texture analysis. It computes the raw matrices required to extract specific texture features. By aggregating these calculations, it minimizes the number of passes over the image data, significantly improving performance.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>The 3D image array containing discretised grey levels. Values should be integers in the range [1, n_bins].</p> required <code>mask</code> <code>ndarray</code> <p>The 3D binary mask array defining the Region of Interest (ROI). Must have the same shape as <code>data</code>. Non-zero values indicate the ROI.</p> required <code>n_bins</code> <code>int</code> <p>The number of grey levels used for discretization (e.g., 16, 32, 64). This determines the size of the resulting matrices.</p> required <code>distance_mask</code> <code>Optional[ndarray]</code> <p>Optional mask used to calculate the distance map for GLDZM. If None, <code>mask</code> is used. This allows calculating distances based on the morphological mask while analyzing intensities from the intensity mask (e.g., after outlier filtering).</p> <code>None</code> <code>ngldm_alpha</code> <code>int</code> <p>The coarseness parameter \u03b1 for NGLDM calculation. Two grey levels are considered dependent if their absolute difference is \u2264 \u03b1. Default is 0 (exact match), which is the IBSI standard. Use \u03b1=1 for tolerance of \u00b11 grey level difference.</p> <code>0</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the calculated texture matrices: - 'glcm' (np.ndarray): Grey Level Co-occurrence Matrix. Shape: (n_dirs, n_bins, n_bins). - 'glrlm' (np.ndarray): Grey Level Run Length Matrix. Shape: (n_dirs, n_bins, max_run_length). - 'ngtdm_s' (np.ndarray): NGTDM Sum of absolute differences. Shape: (n_bins,). - 'ngtdm_n' (np.ndarray): NGTDM Number of valid voxels. Shape: (n_bins,). - 'ngldm' (np.ndarray): Neighbouring Grey Level Dependence Matrix. Shape: (n_bins, n_dependence). - 'glszm' (np.ndarray): Grey Level Size Zone Matrix. Shape: (n_bins, max_zone_size). - 'gldzm' (np.ndarray): Grey Level Distance Zone Matrix. Shape: (n_bins, max_distance).</p> <p>Example: Example:     <pre><code>import numpy as np\ndata = np.random.randint(1, 33, (50, 50, 50))\nmask = np.ones((50, 50, 50))\nmatrices = calculate_all_texture_matrices(data, mask, n_bins=32)\nprint(matrices['glcm'].shape)\n# (13, 32, 32)\n</code></pre></p> Source code in <code>pictologics/features/texture.py</code> <pre><code>def calculate_all_texture_matrices(\n    data: np.ndarray,\n    mask: np.ndarray,\n    n_bins: int,\n    distance_mask: Optional[np.ndarray] = None,\n    ngldm_alpha: int = 0,\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Calculate all texture matrices (GLCM, GLRLM, GLSZM, GLDZM, NGTDM, NGLDM) in an optimized single pass.\n\n    This function serves as the computational backbone for texture analysis. It computes the raw\n    matrices required to extract specific texture features. By aggregating these calculations,\n    it minimizes the number of passes over the image data, significantly improving performance.\n\n    Args:\n        data (np.ndarray): The 3D image array containing discretised grey levels.\n            Values should be integers in the range [1, n_bins].\n        mask (np.ndarray): The 3D binary mask array defining the Region of Interest (ROI).\n            Must have the same shape as `data`. Non-zero values indicate the ROI.\n        n_bins (int): The number of grey levels used for discretization (e.g., 16, 32, 64).\n            This determines the size of the resulting matrices.\n        distance_mask (Optional[np.ndarray]): Optional mask used to calculate the distance map for GLDZM.\n            If None, `mask` is used. This allows calculating distances based on the morphological mask\n            while analyzing intensities from the intensity mask (e.g., after outlier filtering).\n        ngldm_alpha (int): The coarseness parameter \u03b1 for NGLDM calculation. Two grey levels are\n            considered dependent if their absolute difference is \u2264 \u03b1. Default is 0 (exact match),\n            which is the IBSI standard. Use \u03b1=1 for tolerance of \u00b11 grey level difference.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the calculated texture matrices:\n            - 'glcm' (np.ndarray): Grey Level Co-occurrence Matrix. Shape: (n_dirs, n_bins, n_bins).\n            - 'glrlm' (np.ndarray): Grey Level Run Length Matrix. Shape: (n_dirs, n_bins, max_run_length).\n            - 'ngtdm_s' (np.ndarray): NGTDM Sum of absolute differences. Shape: (n_bins,).\n            - 'ngtdm_n' (np.ndarray): NGTDM Number of valid voxels. Shape: (n_bins,).\n            - 'ngldm' (np.ndarray): Neighbouring Grey Level Dependence Matrix. Shape: (n_bins, n_dependence).\n            - 'glszm' (np.ndarray): Grey Level Size Zone Matrix. Shape: (n_bins, max_zone_size).\n            - 'gldzm' (np.ndarray): Grey Level Distance Zone Matrix. Shape: (n_bins, max_distance).\n\n    Example:\n    Example:\n        ```python\n        import numpy as np\n        data = np.random.randint(1, 33, (50, 50, 50))\n        mask = np.ones((50, 50, 50))\n        matrices = calculate_all_texture_matrices(data, mask, n_bins=32)\n        print(matrices['glcm'].shape)\n        # (13, 32, 32)\n        ```\n    \"\"\"\n    # Fast exit for empty ROI\n    if not bool(np.any(mask != 0)):\n        return {\n            \"glcm\": np.zeros((13, n_bins, n_bins), dtype=np.uint64),\n            \"glrlm\": np.zeros((13, n_bins, 1), dtype=np.uint64),\n            \"ngtdm_s\": np.zeros((n_bins,), dtype=np.float64),\n            \"ngtdm_n\": np.zeros((n_bins,), dtype=np.float64),\n            \"ngldm\": np.zeros((n_bins, 27), dtype=np.uint64),\n            \"glszm\": np.zeros((n_bins, 1), dtype=np.uint32),\n            \"gldzm\": np.zeros((n_bins, 1), dtype=np.uint32),\n        }\n\n    # Crop to ROI bounding box (union with distance_mask when provided) to reduce memory traffic.\n    data_c, mask_c, distmask_c = _maybe_crop_to_bbox(data, mask, distance_mask)\n\n    # Use a compact mask representation for kernels.\n    if mask_c.dtype == np.uint8:\n        mask_u8 = mask_c\n    else:\n        mask_u8 = (mask_c != 0).astype(np.uint8)\n    # 1. Local Features (GLCM, GLRLM, NGTDM, NGLDM)\n    # Pre-cast data to smallest possible int type (0-based)\n    # Input data is 1-based, so we subtract 1.\n    if n_bins &lt;= 256:\n        data_int = (data_c - 1).astype(np.uint8)\n    else:\n        data_int = (data_c - 1).astype(np.int32)\n\n    # Determine n_threads for JIT call\n    try:\n        n_threads = int(numba.config.NUMBA_NUM_THREADS)\n    except (ValueError, TypeError):\n        n_threads = 1  # Fallback\n\n    glcm, glrlm, ngtdm_s, ngtdm_n, ngldm = _calculate_local_features_numba(\n        data_int,\n        mask_u8,\n        n_bins,\n        calc_glcm=True,\n        calc_glrlm=True,\n        calc_ngtdm=True,\n        calc_ngldm=True,\n        offsets_26=OFFSETS_26,\n        directions_13=DIRECTIONS_13,\n        ngldm_alpha=ngldm_alpha,\n        n_threads=n_threads,\n    )\n\n    # 2. Zone Features (GLSZM, GLDZM)\n    # Pre-calculate distance map for GLDZM\n    # Use distance_mask if provided, else mask\n    d_mask = distmask_c if distmask_c is not None else mask_u8\n\n    # Pad the mask with 0s to ensure the image border is treated as an edge.\n    mask_bool = d_mask &gt; 0\n    mask_padded = np.pad(mask_bool, 1, mode=\"constant\", constant_values=0)\n    dist_map_padded = distance_transform_cdt(mask_padded, metric=\"taxicab\").astype(\n        np.int32\n    )\n    dist_map = dist_map_padded[1:-1, 1:-1, 1:-1]\n\n    glszm, gldzm = calculate_zone_features(\n        data_c,\n        mask_u8,\n        dist_map,\n        n_bins,\n        calc_glszm=True,\n        calc_gldzm=True,\n    )\n\n    return {\n        \"glcm\": glcm,\n        \"glrlm\": glrlm,\n        \"ngtdm_s\": ngtdm_s,\n        \"ngtdm_n\": ngtdm_n,\n        \"ngldm\": ngldm,\n        \"glszm\": glszm,\n        \"gldzm\": gldzm,\n    }\n</code></pre>"},{"location":"api/features/texture/#pictologics.features.texture.calculate_glcm_features","title":"<code>calculate_glcm_features(data, mask, n_bins, glcm_matrix=None)</code>","text":"<p>Calculate Grey Level Co-occurrence Matrix (GLCM) features.</p> <p>The GLCM describes the second-order statistical distribution of grey levels in the ROI. It counts how often pairs of grey levels occur at a specific distance and direction. This implementation computes features based on the 3D merged GLCM (averaged over all 13 directions), making the features rotationally invariant.</p> <p>IBSI Reference: Section 3.6 (Grey Level Co-occurrence Based Features).</p> <p>Mathematical Definition: Let $P(i,j)$ be the co-occurrence matrix, where $i$ and $j$ are grey levels. The matrix is normalized such that $\\sum_{i,j} P(i,j) = 1$.</p> <p>Calculated Features: *   Joint Maximum (GYBY) *   Joint Average (60VM) *   Joint Variance (UR99) *   Joint Entropy (TU9B) *   Difference Average (TF7R) *   Difference Variance (D3YU) *   Difference Entropy (NTRS) *   Sum Average (ZGXS) *   Sum Variance (OEEB) *   Sum Entropy (P6QZ) *   Angular Second Moment (8ZQL) *   Contrast (ACUI) *   Dissimilarity (8S9J) *   Inverse Difference (IB1Z) *   Normalised Inverse Difference (NDRX) *   Inverse Difference Moment (WF0Z) *   Normalised Inverse Difference Moment (1QCO) *   Inverse Variance (E8JP) *   Correlation (NI2N) *   Autocorrelation (QWB0) *   Cluster Tendency (DG8W) *   Cluster Shade (7NFM) *   Cluster Prominence (AE86) *   Information Correlation 1 (R8DG) *   Information Correlation 2 (JN9H)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>The 3D image array containing discretised grey levels.</p> required <code>mask</code> <code>ndarray</code> <p>The 3D binary mask array defining the ROI.</p> required <code>n_bins</code> <code>int</code> <p>The number of grey levels.</p> required <code>glcm_matrix</code> <code>Optional[ndarray]</code> <p>Pre-calculated GLCM matrix. If provided, <code>data</code> and <code>mask</code> are ignored for matrix calculation, but <code>data</code> is still used for <code>Ng</code> estimation if needed. If None, the matrix is calculated from scratch.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>dict[str, float]: A dictionary of calculated GLCM features, keyed by their name and IBSI code. Example keys: 'joint_maximum_GYBY', 'contrast_ACUI', 'correlation_NI2N'.</p> Example <p><pre><code>import numpy as np\n# ... assuming data and mask defined ...\nfeatures = calculate_glcm_features(data, mask, n_bins=32)\nprint(features['contrast_ACUI'])\n</code></pre> 12.5</p> Source code in <code>pictologics/features/texture.py</code> <pre><code>def calculate_glcm_features(\n    data: np.ndarray,\n    mask: np.ndarray,\n    n_bins: int,\n    glcm_matrix: Optional[np.ndarray] = None,\n) -&gt; dict[str, float]:\n    r\"\"\"\n    Calculate Grey Level Co-occurrence Matrix (GLCM) features.\n\n    The GLCM describes the second-order statistical distribution of grey levels in the ROI.\n    It counts how often pairs of grey levels occur at a specific distance and direction.\n    This implementation computes features based on the 3D merged GLCM (averaged over all 13 directions),\n    making the features rotationally invariant.\n\n    **IBSI Reference**: Section 3.6 (Grey Level Co-occurrence Based Features).\n\n    **Mathematical Definition**:\n    Let $P(i,j)$ be the co-occurrence matrix, where $i$ and $j$ are grey levels.\n    The matrix is normalized such that $\\sum_{i,j} P(i,j) = 1$.\n\n    **Calculated Features**:\n    *   Joint Maximum (GYBY)\n    *   Joint Average (60VM)\n    *   Joint Variance (UR99)\n    *   Joint Entropy (TU9B)\n    *   Difference Average (TF7R)\n    *   Difference Variance (D3YU)\n    *   Difference Entropy (NTRS)\n    *   Sum Average (ZGXS)\n    *   Sum Variance (OEEB)\n    *   Sum Entropy (P6QZ)\n    *   Angular Second Moment (8ZQL)\n    *   Contrast (ACUI)\n    *   Dissimilarity (8S9J)\n    *   Inverse Difference (IB1Z)\n    *   Normalised Inverse Difference (NDRX)\n    *   Inverse Difference Moment (WF0Z)\n    *   Normalised Inverse Difference Moment (1QCO)\n    *   Inverse Variance (E8JP)\n    *   Correlation (NI2N)\n    *   Autocorrelation (QWB0)\n    *   Cluster Tendency (DG8W)\n    *   Cluster Shade (7NFM)\n    *   Cluster Prominence (AE86)\n    *   Information Correlation 1 (R8DG)\n    *   Information Correlation 2 (JN9H)\n\n    Args:\n        data (np.ndarray): The 3D image array containing discretised grey levels.\n        mask (np.ndarray): The 3D binary mask array defining the ROI.\n        n_bins (int): The number of grey levels.\n        glcm_matrix (Optional[np.ndarray]): Pre-calculated GLCM matrix. If provided, `data` and `mask`\n            are ignored for matrix calculation, but `data` is still used for `Ng` estimation if needed.\n            If None, the matrix is calculated from scratch.\n\n    Returns:\n        dict[str, float]: A dictionary of calculated GLCM features, keyed by their name and IBSI code.\n            Example keys: 'joint_maximum_GYBY', 'contrast_ACUI', 'correlation_NI2N'.\n\n    Example:\n        ```python\n        import numpy as np\n        # ... assuming data and mask defined ...\n        features = calculate_glcm_features(data, mask, n_bins=32)\n        print(features['contrast_ACUI'])\n        ```\n        12.5\n    \"\"\"\n    if glcm_matrix is None:\n        data_c, mask_c, _ = _maybe_crop_to_bbox(data, mask, None)\n        if mask_c.dtype == np.uint8:\n            mask_u8 = mask_c\n        else:\n            mask_u8 = (mask_c != 0).astype(np.uint8)\n\n        if n_bins &lt;= 256:\n            data_int = (data_c - 1).astype(np.uint8)\n        else:\n            data_int = (data_c - 1).astype(np.int32)\n\n        # Determine n_threads for JIT call\n        try:\n            n_threads = int(numba.config.NUMBA_NUM_THREADS)\n        except (ValueError, TypeError):\n            n_threads = 1  # Fallback\n\n        # Call combined kernel to calculate only GLCM\n        glcm, _, _, _, _ = _calculate_local_features_numba(\n            data_int,\n            mask_u8,\n            n_bins,\n            calc_glcm=True,\n            calc_glrlm=False,\n            calc_ngtdm=False,\n            calc_ngldm=False,\n            offsets_26=OFFSETS_26,\n            directions_13=DIRECTIONS_13,\n            ngldm_alpha=0,\n            n_threads=n_threads,\n        )\n    else:\n        glcm = glcm_matrix\n\n    # Merge (Sum) -&gt; IAZD\n    glcm_sum = np.sum(glcm, axis=0)\n    glcm_sym = glcm_sum + glcm_sum.T\n\n    # Normalize\n    total_sum = np.sum(glcm_sym)\n    if total_sum == 0:\n        return {}\n\n    P = glcm_sym / total_sum\n\n    # Indices (0-based from np.indices, convert to 1-based for IBSI)\n    i_idx, j_idx = np.indices((n_bins, n_bins))\n    I = i_idx + 1  # noqa: E741\n    J = j_idx + 1\n\n    features = {}\n\n    # Joint Maximum - GYBY\n    features[\"joint_maximum_GYBY\"] = np.max(P)\n\n    # Joint Average - 60VM\n    features[\"joint_average_60VM\"] = np.sum(I * P)\n\n    # Joint Variance - UR99\n    mu = features[\"joint_average_60VM\"]\n    features[\"joint_variance_UR99\"] = np.sum(((I - mu) ** 2) * P)\n\n    # Joint Entropy - TU9B\n    mask_p = P &gt; 0\n    features[\"joint_entropy_TU9B\"] = -np.sum(P[mask_p] * np.log2(P[mask_p]))\n\n    # Difference Average - TF7R\n    k_diff = np.abs(I - J)\n    features[\"difference_average_TF7R\"] = np.sum(k_diff * P)\n\n    # Optimized using bincount\n    k_diff_flat = k_diff.ravel().astype(np.int32)\n    P_flat = P.ravel()\n    p_diff = np.bincount(k_diff_flat, weights=P_flat)\n\n    mu_diff = features[\"difference_average_TF7R\"]\n    k_vals = np.arange(n_bins)\n    features[\"difference_variance_D3YU\"] = np.sum(((k_vals - mu_diff) ** 2) * p_diff)\n\n    # Difference Entropy - NTRS\n    mask_pd = p_diff &gt; 0\n    features[\"difference_entropy_NTRS\"] = -np.sum(\n        p_diff[mask_pd] * np.log2(p_diff[mask_pd])\n    )\n\n    # Sum Average - ZGXS\n    k_sum_grid = I + J\n\n    # Optimized using bincount\n    k_sum_flat = k_sum_grid.ravel().astype(np.int32)\n    # P_flat is already defined in Difference Variance block\n    p_sum_full = np.bincount(k_sum_flat, weights=P_flat)\n\n    # Slice from 2.\n    p_sum = p_sum_full[2:]\n\n    k_vals_sum = np.arange(2, 2 * n_bins + 1)\n    features[\"sum_average_ZGXS\"] = np.sum(k_vals_sum * p_sum)\n\n    # Sum Variance - OEEB\n    mu_sum = features[\"sum_average_ZGXS\"]\n    features[\"sum_variance_OEEB\"] = np.sum(((k_vals_sum - mu_sum) ** 2) * p_sum)\n\n    # Sum Entropy - P6QZ\n    mask_ps = p_sum &gt; 0\n    features[\"sum_entropy_P6QZ\"] = -np.sum(p_sum[mask_ps] * np.log2(p_sum[mask_ps]))\n\n    # Angular Second Moment (Energy) - 8ZQL\n    features[\"angular_second_moment_8ZQL\"] = np.sum(P**2)\n\n    # Contrast - ACUI\n    features[\"contrast_ACUI\"] = np.sum(((I - J) ** 2) * P)\n\n    # Dissimilarity - 8S9J\n    features[\"dissimilarity_8S9J\"] = np.sum(np.abs(I - J) * P)\n\n    # Inverse Difference - IB1Z\n    features[\"inverse_difference_IB1Z\"] = np.sum(P / (1 + np.abs(I - J)))\n\n    roi_data = data[mask &gt; 0]\n    if len(roi_data) &gt; 0:\n        Ng_eff = int(np.max(roi_data) - np.min(roi_data) + 1)\n    else:\n        Ng_eff = 1  # Fallback\n\n    # Normalised Inverse Difference - NDRX\n    features[\"normalised_inverse_difference_NDRX\"] = np.sum(\n        P / (1 + np.abs(I - J) / Ng_eff)\n    )\n\n    # Inverse Difference Moment - WF0Z\n    features[\"inverse_difference_moment_WF0Z\"] = np.sum(P / (1 + (I - J) ** 2))\n\n    # Normalised Inverse Difference Moment - 1QCO\n    features[\"normalised_inverse_difference_moment_1QCO\"] = np.sum(\n        P / (1 + ((I - J) ** 2) / (Ng_eff**2))\n    )\n\n    # Inverse Variance - E8JP\n    mask_neq = I != J\n    features[\"inverse_variance_E8JP\"] = np.sum(\n        P[mask_neq] / ((I[mask_neq] - J[mask_neq]) ** 2)\n    )\n\n    # Correlation - NI2N\n    term1 = np.sum((I - mu) * (J - mu) * P)\n    if features[\"joint_variance_UR99\"] != 0:\n        features[\"correlation_NI2N\"] = term1 / features[\"joint_variance_UR99\"]\n    else:\n        features[\"correlation_NI2N\"] = (\n            1.0  # Or NaN? IBSI doesn't specify for 0 variance.\n        )\n\n    # Autocorrelation - QWB0\n    features[\"autocorrelation_QWB0\"] = np.sum(I * J * P)\n\n    # Cluster Tendency - DG8W\n    features[\"cluster_tendency_DG8W\"] = np.sum(((I + J - 2 * mu) ** 2) * P)\n\n    # Cluster Shade - 7NFM\n    features[\"cluster_shade_7NFM\"] = np.sum(((I + J - 2 * mu) ** 3) * P)\n\n    # Cluster Prominence - AE86\n    features[\"cluster_prominence_AE86\"] = np.sum(((I + J - 2 * mu) ** 4) * P)\n\n    # Information Correlation 1 - R8DG\n    HXY = features[\"joint_entropy_TU9B\"]\n    p_x = np.sum(P, axis=1)\n    mask_px = p_x &gt; 0\n    HX = -np.sum(p_x[mask_px] * np.log2(p_x[mask_px]))\n\n    HXY1 = -np.sum(P[mask_p] * np.log2(p_x[I[mask_p] - 1] * p_x[J[mask_p] - 1]))\n\n    if HX != 0:\n        features[\"information_correlation_1_R8DG\"] = (HXY - HXY1) / HX\n    else:\n        features[\"information_correlation_1_R8DG\"] = np.nan\n\n    # Information Correlation 2 - JN9H\n    P_prod = np.outer(p_x, p_x)\n    mask_prod = P_prod &gt; 0\n    HXY2 = -np.sum(P_prod[mask_prod] * np.log2(P_prod[mask_prod]))\n\n    features[\"information_correlation_2_JN9H\"] = np.sqrt(1 - np.exp(-2 * (HXY2 - HXY)))\n    return features\n</code></pre>"},{"location":"api/features/texture/#pictologics.features.texture.calculate_gldzm_features","title":"<code>calculate_gldzm_features(data, mask, n_bins, gldzm_matrix=None, distance_mask=None)</code>","text":"<p>Calculate Grey Level Distance Zone Matrix (GLDZM) features.</p> <p>The GLDZM counts the number of zones of linked voxels with the same grey level, categorized by the distance of the zone from the ROI border. This captures information about the spatial distribution of textures relative to the boundary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>The 3D image array containing discretised grey levels.</p> required <code>mask</code> <code>ndarray</code> <p>The 3D binary mask array defining the ROI.</p> required <code>n_bins</code> <code>int</code> <p>The number of grey levels.</p> required <code>gldzm_matrix</code> <code>Optional[ndarray]</code> <p>Pre-calculated GLDZM matrix.</p> <code>None</code> <code>distance_mask</code> <code>Optional[ndarray]</code> <p>Optional mask used to calculate the distance map. If None, <code>mask</code> is used. This allows calculating distances based on the morphological mask while analyzing intensities from the intensity mask (e.g., after outlier filtering).</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>dict[str, float]: A dictionary of calculated GLDZM features. Example keys: 'small_distance_emphasis_0GBI', 'zone_distance_entropy_GBDU'.</p> Source code in <code>pictologics/features/texture.py</code> <pre><code>def calculate_gldzm_features(\n    data: np.ndarray,\n    mask: np.ndarray,\n    n_bins: int,\n    gldzm_matrix: Optional[np.ndarray] = None,\n    distance_mask: Optional[np.ndarray] = None,\n) -&gt; dict[str, float]:\n    \"\"\"\n    Calculate Grey Level Distance Zone Matrix (GLDZM) features.\n\n    The GLDZM counts the number of zones of linked voxels with the same grey level,\n    categorized by the distance of the zone from the ROI border.\n    This captures information about the spatial distribution of textures relative to the boundary.\n\n    Args:\n        data (np.ndarray): The 3D image array containing discretised grey levels.\n        mask (np.ndarray): The 3D binary mask array defining the ROI.\n        n_bins (int): The number of grey levels.\n        gldzm_matrix (Optional[np.ndarray]): Pre-calculated GLDZM matrix.\n        distance_mask (Optional[np.ndarray]): Optional mask used to calculate the distance map.\n            If None, `mask` is used. This allows calculating distances based on the morphological mask\n            while analyzing intensities from the intensity mask (e.g., after outlier filtering).\n\n    Returns:\n        dict[str, float]: A dictionary of calculated GLDZM features.\n            Example keys: 'small_distance_emphasis_0GBI', 'zone_distance_entropy_GBDU'.\n    \"\"\"\n    if gldzm_matrix is None:\n        # Calculate distance map\n        # Use distance_mask if provided, else mask\n        d_mask = distance_mask if distance_mask is not None else mask\n\n        # Pad the mask with 0s to ensure the image border is treated as an edge.\n        mask_bool = d_mask &gt; 0\n        mask_padded = np.pad(mask_bool, 1, mode=\"constant\", constant_values=0)\n        dist_map_padded = distance_transform_cdt(mask_padded, metric=\"taxicab\").astype(\n            np.int32\n        )\n        dist_map = dist_map_padded[1:-1, 1:-1, 1:-1]\n\n        _, gldzm = calculate_zone_features(\n            data,\n            mask,\n            dist_map,\n            n_bins,\n            calc_glszm=False,\n            calc_gldzm=True,\n        )\n    else:\n        gldzm = gldzm_matrix\n\n    N_zones = np.sum(gldzm)\n    if N_zones == 0:\n        return {}\n\n    P = gldzm / N_zones\n\n    n_g, n_d = gldzm.shape\n    i_idx, j_idx = np.indices((n_g, n_d))\n    I = i_idx + 1  # noqa: E741\n    J = j_idx + 1  # Distance\n\n    features = {}\n\n    # Small Distance Emphasis (SDE) - 0GBI\n    features[\"small_distance_emphasis_0GBI\"] = np.sum(P / (J**2))\n\n    # Large Distance Emphasis (LDE) - MB4I\n    features[\"large_distance_emphasis_MB4I\"] = np.sum(P * (J**2))\n\n    # Grey Level Non-Uniformity (GLNU) - VFT7\n    s_i = np.sum(gldzm, axis=1)\n    features[\"grey_level_non_uniformity_VFT7\"] = np.sum(s_i**2) / N_zones\n\n    # Normalised Grey Level Non-Uniformity (GLNN) - 7HP3\n    features[\"normalised_grey_level_non_uniformity_7HP3\"] = np.sum(s_i**2) / (\n        N_zones**2\n    )\n\n    # Zone Distance Non-Uniformity (ZDNU) - V294\n    s_j = np.sum(gldzm, axis=0)\n    features[\"zone_distance_non_uniformity_V294\"] = np.sum(s_j**2) / N_zones\n\n    # Normalised Zone Distance Non-Uniformity (ZDNN) - IATH\n    features[\"normalised_zone_distance_non_uniformity_IATH\"] = np.sum(s_j**2) / (\n        N_zones**2\n    )\n\n    # Zone Percentage (ZP) - VIWW\n    n_voxels = np.sum(mask)\n    features[\"zone_percentage_VIWW\"] = N_zones / n_voxels\n\n    # Grey Level Variance (GLV) - QK93\n    mu_i = np.sum(I * P)\n    features[\"grey_level_variance_QK93\"] = np.sum(((I - mu_i) ** 2) * P)\n\n    # Zone Distance Variance (ZDV) - 7WT1\n    mu_j = np.sum(J * P)\n    features[\"zone_distance_variance_7WT1\"] = np.sum(((J - mu_j) ** 2) * P)\n\n    # Zone Distance Entropy (ZDE) - GBDU\n    mask_p = P &gt; 0\n    features[\"zone_distance_entropy_GBDU\"] = -np.sum(P[mask_p] * np.log2(P[mask_p]))\n\n    # Low Grey Level Zone Emphasis (LGLZE) - S1RA\n    features[\"low_grey_level_zone_emphasis_S1RA\"] = np.sum(P / (I**2))\n\n    # High Grey Level Zone Emphasis (HGLZE) - K26C\n    features[\"high_grey_level_zone_emphasis_K26C\"] = np.sum(P * (I**2))\n\n    # Small Distance Low Grey Level Emphasis (SDLGLE) - RUVG\n    features[\"small_distance_low_grey_level_emphasis_RUVG\"] = np.sum(\n        P / ((I**2) * (J**2))\n    )\n\n    # Small Distance High Grey Level Emphasis (SDHGLE) - DKNJ\n    features[\"small_distance_high_grey_level_emphasis_DKNJ\"] = np.sum(\n        P * (I**2) / (J**2)\n    )\n\n    # Large Distance Low Grey Level Emphasis (LDLGLE) - A7WM\n    features[\"large_distance_low_grey_level_emphasis_A7WM\"] = np.sum(\n        P * (J**2) / (I**2)\n    )\n\n    # Large Distance High Grey Level Emphasis (LDHGLE) - KLTH\n    features[\"large_distance_high_grey_level_emphasis_KLTH\"] = np.sum(\n        P * (I**2) * (J**2)\n    )\n\n    return features\n</code></pre>"},{"location":"api/features/texture/#pictologics.features.texture.calculate_glrlm_features","title":"<code>calculate_glrlm_features(data, mask, n_bins, glrlm_matrix=None)</code>","text":"<p>Calculate Grey Level Run Length Matrix (GLRLM) features.</p> <p>The GLRLM quantifies grey level runs, which are defined as the length in number of pixels, of consecutive pixels that have the same grey level value. This implementation computes features based on the 3D merged GLRLM (averaged over all 13 directions).</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>The 3D image array containing discretised grey levels.</p> required <code>mask</code> <code>ndarray</code> <p>The 3D binary mask array defining the ROI.</p> required <code>n_bins</code> <code>int</code> <p>The number of grey levels.</p> required <code>glrlm_matrix</code> <code>Optional[ndarray]</code> <p>Pre-calculated GLRLM matrix.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>dict[str, float]: A dictionary of calculated GLRLM features. Example keys: 'short_runs_emphasis_22OV', 'grey_level_non_uniformity_R5YN'.</p> Source code in <code>pictologics/features/texture.py</code> <pre><code>def calculate_glrlm_features(\n    data: np.ndarray,\n    mask: np.ndarray,\n    n_bins: int,\n    glrlm_matrix: Optional[np.ndarray] = None,\n) -&gt; dict[str, float]:\n    \"\"\"\n    Calculate Grey Level Run Length Matrix (GLRLM) features.\n\n    The GLRLM quantifies grey level runs, which are defined as the length in number of pixels,\n    of consecutive pixels that have the same grey level value.\n    This implementation computes features based on the 3D merged GLRLM (averaged over all 13 directions).\n\n    Args:\n        data (np.ndarray): The 3D image array containing discretised grey levels.\n        mask (np.ndarray): The 3D binary mask array defining the ROI.\n        n_bins (int): The number of grey levels.\n        glrlm_matrix (Optional[np.ndarray]): Pre-calculated GLRLM matrix.\n\n    Returns:\n        dict[str, float]: A dictionary of calculated GLRLM features.\n            Example keys: 'short_runs_emphasis_22OV', 'grey_level_non_uniformity_R5YN'.\n    \"\"\"\n    if glrlm_matrix is None:\n        if n_bins &lt;= 256:\n            data_int = (data - 1).astype(np.uint8)\n        else:\n            data_int = (data - 1).astype(np.int32)  # pragma: no cover\n\n        # Determine n_threads for JIT call\n        try:\n            n_threads = int(numba.config.NUMBA_NUM_THREADS)\n        except (ValueError, TypeError):\n            n_threads = 1  # Fallback\n\n        # Call combined kernel\n        _, glrlm, _, _, _ = _calculate_local_features_numba(\n            data_int,\n            mask,\n            n_bins,\n            calc_glcm=False,\n            calc_glrlm=True,\n            calc_ngtdm=False,\n            calc_ngldm=False,\n            offsets_26=OFFSETS_26,\n            directions_13=DIRECTIONS_13,\n            ngldm_alpha=0,\n            n_threads=n_threads,\n        )\n    else:\n        glrlm = glrlm_matrix\n\n    # Merge (Sum) -&gt; IAZD\n    glrlm_sum = np.sum(glrlm, axis=0)\n\n    # Remove length 0 (column 0)\n    glrlm = glrlm_sum[:, 1:]\n\n    N_runs = np.sum(glrlm)\n    if N_runs == 0:\n        return {}\n\n    P = glrlm / N_runs\n\n    n_g, n_r = glrlm.shape\n    i_idx, j_idx = np.indices((n_g, n_r))\n    I = i_idx + 1  # noqa: E741\n    J = j_idx + 1\n\n    features = {}\n\n    # Short Run Emphasis (SRE) - 22OV\n    features[\"short_runs_emphasis_22OV\"] = np.sum(P / (J**2))\n\n    # Long Run Emphasis (LRE) - W4KF\n    features[\"long_runs_emphasis_W4KF\"] = np.sum(P * (J**2))\n\n    # Grey Level Non-Uniformity (GLNU) - R5YN\n    s_i = np.sum(glrlm, axis=1)\n    features[\"grey_level_non_uniformity_R5YN\"] = np.sum(s_i**2) / N_runs\n\n    # Normalised Grey Level Non-Uniformity (GLNN) - OVBL\n    features[\"normalised_grey_level_non_uniformity_OVBL\"] = np.sum(s_i**2) / (N_runs**2)\n\n    # Run Length Non-Uniformity (RLNU) - W92Y\n    s_j = np.sum(glrlm, axis=0)\n    features[\"run_length_non_uniformity_W92Y\"] = np.sum(s_j**2) / N_runs\n\n    # Normalised Run Length Non-Uniformity (RLNN) - IC23\n    features[\"normalised_run_length_non_uniformity_IC23\"] = np.sum(s_j**2) / (N_runs**2)\n\n    # Run Percentage (RP) - 9ZK5\n    n_voxels = np.sum(mask)\n    n_dirs = 13  # Fixed for 3D\n    features[\"run_percentage_9ZK5\"] = N_runs / (n_voxels * n_dirs)\n\n    # Grey Level Variance (GLV) - 8CE5\n    mu_i = np.sum(I * P)\n    features[\"grey_level_variance_8CE5\"] = np.sum(((I - mu_i) ** 2) * P)\n\n    # Run Length Variance (RLV) - SXLW\n    mu_j = np.sum(J * P)\n    features[\"run_length_variance_SXLW\"] = np.sum(((J - mu_j) ** 2) * P)\n\n    # Run Entropy (RE) - HJ9O\n    mask_p = P &gt; 0\n    features[\"run_entropy_HJ9O\"] = -np.sum(P[mask_p] * np.log2(P[mask_p]))\n\n    # Low Grey Level Run Emphasis (LGLRE) - V3SW\n    features[\"low_grey_level_run_emphasis_V3SW\"] = np.sum(P / (I**2))\n\n    # High Grey Level Run Emphasis (HGLRE) - G3QZ\n    features[\"high_grey_level_run_emphasis_G3QZ\"] = np.sum(P * (I**2))\n\n    # Short Run Low Grey Level Emphasis (SRLGLE) - HTZT\n    features[\"short_run_low_grey_level_emphasis_HTZT\"] = np.sum(P / ((I**2) * (J**2)))\n\n    # Short Run High Grey Level Emphasis (SRHGLE) - GD3A\n    features[\"short_run_high_grey_level_emphasis_GD3A\"] = np.sum(P * (I**2) / (J**2))\n\n    # Long Run Low Grey Level Emphasis (LRLGLE) - IVPO\n    features[\"long_run_low_grey_level_emphasis_IVPO\"] = np.sum(P * (J**2) / (I**2))\n\n    # Long Run High Grey Level Emphasis (LRHGLE) - 3KUM\n    features[\"long_run_high_grey_level_emphasis_3KUM\"] = np.sum(P * (I**2) * (J**2))\n\n    return features\n</code></pre>"},{"location":"api/features/texture/#pictologics.features.texture.calculate_glszm_features","title":"<code>calculate_glszm_features(data, mask, n_bins, glszm_matrix=None)</code>","text":"<p>Calculate Grey Level Size Zone Matrix (GLSZM) features.</p> <p>The GLSZM counts the number of zones (connected components) of linked voxels that share the same grey level intensity. A zone is defined as a group of connected voxels with the same grey level. This matrix is rotationally invariant by definition.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>The 3D image array containing discretised grey levels.</p> required <code>mask</code> <code>ndarray</code> <p>The 3D binary mask array defining the ROI.</p> required <code>n_bins</code> <code>int</code> <p>The number of grey levels.</p> required <code>glszm_matrix</code> <code>Optional[ndarray]</code> <p>Pre-calculated GLSZM matrix.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>dict[str, float]: A dictionary of calculated GLSZM features. Example keys: 'small_zone_emphasis_P001', 'zone_percentage_P30P'.</p> Source code in <code>pictologics/features/texture.py</code> <pre><code>def calculate_glszm_features(\n    data: np.ndarray,\n    mask: np.ndarray,\n    n_bins: int,\n    glszm_matrix: Optional[np.ndarray] = None,\n) -&gt; dict[str, float]:\n    \"\"\"\n    Calculate Grey Level Size Zone Matrix (GLSZM) features.\n\n    The GLSZM counts the number of zones (connected components) of linked voxels\n    that share the same grey level intensity. A zone is defined as a group of connected voxels\n    with the same grey level. This matrix is rotationally invariant by definition.\n\n    Args:\n        data (np.ndarray): The 3D image array containing discretised grey levels.\n        mask (np.ndarray): The 3D binary mask array defining the ROI.\n        n_bins (int): The number of grey levels.\n        glszm_matrix (Optional[np.ndarray]): Pre-calculated GLSZM matrix.\n\n    Returns:\n        dict[str, float]: A dictionary of calculated GLSZM features.\n            Example keys: 'small_zone_emphasis_P001', 'zone_percentage_P30P'.\n    \"\"\"\n    if glszm_matrix is None:\n        data_c, mask_c, _ = _maybe_crop_to_bbox(data, mask, None)\n        if mask_c.dtype == np.uint8:\n            mask_u8 = mask_c\n        else:\n            mask_u8 = (mask_c != 0).astype(np.uint8)\n\n        # We need dist_map for the combined kernel signature, even if unused for GLSZM\n        dummy_dist = np.zeros_like(data_c, dtype=np.int32)\n\n        glszm, _ = calculate_zone_features(\n            data_c, mask_u8, dummy_dist, n_bins, calc_glszm=True, calc_gldzm=False\n        )\n    else:\n        glszm = glszm_matrix\n\n    N_zones = np.sum(glszm)\n    if N_zones == 0:\n        return {}\n\n    P = glszm / N_zones\n\n    n_g, n_s = glszm.shape\n    i_idx, j_idx = np.indices((n_g, n_s))\n    I = i_idx + 1  # noqa: E741\n    J = j_idx + 1  # Zone size\n\n    features = {}\n\n    # Small Zone Emphasis (SZE) - P001\n    features[\"small_zone_emphasis_P001\"] = np.sum(P / (J**2))\n\n    # Large Zone Emphasis (LZE) - 48P8\n    features[\"large_zone_emphasis_48P8\"] = np.sum(P * (J**2))\n\n    # Grey Level Non-Uniformity (GLNU) - JNSA\n    s_i = np.sum(glszm, axis=1)\n    features[\"grey_level_non_uniformity_JNSA\"] = np.sum(s_i**2) / N_zones\n\n    # Normalised Grey Level Non-Uniformity (GLNN) - Y1RO\n    features[\"normalised_grey_level_non_uniformity_Y1RO\"] = np.sum(s_i**2) / (\n        N_zones**2\n    )\n\n    # Zone Size Non-Uniformity (ZSNU) - 4JP3\n    s_j = np.sum(glszm, axis=0)\n    features[\"zone_size_non_uniformity_4JP3\"] = np.sum(s_j**2) / N_zones\n\n    # Normalised Zone Size Non-Uniformity (ZSNN) - VB3A\n    features[\"normalised_zone_size_non_uniformity_VB3A\"] = np.sum(s_j**2) / (N_zones**2)\n\n    # Zone Percentage (ZP) - P30P\n    n_voxels = np.sum(mask)\n    features[\"zone_percentage_P30P\"] = N_zones / n_voxels\n\n    # Grey Level Variance (GLV) - BYLV\n    mu_i = np.sum(I * P)\n    features[\"grey_level_variance_BYLV\"] = np.sum(((I - mu_i) ** 2) * P)\n\n    # Zone Size Variance (ZSV) - 3NSA\n    mu_j = np.sum(J * P)\n    features[\"zone_size_variance_3NSA\"] = np.sum(((J - mu_j) ** 2) * P)\n\n    # Zone Size Entropy (ZSE) - GU8N\n    mask_p = P &gt; 0\n    features[\"zone_size_entropy_GU8N\"] = -np.sum(P[mask_p] * np.log2(P[mask_p]))\n\n    # Low Grey Level Zone Emphasis (LGLZE) - XMSY\n    features[\"low_grey_level_zone_emphasis_XMSY\"] = np.sum(P / (I**2))\n\n    # High Grey Level Zone Emphasis (HGLZE) - 5GN9\n    features[\"high_grey_level_zone_emphasis_5GN9\"] = np.sum(P * (I**2))\n\n    # Small Zone Low Grey Level Emphasis (SZLGLE) - 5RAI\n    features[\"small_zone_low_grey_level_emphasis_5RAI\"] = np.sum(P / ((I**2) * (J**2)))\n\n    # Small Zone High Grey Level Emphasis (SZHGLE) - HW1V\n    features[\"small_zone_high_grey_level_emphasis_HW1V\"] = np.sum(P * (I**2) / (J**2))\n\n    # Large Zone Low Grey Level Emphasis (LZLGLE) - YH51\n    features[\"large_zone_low_grey_level_emphasis_YH51\"] = np.sum(P * (J**2) / (I**2))\n\n    # Large Zone High Grey Level Emphasis (LZHGLE) - J17V\n    features[\"large_zone_high_grey_level_emphasis_J17V\"] = np.sum(P * (I**2) * (J**2))\n\n    return features\n</code></pre>"},{"location":"api/features/texture/#pictologics.features.texture.calculate_ngldm_features","title":"<code>calculate_ngldm_features(data, mask, n_bins, ngldm_matrix=None, ngldm_alpha=0)</code>","text":"<p>Calculate Neighbourhood Grey Level Dependence Matrix (NGLDM) features.</p> <p>The NGLDM captures the dependence of grey levels on their neighbours. A \"dependence\" is defined as a connected voxel having a similar grey level (within a tolerance \u03b1).</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>The 3D image array containing discretised grey levels.</p> required <code>mask</code> <code>ndarray</code> <p>The 3D binary mask array defining the ROI.</p> required <code>n_bins</code> <code>int</code> <p>The number of grey levels.</p> required <code>ngldm_matrix</code> <code>Optional[ndarray]</code> <p>Pre-calculated NGLDM matrix.</p> <code>None</code> <code>ngldm_alpha</code> <code>int</code> <p>The coarseness parameter \u03b1. Two grey levels are considered dependent if their absolute difference is \u2264 \u03b1. Default is 0 (exact match, IBSI standard).</p> <code>0</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>dict[str, float]: A dictionary of calculated NGLDM features. Example keys: 'low_dependence_emphasis_SODN', 'dependence_count_entropy_FCBV'.</p> Source code in <code>pictologics/features/texture.py</code> <pre><code>def calculate_ngldm_features(\n    data: np.ndarray,\n    mask: np.ndarray,\n    n_bins: int,\n    ngldm_matrix: Optional[np.ndarray] = None,\n    ngldm_alpha: int = 0,\n) -&gt; dict[str, float]:\n    \"\"\"\n    Calculate Neighbourhood Grey Level Dependence Matrix (NGLDM) features.\n\n    The NGLDM captures the dependence of grey levels on their neighbours.\n    A \"dependence\" is defined as a connected voxel having a similar grey level (within a tolerance \u03b1).\n\n    Args:\n        data (np.ndarray): The 3D image array containing discretised grey levels.\n        mask (np.ndarray): The 3D binary mask array defining the ROI.\n        n_bins (int): The number of grey levels.\n        ngldm_matrix (Optional[np.ndarray]): Pre-calculated NGLDM matrix.\n        ngldm_alpha (int): The coarseness parameter \u03b1. Two grey levels are considered dependent\n            if their absolute difference is \u2264 \u03b1. Default is 0 (exact match, IBSI standard).\n\n    Returns:\n        dict[str, float]: A dictionary of calculated NGLDM features.\n            Example keys: 'low_dependence_emphasis_SODN', 'dependence_count_entropy_FCBV'.\n    \"\"\"\n    if ngldm_matrix is None:\n        if n_bins &lt;= 256:\n            data_int = (data - 1).astype(np.uint8)\n        elif n_bins &lt;= 65536:\n            data_int = (data - 1).astype(np.uint16)\n        else:\n            data_int = (data - 1).astype(np.int32)  # pragma: no cover\n\n        # Determine n_threads for JIT call\n        try:\n            n_threads = int(numba.config.NUMBA_NUM_THREADS)\n        except (ValueError, TypeError):\n            n_threads = 1  # Fallback\n\n        _, _, _, _, ngldm = _calculate_local_features_numba(\n            data_int,\n            mask,\n            n_bins,\n            calc_glcm=False,\n            calc_glrlm=False,\n            calc_ngtdm=False,\n            calc_ngldm=True,\n            offsets_26=OFFSETS_26,\n            directions_13=DIRECTIONS_13,\n            ngldm_alpha=ngldm_alpha,\n            n_threads=n_threads,\n        )\n    else:\n        ngldm = ngldm_matrix\n\n    N_s = np.sum(ngldm)\n    if N_s == 0:\n        return {}\n\n    P = ngldm / N_s\n\n    n_g, n_d = ngldm.shape\n    i_idx, j_idx = np.indices((n_g, n_d))\n    I = i_idx + 1  # noqa: E741\n    J = j_idx + 1  # Dependence count\n\n    features = {}\n\n    # Low Dependence Emphasis (LDE) - SODN\n    features[\"low_dependence_emphasis_SODN\"] = np.sum(P / (J**2))\n\n    # High Dependence Emphasis (HDE) - IMOQ\n    features[\"high_dependence_emphasis_IMOQ\"] = np.sum(P * (J**2))\n\n    # Low Grey Level Count Emphasis (LGCE) - TL9H\n    features[\"low_grey_level_count_emphasis_TL9H\"] = np.sum(P / (I**2))\n\n    # High Grey Level Count Emphasis (HGCE) - OAE7\n    features[\"high_grey_level_count_emphasis_OAE7\"] = np.sum(P * (I**2))\n\n    # Low Dependence Low Grey Level Emphasis (LDLGE) - EQ3F\n    features[\"low_dependence_low_grey_level_emphasis_EQ3F\"] = np.sum(\n        P / ((I**2) * (J**2))\n    )\n\n    # Low Dependence High Grey Level Emphasis (LDHGE) - JA6D\n    features[\"low_dependence_high_grey_level_emphasis_JA6D\"] = np.sum(\n        P * (I**2) / (J**2)\n    )\n\n    # High Dependence Low Grey Level Emphasis (HDLGE) - NBZI\n    features[\"high_dependence_low_grey_level_emphasis_NBZI\"] = np.sum(\n        P * (J**2) / (I**2)\n    )\n\n    # High Dependence High Grey Level Emphasis (HDHGE) - 9QMG\n    features[\"high_dependence_high_grey_level_emphasis_9QMG\"] = np.sum(\n        P * (I**2) * (J**2)\n    )\n\n    # Grey Level Non-Uniformity - FP8K\n    s_i = np.sum(ngldm, axis=1)\n    features[\"grey_level_non_uniformity_FP8K\"] = np.sum(s_i**2) / N_s\n\n    # Normalised Grey Level Non-Uniformity - 5SPA\n    features[\"normalised_grey_level_non_uniformity_5SPA\"] = np.sum(s_i**2) / (N_s**2)\n\n    # Dependence Count Non-Uniformity - Z87G\n    s_j = np.sum(ngldm, axis=0)\n    features[\"dependence_count_non_uniformity_Z87G\"] = np.sum(s_j**2) / N_s\n\n    # Normalised Dependence Count Non-Uniformity - OKJI\n    features[\"normalised_dependence_count_non_uniformity_OKJI\"] = np.sum(s_j**2) / (\n        N_s**2\n    )\n\n    # Dependence Count Percentage - 6XV8\n    n_voxels = np.sum(mask)\n    features[\"dependence_count_percentage_6XV8\"] = N_s / n_voxels\n\n    # Grey Level Variance - 1PFV\n    mu_i = np.sum(I * P)\n    features[\"grey_level_variance_1PFV\"] = np.sum(((I - mu_i) ** 2) * P)\n\n    # Dependence Count Variance - DNX2\n    mu_j = np.sum(J * P)\n    features[\"dependence_count_variance_DNX2\"] = np.sum(((J - mu_j) ** 2) * P)\n\n    # Dependence Count Entropy - FCBV\n    mask_p = P &gt; 0\n    features[\"dependence_count_entropy_FCBV\"] = -np.sum(P[mask_p] * np.log2(P[mask_p]))\n\n    # Dependence Count Energy - CAS9\n    features[\"dependence_count_energy_CAS9\"] = np.sum(P**2)\n\n    return features\n</code></pre>"},{"location":"api/features/texture/#pictologics.features.texture.calculate_ngtdm_features","title":"<code>calculate_ngtdm_features(data, mask, n_bins, ngtdm_matrices=None)</code>","text":"<p>Calculate Neighbourhood Grey Tone Difference Matrix (NGTDM) features.</p> <p>The NGTDM quantifies the difference between a grey value and the average grey value of its neighbours. It captures the coarseness and contrast of the texture.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>The 3D image array containing discretised grey levels.</p> required <code>mask</code> <code>ndarray</code> <p>The 3D binary mask array defining the ROI.</p> required <code>n_bins</code> <code>int</code> <p>The number of grey levels.</p> required <code>ngtdm_matrices</code> <code>Optional[tuple[ndarray, ndarray]]</code> <p>Pre-calculated NGTDM matrices (sum of absolute differences <code>s</code>, and count <code>n</code>).</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>dict[str, float]: A dictionary of calculated NGTDM features. Example keys: 'coarseness_QCDE', 'contrast_65HE', 'busyness_NQ30'.</p> Source code in <code>pictologics/features/texture.py</code> <pre><code>def calculate_ngtdm_features(\n    data: np.ndarray,\n    mask: np.ndarray,\n    n_bins: int,\n    ngtdm_matrices: Optional[tuple[np.ndarray, np.ndarray]] = None,\n) -&gt; dict[str, float]:\n    \"\"\"\n    Calculate Neighbourhood Grey Tone Difference Matrix (NGTDM) features.\n\n    The NGTDM quantifies the difference between a grey value and the average grey value\n    of its neighbours. It captures the coarseness and contrast of the texture.\n\n    Args:\n        data (np.ndarray): The 3D image array containing discretised grey levels.\n        mask (np.ndarray): The 3D binary mask array defining the ROI.\n        n_bins (int): The number of grey levels.\n        ngtdm_matrices (Optional[tuple[np.ndarray, np.ndarray]]): Pre-calculated NGTDM matrices\n            (sum of absolute differences `s`, and count `n`).\n\n    Returns:\n        dict[str, float]: A dictionary of calculated NGTDM features.\n            Example keys: 'coarseness_QCDE', 'contrast_65HE', 'busyness_NQ30'.\n    \"\"\"\n    if ngtdm_matrices is None:\n        if n_bins &lt;= 256:\n            data_int = (data - 1).astype(np.uint8)\n        elif n_bins &lt;= 65536:\n            data_int = (data - 1).astype(np.uint16)\n        else:\n            data_int = (data - 1).astype(np.int32)  # pragma: no cover\n\n        # Determine n_threads for JIT call\n        try:\n            n_threads = int(numba.config.NUMBA_NUM_THREADS)\n        except (ValueError, TypeError):\n            n_threads = 1  # Fallback\n\n        _, _, s, n, _ = _calculate_local_features_numba(\n            data_int,\n            mask,\n            n_bins,\n            calc_glcm=False,\n            calc_glrlm=False,\n            calc_ngtdm=True,\n            calc_ngldm=False,\n            offsets_26=OFFSETS_26,\n            directions_13=DIRECTIONS_13,\n            ngldm_alpha=0,\n            n_threads=n_threads,\n        )\n    else:\n        s, n = ngtdm_matrices\n\n    # s[i] is sum of absolute differences for grey level i+1\n    # n[i] is number of voxels of grey level i+1 with valid neighborhood\n\n    N_vp = np.sum(n)\n    if N_vp == 0:\n        return {}\n\n    p = n / N_vp\n\n    # Indices\n    i_idx = np.arange(n_bins)\n    I = i_idx + 1  # noqa: E741\n\n    features = {}\n\n    # Filter for non-zero probabilities (required for Busyness, Complexity, Strength)\n    mask_p = p &gt; 0\n    p_nz = p[mask_p]\n    s_nz = s[mask_p]\n    I_nz = I[mask_p]\n\n    # Coarseness - QCDE\n    sum_ps = np.sum(p_nz * s_nz)\n    if sum_ps &gt; 1e-10:\n        features[\"coarseness_QCDE\"] = 1 / sum_ps\n    else:\n        features[\"coarseness_QCDE\"] = 1e6\n\n    # Contrast - 65HE\n    Ng_p = len(p_nz)\n\n    if Ng_p &gt; 1:\n        # Term 1: Dynamic range variance\n        Pi, Pj = np.meshgrid(p_nz, p_nz, indexing=\"ij\")\n        Ii, Ij = np.meshgrid(I_nz, I_nz, indexing=\"ij\")\n\n        term1_sum = np.sum(Pi * Pj * ((Ii - Ij) ** 2))\n        term1 = term1_sum / (Ng_p * (Ng_p - 1))\n\n        # Term 2: Intensity change\n        sum_s = np.sum(s)\n        term2 = sum_s / N_vp\n\n        features[\"contrast_65HE\"] = term1 * term2\n    else:\n        features[\"contrast_65HE\"] = 0.0\n\n    # Busyness - NQ30\n    IPi = I_nz * p_nz\n\n    # Grid\n    IPi_grid, IPj_grid = np.meshgrid(IPi, IPi, indexing=\"ij\")\n    denom_busyness = np.sum(np.abs(IPi_grid - IPj_grid))\n\n    if denom_busyness &gt; 1e-10:\n        features[\"busyness_NQ30\"] = sum_ps / denom_busyness\n    else:\n        features[\"busyness_NQ30\"] = 0.0\n\n    # Complexity - HDEZ\n    Pi, Pj = np.meshgrid(p_nz, p_nz, indexing=\"ij\")\n    Si, Sj = np.meshgrid(s_nz, s_nz, indexing=\"ij\")\n    Ii, Ij = np.meshgrid(I_nz, I_nz, indexing=\"ij\")\n\n    denom_comp = Pi + Pj\n    term_comp = np.abs(Ii - Ij) * (Pi * Si + Pj * Sj) / denom_comp\n\n    features[\"complexity_HDEZ\"] = (1 / N_vp) * np.sum(term_comp)\n\n    # Strength - 1X9X\n    sum_s = np.sum(s)\n\n    term_str = (Pi + Pj) * ((Ii - Ij) ** 2)\n    sum_term_str = np.sum(term_str)\n\n    if sum_s &gt; 1e-10:\n        features[\"strength_1X9X\"] = sum_term_str / sum_s\n    else:\n        features[\"strength_1X9X\"] = 0.0\n\n    return features\n</code></pre>"},{"location":"api/features/texture/#pictologics.features.texture.calculate_zone_features","title":"<code>calculate_zone_features(data, mask, dist_map, n_bins, calc_glszm=True, calc_gldzm=True)</code>","text":"<p>Wrapper for _calculate_zone_features_numba with buffer pooling.</p> <p>This function manages pre-allocated buffers to reduce memory allocation overhead for repeated calls (e.g., during batch processing).</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>3D discretized image data.</p> required <code>mask</code> <code>ndarray</code> <p>3D mask array (not modified - copied internally by JIT function).</p> required <code>dist_map</code> <code>ndarray</code> <p>3D distance map for GLDZM.</p> required <code>n_bins</code> <code>int</code> <p>Number of grey level bins.</p> required <code>calc_glszm</code> <code>bool</code> <p>Whether to calculate GLSZM.</p> <code>True</code> <code>calc_gldzm</code> <code>bool</code> <p>Whether to calculate GLDZM.</p> <code>True</code> <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>Tuple of (glszm, gldzm) matrices.</p> Source code in <code>pictologics/features/texture.py</code> <pre><code>def calculate_zone_features(\n    data: np.ndarray,\n    mask: np.ndarray,\n    dist_map: np.ndarray,\n    n_bins: int,\n    calc_glszm: bool = True,\n    calc_gldzm: bool = True,\n) -&gt; tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Wrapper for _calculate_zone_features_numba with buffer pooling.\n\n    This function manages pre-allocated buffers to reduce memory allocation\n    overhead for repeated calls (e.g., during batch processing).\n\n    Args:\n        data: 3D discretized image data.\n        mask: 3D mask array (not modified - copied internally by JIT function).\n        dist_map: 3D distance map for GLDZM.\n        n_bins: Number of grey level bins.\n        calc_glszm: Whether to calculate GLSZM.\n        calc_gldzm: Whether to calculate GLDZM.\n\n    Returns:\n        Tuple of (glszm, gldzm) matrices.\n    \"\"\"\n    # For zone features, the worst-case number of zones is bounded by ROI voxel count.\n    # Sizing buffers to full image volume is extremely costly for sparse ROIs.\n    max_zones = int(np.count_nonzero(mask))\n    if max_zones &lt; 1:\n        max_zones = 1\n\n    # Get pre-allocated buffers from pool\n    pool = _ZoneBufferPool.get_instance()\n    res_gl, res_size, res_dist, stack = pool.get_buffers(max_zones)\n\n    return cast(\n        tuple[np.ndarray, np.ndarray],\n        _calculate_zone_features_numba(\n            data,\n            mask,\n            dist_map,\n            n_bins,\n            res_gl,\n            res_size,\n            res_dist,\n            stack,\n            calc_glszm,\n            calc_gldzm,\n        ),\n    )\n</code></pre>"},{"location":"user_guide/case_examples/","title":"Case examples","text":"<p>This section provides practical, end-to-end examples for common Pictologics workflows. The goal is to show how to combine loading, preprocessing, feature extraction, and result export patterns into scripts you can reuse. Many of these common processing techniques are in development to make the batch processing of cases even more easy. Therefore check back often to see any of these processing steps being implemented into the core package.</p>"},{"location":"user_guide/case_examples/#case-1-batch-radiomics-from-a-folder-of-nifti-files-no-masks","title":"Case 1: Batch radiomics from a folder of NIfTI files (no masks)","text":""},{"location":"user_guide/case_examples/#scenario","title":"Scenario","text":"<p>You have a folder of NIfTI volumes where each file is a separate exported segmentation-like volume. There are no mask files.</p> <p>You want to:</p> <ul> <li>Process every <code>*.nii</code> / <code>*.nii.gz</code> file in a folder.</li> <li>Use the whole image as the initial ROI (because no mask is provided).</li> <li>Resample to 0.5\u00d70.5\u00d70.5 mm.</li> <li>Restrict the ROI to intensities in [-100, 3000] (CT HU example).</li> <li>Remove disjoint parts by keeping the largest connected component.</li> <li>Compute all radiomic feature families for four discretisation settings:</li> <li>FBN with <code>n_bins=8</code></li> <li>FBN with <code>n_bins=16</code></li> <li>FBS with <code>bin_width=8</code></li> <li>FBS with <code>bin_width=16</code></li> <li>Export a single wide CSV where:</li> <li>Each row is one input NIfTI file.</li> <li>Columns include metadata (e.g., filename) + all computed features.</li> <li>Save pipeline logs to a separate folder.</li> </ul>"},{"location":"user_guide/case_examples/#important-notes","title":"Important notes","text":"<ul> <li>Maskless pipeline runs: <code>RadiomicsPipeline.run(...)</code> accepts <code>mask=None</code>, <code>mask=\"\"</code>, or an omitted mask argument.   In that case, Pictologics generates a full (all-ones) ROI mask internally (whole-image ROI).</li> <li>Empty ROI is an error: If your preprocessing removes all voxels (e.g., a too-tight HU range), the pipeline raises   a clear error instead of silently returning empty outputs.</li> <li>Morphology on whole-image ROI: Shape features will describe the shape of the ROI mask.   With a maskless run, that ROI starts as the full image volume, then becomes whatever remains after resegmentation   and connected-component filtering. This is valid computationally, but make sure it matches your scientific intent.</li> <li>Sentinel value filtering: The <code>resegment</code> step with <code>range_min=-100</code> also filters out common DICOM sentinel   values (e.g., -1024, -2048) that represent missing/invalid data. This is the IBSI-recommended approach for   handling NA values in medical imaging data.</li> </ul>"},{"location":"user_guide/case_examples/#full-example-script","title":"Full example script","text":"<pre><code>from pathlib import Path\n\nfrom pictologics import RadiomicsPipeline\nfrom pictologics.results import format_results, save_results\n\ndef strip_nii_suffix(name):\n    \"\"\"Remove .nii or .nii.gz suffix from filename.\"\"\"\n    if name.endswith(\".nii.gz\"):\n        return name[: -len(\".nii.gz\")]\n    if name.endswith(\".nii\"):\n        return name[: -len(\".nii\")]\n    return name\n\ndef main():\n    # Configure paths\n    input_dir = Path(\"path/to/nifti_folder\")\n    output_csv = Path(\"results.csv\")\n    log_dir = Path(\"logs\")\n    log_dir.mkdir(parents=True, exist_ok=True)\n\n    # Define common preprocessing steps\n    base_steps = [\n        # Resample to 0.5mm isotropic. Round intensities to integers (useful for HU).\n        {\"step\": \"resample\", \"params\": {\"new_spacing\": (0.5, 0.5, 0.5), \"round_intensities\": True}},\n        # Exclude voxels outside standard HU range\n        {\"step\": \"resegment\", \"params\": {\"range_min\": -100, \"range_max\": 3000}},\n        # Keep only the largest connected component of the ROI mask\n        {\"step\": \"keep_largest_component\", \"params\": {\"apply_to\": \"morph\"}},\n    ]\n\n    # Shared feature extraction configuration\n    extract_all = {\n        \"step\": \"extract_features\",\n        \"params\": {\n            \"families\": [\"intensity\", \"morphology\", \"texture\", \"histogram\", \"ivh\"],\n            \"include_spatial_intensity\": False,\n            \"include_local_intensity\": False,\n        },\n    }\n\n    # Initialize the pipeline\n    pipeline = RadiomicsPipeline()\n\n    # Add 4 configurations (2 FBN, 2 FBS)\n    for n_bins in (8, 16):\n        pipeline.add_config(\n            f\"case1_fbn_{n_bins}\",\n            base_steps + [\n                {\"step\": \"discretise\", \"params\": {\"method\": \"FBN\", \"n_bins\": n_bins}},\n                extract_all,\n            ],\n        )\n\n    for bin_width in (8, 16):\n        pipeline.add_config(\n            f\"case1_fbs_{bin_width}\",\n            base_steps + [\n                {\"step\": \"discretise\", \"params\": {\"method\": \"FBS\", \"bin_width\": bin_width}},\n                extract_all,\n            ],\n        )\n\n    # Prepare for batch processing\n    rows = []\n    nifti_paths = sorted(input_dir.glob(\"*.nii*\"))\n    if not nifti_paths:\n        raise ValueError(f\"No NIfTI files found in: {input_dir}\")\n\n    # Process each NIfTI file\n    for path in nifti_paths:\n        subject_id = strip_nii_suffix(path.name)\n        pipeline.clear_log()\n\n        # Run pipeline (mask omitted -&gt; whole-image ROI)\n        results = pipeline.run(\n            image=str(path),\n            subject_id=subject_id,\n            config_names=[\"case1_fbn_8\", \"case1_fbn_16\", \"case1_fbs_8\", \"case1_fbs_16\"],\n        )\n\n        # Format results as flat dictionary and add metadata\n        row = format_results(\n            results,\n            fmt=\"wide\",\n            meta={\"subject_id\": subject_id, \"file\": str(path)}\n        )\n        rows.append(row)\n\n        # Save per-case logs\n        pipeline.save_log(str(log_dir / f\"{subject_id}.json\"))\n\n    # Consolidated export of all results\n    save_results(rows, output_csv)\n    print(f\"Wrote {len(rows)} rows to {output_csv}\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"user_guide/case_examples/#output-format","title":"Output format","text":"<ul> <li>One row per file.</li> <li>Columns include:</li> <li><code>subject_id</code></li> <li><code>file</code></li> <li>Feature columns prefixed by configuration name (e.g., <code>case1_fbn_8__mean_intensity_Q4LE</code>).</li> </ul>"},{"location":"user_guide/case_examples/#case-2-batch-radiomics-from-dicom-case-folders-image-segmentation","title":"Case 2: Batch radiomics from DICOM case folders (Image + Segmentation)","text":""},{"location":"user_guide/case_examples/#scenario_1","title":"Scenario","text":"<p>You have a folder of cases. Each case is a separate folder and contains two subfolders:</p> <ul> <li><code>Image/</code>: the DICOM image series (CT/MR/etc.), stored at an arbitrary depth.</li> <li><code>Segmentation/</code>: the DICOM segmentation, also stored at an arbitrary depth.</li> </ul> <p>You want to:</p> <ul> <li>For each case, recursively discover the DICOM series folders.</li> <li>Load the image series and segmentation series.</li> <li>Convert the segmentation to a binary ROI mask by keeping all voxels where the segmentation value is <code>&gt; 0</code> (handled automatically during loading).</li> <li>Resample to 1\u00d71\u00d71 mm.</li> <li>Do not apply intensity filtering/resegmentation, and do not keep the largest connected component.</li> <li>Compute all radiomic feature families for two discretisations:</li> <li>FBS with <code>bin_width=256</code></li> <li>FBN with <code>n_bins=64</code></li> <li>Export a long-format CSV (tidy data, one row per feature).</li> <li>Save pipeline logs into a separate folder (one JSON per case).</li> <li>Show a progress bar during batch processing.</li> </ul>"},{"location":"user_guide/case_examples/#notes","title":"Notes","text":"<ul> <li>Progress bar dependency: This example uses <code>tqdm</code>.<ul> <li>If you are running this outside the library repo, install it with <code>pip install tqdm</code>.</li> <li>If you are adding it to your Poetry-managed project, use <code>poetry add tqdm</code>.</li> </ul> </li> <li>Segmentation DICOM at arbitrary depth: The helper <code>_find_dicom_series_root(...)</code> looks for the subfolder with     the most <code>.dcm</code> files and uses that as the series root.</li> <li>Multiple masks in one SEG: If your segmentation DICOM encodes multiple labels (e.g., values 1..N), the     <code>_binarize_segmentation_mask(...)</code> step turns it into a single ROI by keeping all voxels where the value is <code>&gt; 0</code>.</li> <li>Multi-phase DICOM series: If your image series contains multiple phases (e.g., cardiac CT with 10%, 20%... phases),     use <code>get_dicom_phases()</code> to discover available phases and <code>dataset_index</code> to select one:     <pre><code>from pictologics.utilities import get_dicom_phases\n\nphases = get_dicom_phases(str(image_root))\nprint(f\"Found {len(phases)} phases\")\n# Load a specific phase (default is 0)\nimage = load_image(str(image_root), recursive=True, dataset_index=0)\n</code></pre></li> </ul>"},{"location":"user_guide/case_examples/#full-example-script_1","title":"Full example script","text":"<pre><code>from pathlib import Path\nimport numpy as np\nfrom pictologics import Image, RadiomicsPipeline, load_image, load_and_merge_images\nfrom pictologics.results import format_results, save_results\n\n\ndef main():\n    # Configure paths\n    cases_dir = Path(\"path/to/cases_root\")\n    output_csv = Path(\"dicom_results_long.csv\")\n    log_dir = Path(\"dicom_logs\")\n    log_dir.mkdir(parents=True, exist_ok=True)\n\n    # Find all case directories\n    case_dirs = sorted([p for p in cases_dir.iterdir() if p.is_dir()])\n    if not case_dirs:\n        raise ValueError(f\"No case folders found in: {cases_dir}\")\n\n    # Shared feature extraction settings\n    extract_all = {\n        \"step\": \"extract_features\",\n        \"params\": {\n            \"families\": [\"intensity\", \"morphology\", \"texture\", \"histogram\", \"ivh\"],\n            \"include_spatial_intensity\": False,\n            \"include_local_intensity\": False,\n        },\n    }\n\n    # Initialize the pipeline\n    pipeline = RadiomicsPipeline()\n\n    # Configuration A: Fixed Bin Size\n    pipeline.add_config(\n        \"case2_fbs_256\",\n        [\n            {\"step\": \"resample\", \"params\": {\"new_spacing\": (1.0, 1.0, 1.0)}},\n            {\"step\": \"discretise\", \"params\": {\"method\": \"FBS\", \"bin_width\": 256.0}},\n            extract_all,\n        ],\n    )\n\n    # Configuration B: Fixed Bin Number\n    pipeline.add_config(\n        \"case2_fbn_64\",\n        [\n            {\"step\": \"resample\", \"params\": {\"new_spacing\": (1.0, 1.0, 1.0)}},\n            {\"step\": \"discretise\", \"params\": {\"method\": \"FBN\", \"n_bins\": 64}},\n            extract_all,\n        ],\n    )\n\n    # Use tqdm for a progress bar\n    from tqdm import tqdm\n\n    rows = []\n    for case_dir in tqdm(case_dirs, desc=\"Radiomics (DICOM cases)\", unit=\"case\"):\n        subject_id = case_dir.name\n        image_root = case_dir / \"Image\"\n        seg_root = case_dir / \"Segmentation\"\n\n        # load_image with recursive=True finds the best series folder automatically\n        image = load_image(str(image_root), recursive=True)\n\n        # Load the segmentation using load_and_merge_images with binarize=True\n        # recursive=True ensures we find the DICOM series inside the Segmentation folder\n        mask = load_and_merge_images(\n            [str(seg_root)], \n            binarize=True, \n            recursive=True\n        )\n\n        pipeline.clear_log()\n\n        # Execute extraction for both configurations\n        results = pipeline.run(\n            image=image,\n            mask=mask,\n            subject_id=subject_id,\n            config_names=[\"case2_fbs_256\", \"case2_fbn_64\"],\n        )\n\n        # Format results and store\n        row = format_results(\n            results,\n            fmt=\"long\",  # Tidy format: [subject_id, config, feature_name, value]\n            meta={\n                \"subject_id\": subject_id,\n                \"image_root\": str(image_root),\n                \"seg_root\": str(seg_root),\n            },\n        )\n        rows.append(row)\n\n        # Save per-case logs\n        pipeline.save_log(str(log_dir / f\"{subject_id}.json\"))\n\n    # Final export\n    save_results(rows, output_csv)\n    print(f\"Wrote {len(rows)} rows to {output_csv}\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"user_guide/case_examples/#case-3-batch-radiomics-from-a-flat-nifti-folder-multiple-masks-per-image","title":"Case 3: Batch radiomics from a flat NIfTI folder (multiple masks per image)","text":""},{"location":"user_guide/case_examples/#scenario_2","title":"Scenario","text":"<p>You have a single large folder containing both images and masks as NIfTI files.</p> <ul> <li>Image files end with <code>_IMG</code> (e.g., <code>CASE001_IMG.nii.gz</code>).</li> <li>Mask files end with <code>MASKn</code> where <code>n</code> is a number (e.g., <code>CASE001_MASK1.nii.gz</code>, <code>CASE001_MASK2.nii.gz</code>).</li> <li>There can be multiple segmentation masks per image.</li> </ul> <p>You want to:</p> <ul> <li>For each image, automatically find all its corresponding masks.</li> <li>Merge all masks into a single ROI using <code>load_and_merge_images(...)</code>.</li> <li>Do not apply any preprocessing (no resampling, no thresholding, no connected components).</li> <li>Compute radiomics for the six standard discretisations (FBN 8/16/32 and FBS 8/16/32).</li> <li>Export a long-format JSON file for easy ingestion into NoSQL databases or web apps.</li> <li>Save logs for each case into a separate folder.</li> <li>Show a progress bar during batch processing.</li> </ul> <p>Tip</p> <p>Flexible Image Loading The <code>load_and_merge_images</code> function uses <code>load_image</code> for each path in its input list. This means you can merge: - Multiple NIfTI files (as shown here). - DICOM series folders. - Single DICOM slice files. - Or a mix of these formats, provided they share the same spatial geometry.</p> <p>You can also pass <code>recursive=True</code> (to search subfolders) or <code>dataset_index=N</code> (for 4D files) to control how each mask is loaded.</p>"},{"location":"user_guide/case_examples/#full-example-script_2","title":"Full example script","text":"<pre><code>from pathlib import Path\n\nimport numpy as np\n\nfrom pictologics import Image, RadiomicsPipeline, load_and_merge_images, load_image\nfrom pictologics.results import format_results, save_results\n\n\n\n\n\ndef strip_suffixes(name):\n    \"\"\"Strip .nii/.nii.gz and trailing _IMG to get a stable case id.\"\"\"\n    if name.endswith(\".nii.gz\"):\n        name = name[: -len(\".nii.gz\")]\n    elif name.endswith(\".nii\"):\n        name = name[: -len(\".nii\")]\n    if name.endswith(\"_IMG\"):\n        name = name[: -len(\"_IMG\")]\n    return name\n\n\ndef main():\n    # Configure paths\n    input_dir = Path(\"path/to/nifti_folder\")\n    output_file = Path(\"case3_results_long.json\")\n    log_dir = Path(\"case3_logs\")\n    log_dir.mkdir(parents=True, exist_ok=True)\n\n    # Use tqdm for a progress bar\n    from tqdm import tqdm\n\n    # Identify all images (files ending in _IMG)\n    image_paths = sorted(input_dir.glob(\"*_IMG.nii*\"))\n    if not image_paths:\n        raise ValueError(f\"No *_IMG NIfTI files found in: {input_dir}\")\n\n    # Initialize the pipeline\n    pipeline = RadiomicsPipeline()\n\n    # Shared feature extraction settings\n    extract_all = {\n        \"step\": \"extract_features\",\n        \"params\": {\n            \"families\": [\"intensity\", \"morphology\", \"texture\", \"histogram\", \"ivh\"],\n            \"include_spatial_intensity\": False,\n            \"include_local_intensity\": False,\n        },\n    }\n\n    # Add 6 target configurations (no preprocessing requested)\n    for n_bins in (8, 16, 32):\n        pipeline.add_config(\n            f\"case3_fbn_{n_bins}\",\n            [\n                {\"step\": \"discretise\", \"params\": {\"method\": \"FBN\", \"n_bins\": n_bins}},\n                extract_all,\n            ],\n        )\n\n    for bin_width in (8.0, 16.0, 32.0):\n        pipeline.add_config(\n            f\"case3_fbs_{int(bin_width)}\",\n            [\n                {\"step\": \"discretise\", \"params\": {\"method\": \"FBS\", \"bin_width\": bin_width}},\n                extract_all,\n            ],\n        )\n\n    target_configs = [\n        \"case3_fbn_8\", \"case3_fbn_16\", \"case3_fbn_32\",\n        \"case3_fbs_8\", \"case3_fbs_16\", \"case3_fbs_32\",\n    ]\n\n    # Process each image and its associated masks\n    rows = []\n    for img_path in tqdm(image_paths, desc=\"Radiomics (NIfTI images)\", unit=\"image\"):\n        subject_id = strip_suffixes(img_path.name)\n\n        # Find all corresponding masks (e.g., CASE001_MASK1.nii.gz, etc.)\n        mask_paths = sorted(input_dir.glob(f\"{subject_id}_MASK*.nii*\"))\n        if not mask_paths:\n            raise ValueError(f\"No masks found for {subject_id}\")\n\n        image = load_image(str(img_path))\n\n        # Merge multiple masks into one and ensure binary semantics\n        mask = load_and_merge_images(\n            [str(p) for p in mask_paths],\n            reference_image=image,\n            binarize=True\n        )\n\n        pipeline.clear_log()\n\n        # Run extraction for all target configurations\n        results = pipeline.run(\n            image=image,\n            mask=mask,\n            subject_id=subject_id,\n            config_names=target_configs,\n        )\n\n        # Format results and store metadata\n        row = format_results(\n            results,\n            fmt=\"long\",\n            meta={\n                \"subject_id\": subject_id,\n                \"image\": str(img_path),\n                \"masks\": \";\".join(str(p) for p in mask_paths),\n            },\n        )\n        rows.append(row)\n\n        # Save per-case logs\n        pipeline.save_log(str(log_dir / f\"{subject_id}.json\"))\n\n    # Consolidated export (save_results handles list of DataFrames for long format automatically)\n    save_results(rows, output_file)\n    print(f\"Wrote {len(rows)} cases to {output_file}\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"user_guide/case_examples/#case-4-parallel-batch-radiomics-from-dicom-cases-merge-multiple-segmentation-folders","title":"Case 4: Parallel batch radiomics from DICOM cases (merge multiple segmentation folders)","text":""},{"location":"user_guide/case_examples/#scenario_3","title":"Scenario","text":"<p>You have a folder of cases. Each case is a separate folder and contains:</p> <ul> <li><code>Image/</code>: the DICOM image series (CT/MR/etc.), stored at an arbitrary depth.</li> <li><code>Segmentation/</code>: multiple subfolders, each containing a segmentation series at an arbitrary depth.</li> </ul> <p>You want to:</p> <ul> <li>For each case, recursively discover the DICOM image series folder.</li> <li>Discover all segmentation series folders under <code>Segmentation/</code> and load them.</li> <li>Convert each segmentation to a binary mask (values <code>&gt; 0</code> become 1).</li> <li>Merge all binary masks into a single ROI mask per case.</li> <li>Apply all preprocessing steps supported by the pipeline (resample, resegment, outlier filtering,   intensity rounding, and largest connected component).</li> <li>Compute radiomics for six discretisations (FBN 8/16/32 and FBS 8/16/32).</li> <li>Run cases in parallel on multiple CPU cores, with a user-controlled <code>n_jobs</code>.</li> <li>Export a single wide JSON file (one object per case) and save per-case logs.</li> </ul>"},{"location":"user_guide/case_examples/#notes_1","title":"Notes","text":"<ul> <li>Progress bar dependency: This example uses <code>tqdm</code>.<ul> <li>If you are running this outside the library repo, install it with <code>pip install tqdm</code>.</li> <li>If you are adding it to your Poetry-managed project, use <code>poetry add tqdm</code>.</li> </ul> </li> <li>Multiprocessing requirement: On Windows/macOS, keep the parallel execution inside   <code>if __name__ == \"__main__\":</code> (as shown) to avoid process-spawn issues.</li> <li>JIT warmup in parallel workers: Pictologics performs a Numba JIT warmup at package import.     With <code>ProcessPoolExecutor</code>, each worker is a separate Python process, so warmup happens once per worker process     (on its first import of <code>pictologics</code>) and then stays warm for all cases that worker processes.     It is not re-run for every case unless you explicitly call <code>warmup_jit()</code> inside your per-case function.     You can disable auto-warmup via <code>PICTOLOGICS_DISABLE_WARMUP=1</code> if you prefer to skip the upfront cost.</li> <li>Preprocessing parameters are dataset-dependent: The <code>resegment</code> range here uses the CT HU example   <code>[-100, 3000]</code>. Adjust or remove it for non-CT data.</li> </ul>"},{"location":"user_guide/case_examples/#full-example-script_3","title":"Full example script","text":"<pre><code>from concurrent.futures import ProcessPoolExecutor, as_completed\nfrom pathlib import Path\nimport numpy as np\nfrom pictologics import Image, RadiomicsPipeline, load_image, load_and_merge_images\nfrom pictologics.results import format_results, save_results\n\n\ndef collect_segmentation_series_roots(seg_root):\n    \"\"\"Collect all segmentation series subfolders.\"\"\"\n    if not seg_root.exists():\n        raise ValueError(f\"Folder does not exist: {seg_root}\")\n\n    subdirs = sorted([p for p in seg_root.iterdir() if p.is_dir()])\n    if not subdirs:\n        return [seg_root]\n\n    return subdirs\n\ndef build_case4_pipeline():\n    \"\"\"Define the pipeline with preprocessing and all feature families.\"\"\"\n    pipeline = RadiomicsPipeline()\n\n    # Define standard CT preprocessing\n    preprocess_steps = [\n        {\"step\": \"resample\", \"params\": {\"new_spacing\": (1.0, 1.0, 1.0)}},\n        {\"step\": \"resegment\", \"params\": {\"range_min\": -100, \"range_max\": 3000}},\n        {\"step\": \"filter_outliers\", \"params\": {\"sigma\": 3.0}},\n        {\"step\": \"round_intensities\"},\n        {\"step\": \"keep_largest_component\", \"params\": {\"apply_to\": \"morph\"}},\n    ]\n\n    extract_all = {\n        \"step\": \"extract_features\",\n        \"params\": {\n            \"families\": [\"intensity\", \"morphology\", \"texture\", \"histogram\", \"ivh\"],\n            \"include_spatial_intensity\": False,\n            \"include_local_intensity\": False,\n        },\n    }\n\n    # Add discretisation variants\n    for n_bins in (8, 16, 32):\n        pipeline.add_config(\n            f\"case4_fbn_{n_bins}\",\n            preprocess_steps + [{\"step\": \"discretise\", \"params\": {\"method\": \"FBN\", \"n_bins\": n_bins}}, extract_all],\n        )\n\n    for bin_width in (8.0, 16.0, 32.0):\n        pipeline.add_config(\n            f\"case4_fbs_{int(bin_width)}\",\n            preprocess_steps + [{\"step\": \"discretise\", \"params\": {\"method\": \"FBS\", \"bin_width\": bin_width}}, extract_all],\n        )\n\n    config_names = [f\"case4_fbn_{b}\" for b in (8, 16, 32)] + [f\"case4_fbs_{b}\" for b in (8, 16, 32)]\n    return pipeline, config_names\n\ndef process_case(case_dir, log_dir):\n    \"\"\"Worker function for single case processing.\"\"\"\n    case_path = Path(case_dir)\n    subject_id = case_path.name\n    image_root = case_path / \"Image\"\n    seg_root = case_path / \"Segmentation\"\n\n    # Load image recursively\n    image = load_image(str(image_root), recursive=True)\n\n    # Load and merge all found segmentations\n    seg_roots = collect_segmentation_series_roots(seg_root)\n\n    # load_and_merge_images handles multiple paths, geometry checking, and binarization\n    try:\n        mask = load_and_merge_images(\n            [str(p) for p in seg_roots], \n            reference_image=image, \n            binarize=True, \n            recursive=True\n        )\n    except ValueError as e:\n         raise ValueError(f\"Failed to load/merge masks for {subject_id}: {e}\")\n\n    # Setup and run pipeline\n    pipeline, config_names = build_case4_pipeline()\n    pipeline.clear_log()\n    results = pipeline.run(image=image, mask=mask, subject_id=subject_id, config_names=config_names)\n\n    # Save results and log\n    Path(log_dir).mkdir(parents=True, exist_ok=True)\n    pipeline.save_log(str(Path(log_dir) / f\"{subject_id}.json\"))\n\n    return format_results(\n        results,\n        fmt=\"wide\",\n        meta={\n            \"subject_id\": subject_id,\n            \"image_root\": str(image_root),\n            \"seg_roots\": \";\".join(str(p) for p in seg_roots),\n        },\n    )\n\ndef main():\n    # Configure paths\n    cases_dir = Path(\"path/to/cases_root\")\n    output_file = Path(\"case4_parallel_results.json\")\n    log_dir = Path(\"case4_logs\")\n    log_dir.mkdir(parents=True, exist_ok=True)\n\n    # Start parallel processing\n    n_jobs = 4\n    case_dirs = sorted([p for p in cases_dir.iterdir() if p.is_dir()])\n    if not case_dirs:\n        raise ValueError(f\"No case folders found in: {cases_dir}\")\n\n    from tqdm import tqdm\n    rows = []\n    errors = []\n\n    # Map each case to the worker function\n    with ProcessPoolExecutor(max_workers=n_jobs) as executor:\n        futures = {\n            executor.submit(process_case, str(case_dir), str(log_dir)): case_dir\n            for case_dir in case_dirs\n        }\n\n        with tqdm(total=len(futures), desc=\"Radiomics (parallel cases)\", unit=\"case\") as pbar:\n            for fut in as_completed(futures):\n                case_dir = futures[fut]\n                try:\n                    rows.append(fut.result())\n                except Exception as e:\n                    errors.append((str(case_dir), repr(e)))\n                finally:\n                    pbar.update(1)\n\n    if errors:\n        msg = \"\\n\".join(f\"- {case}: {err}\" for case, err in errors)\n        raise RuntimeError(f\"One or more cases failed:\\n{msg}\")\n\n    # Final data export\n    save_results(rows, output_file)\n    print(f\"Wrote {len(rows)} cases to {output_file}\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"user_guide/case_examples/#case-5-batch-radiomics-from-dicom-seg-files-with-multiple-segments","title":"Case 5: Batch radiomics from DICOM SEG files with multiple segments","text":""},{"location":"user_guide/case_examples/#scenario_4","title":"Scenario","text":"<p>You have a folder of cases. Each case contains:</p> <ul> <li><code>Image/</code>: the DICOM image series (CT/MR/etc.)</li> <li><code>segmentation.dcm</code>: a DICOM SEG file with multiple labeled segments (e.g., liver, spleen, kidneys)</li> </ul> <p>You want to:</p> <ul> <li>Load the image and inspect the available segments in the SEG file.</li> <li>Process each segment separately to get per-organ radiomics.</li> <li>Apply standard preprocessing and compute features for each segment.</li> <li>Export results with segment labels in the output.</li> </ul>"},{"location":"user_guide/case_examples/#notes_2","title":"Notes","text":"<ul> <li><code>get_segment_info()</code> returns metadata about each segment (number, label, algorithm).</li> <li><code>load_seg()</code> with <code>combine_segments=False</code> returns a dict mapping segment numbers to <code>Image</code> objects.</li> <li>Alignment: Use <code>reference_image</code> to ensure the SEG mask matches the CT geometry.</li> </ul>"},{"location":"user_guide/case_examples/#full-example-script_4","title":"Full example script","text":"<pre><code>from pathlib import Path\nfrom pictologics import load_image, load_seg, RadiomicsPipeline\nfrom pictologics.loaders import get_segment_info\nfrom pictologics.results import format_results, save_results\n\n\ndef main():\n    # Configure paths\n    cases_dir = Path(\"path/to/cases_root\")\n    output_csv = Path(\"case5_per_segment_results.csv\")\n    log_dir = Path(\"case5_logs\")\n    log_dir.mkdir(parents=True, exist_ok=True)\n\n    # Find all case directories\n    case_dirs = sorted([p for p in cases_dir.iterdir() if p.is_dir()])\n    if not case_dirs:\n        raise ValueError(f\"No case folders found in: {cases_dir}\")\n\n    # Initialize pipeline with standard config\n    pipeline = RadiomicsPipeline()\n    pipeline.add_config(\n        \"case5_fbn_32\",\n        [\n            {\"step\": \"resample\", \"params\": {\"new_spacing\": (1.0, 1.0, 1.0)}},\n            {\"step\": \"discretise\", \"params\": {\"method\": \"FBN\", \"n_bins\": 32}},\n            {\n                \"step\": \"extract_features\",\n                \"params\": {\n                    \"families\": [\"intensity\", \"morphology\", \"texture\", \"histogram\"],\n                    \"include_spatial_intensity\": False,\n                    \"include_local_intensity\": False,\n                },\n            },\n        ],\n    )\n\n    from tqdm import tqdm\n    rows = []\n\n    for case_dir in tqdm(case_dirs, desc=\"Radiomics (per-segment)\", unit=\"case\"):\n        subject_id = case_dir.name\n        image_root = case_dir / \"Image\"\n        seg_file = case_dir / \"segmentation.dcm\"\n\n        # Load the reference image\n        image = load_image(str(image_root), recursive=True)\n\n        # Inspect available segments\n        segments = get_segment_info(str(seg_file))\n        print(f\"\\n{subject_id}: Found {len(segments)} segments\")\n        for seg in segments:\n            print(f\"  Segment {seg['segment_number']}: {seg['segment_label']}\")\n\n        # Load each segment separately, aligned to image geometry\n        segment_masks = load_seg(\n            str(seg_file),\n            combine_segments=False,  # Returns dict {seg_num: Image}\n            reference_image=image\n        )\n\n        # Process each segment\n        for seg_num, mask in segment_masks.items():\n            # Find segment label from metadata\n            seg_info = next(s for s in segments if s[\"segment_number\"] == seg_num)\n            seg_label = seg_info[\"segment_label\"]\n\n            pipeline.clear_log()\n            results = pipeline.run(\n                image=image,\n                mask=mask,\n                subject_id=f\"{subject_id}_{seg_label}\",\n                config_names=[\"case5_fbn_32\"],\n            )\n\n            row = format_results(\n                results,\n                fmt=\"wide\",\n                meta={\n                    \"subject_id\": subject_id,\n                    \"segment_number\": seg_num,\n                    \"segment_label\": seg_label,\n                },\n            )\n            rows.append(row)\n\n            # Save per-segment log\n            pipeline.save_log(str(log_dir / f\"{subject_id}_{seg_label}.json\"))\n\n    # Export all results\n    save_results(rows, output_csv)\n    print(f\"\\nWrote {len(rows)} rows to {output_csv}\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"user_guide/case_examples/#output-format_1","title":"Output format","text":"<ul> <li>One row per segment per case.</li> <li>Columns include:</li> <li><code>subject_id</code> - Case identifier</li> <li><code>segment_number</code> - Numeric segment ID from SEG file</li> <li><code>segment_label</code> - Human-readable segment name (e.g., \"Liver\", \"Spleen\")</li> <li>Feature columns prefixed by configuration name</li> </ul>"},{"location":"user_guide/case_examples/#output-options","title":"Output Options","text":"<p>For details on result formatting (<code>wide</code> vs <code>long</code>, <code>output_type</code> options) and export functions, see the Feature Calculations - Working with Results.</p>"},{"location":"user_guide/data_loading/","title":"Data Loading","text":"<p>This guide covers all aspects of loading medical imaging data into Pictologics. Whether you're working with NIfTI files, DICOM series, multi-phase acquisitions, or segmentation masks, this page will help you get your data into the <code>Image</code> class for radiomics analysis.</p>"},{"location":"user_guide/data_loading/#the-image-class","title":"The Image Class","text":"<p>All data in Pictologics is represented by the <code>Image</code> dataclass, which provides a standardized container for 3D medical image data. All data are stored as 3D numpy arrays, with additional metadata to describe the geometry of the data. If 2D data is provided, it is converted to a 3D numpy array with a singleton dimension.</p> <pre><code>from pictologics import Image\n\n# Image attributes:\n# - array: numpy.ndarray (3D, in X, Y, Z order)\n# - spacing: tuple[float, float, float] (voxel dimensions in mm)\n# - origin: tuple[float, float, float] (world coordinates of first voxel)\n# - direction: Optional[numpy.ndarray] (3x3 direction cosine matrix)\n# - modality: str (e.g., \"CT\", \"MR\", \"Unknown\")\n</code></pre> <p>[!NOTE] Pictologics uses (X, Y, Z) axis ordering to match ITK/SimpleITK conventions. This differs from raw DICOM (which uses Rows, Columns = Y, X) and matplotlib (which expects height, width = Y, X). All loaders handle these transformations automatically.</p>"},{"location":"user_guide/data_loading/#basic-loading-with-load_image","title":"Basic Loading with <code>load_image()</code>","text":"<p>The <code>load_image()</code> function is the primary entry point for loading data. It automatically detects the file format and handles the appropriate loading strategy.</p>"},{"location":"user_guide/data_loading/#loading-nifti-files","title":"Loading NIfTI Files","text":"<pre><code>from pictologics import load_image\n\n# Load a NIfTI file (.nii or .nii.gz)\nimage = load_image(\"path/to/scan.nii.gz\")\nmask = load_image(\"path/to/segmentation.nii.gz\")\n\nprint(f\"Shape: {image.array.shape}\")\nprint(f\"Spacing: {image.spacing}\")\nprint(f\"Origin: {image.origin}\")\n</code></pre>"},{"location":"user_guide/data_loading/#loading-dicom-series","title":"Loading DICOM Series","text":"<p>For a directory containing DICOM files from a single series:</p> <pre><code># Load all DICOM files in a directory as a single volume\nimage = load_image(\"path/to/dicom_folder/\")\n\n# Pictologics automatically:\n# - Finds all DICOM files in the directory\n# - Sorts slices by spatial position\n# - Extracts spacing, origin, and direction from headers\n# - Stacks slices into a 3D volume\n</code></pre>"},{"location":"user_guide/data_loading/#loading-a-single-dicom-file","title":"Loading a Single DICOM File","text":"<p>Single DICOM files (e.g., enhanced DICOM, segmentation objects) are also supported:</p> <pre><code># Load a single DICOM file\nimage = load_image(\"path/to/image.dcm\")\n</code></pre>"},{"location":"user_guide/data_loading/#dicom-intensity-rescaling","title":"DICOM Intensity Rescaling","text":"<p>By default, <code>load_image()</code> applies RescaleSlope and RescaleIntercept transformations to DICOM data, converting stored pixel values to real-world values (e.g., Hounsfield Units for CT). This matches the behavior of NIfTI loading, which always applies its scaling factors.</p> <pre><code># Default: values are converted (e.g., to Hounsfield Units)\nct = load_image(\"ct_scan/\")\nprint(ct.array.min(), ct.array.max())  # e.g., -1024.0 to 3000.0\n\n# If you need raw stored pixel values:\nct_raw = load_image(\"ct_scan/\", apply_rescale=False)\nprint(ct_raw.array.min(), ct_raw.array.max())  # e.g., 0 to 4095\n</code></pre> Format Rescaling Behavior NIfTI Always applies <code>scl_slope</code> and <code>scl_inter</code> from header DICOM Applies <code>RescaleSlope</code> and <code>RescaleIntercept</code> when <code>apply_rescale=True</code> (default)"},{"location":"user_guide/data_loading/#handling-sentinel-na-values","title":"Handling Sentinel (NA) Values","text":"<p>Medical imaging formats often use a sentinel value to represent missing or invalid data. Common examples:</p> Modality Common Sentinel Values CT -1024, -2048, -32768 (outside tissue HU range) MR 0 (often used for background/air) PET 0 or negative values <p>Since DICOM uses integer storage and cannot represent <code>NaN</code>, these sentinel values are substituted for missing data. To exclude them from analysis, use the <code>resegment</code> preprocessing step in your pipeline:</p> <pre><code>from pictologics import RadiomicsPipeline\n\npipeline = RadiomicsPipeline()\npipeline.add_config(\"ct_analysis\", [\n    # Exclude sentinel values by filtering to valid HU range\n    {\"step\": \"resegment\", \"params\": {\"range_min\": -100, \"range_max\": 3000}},\n    {\"step\": \"discretise\", \"params\": {\"method\": \"FBN\", \"n_bins\": 32}},\n    {\"step\": \"extract_features\", \"params\": {\"families\": [\"intensity\", \"texture\"]}},\n])\n</code></pre> <p>This is the IBSI-recommended approach \u2014 filter invalid intensities before feature extraction rather than at load time.</p> <p>[!TIP] Check your data's minimum value to identify potential sentinels: <pre><code>image = load_image(\"scan.dcm\")\nprint(f\"Min: {image.array.min()}, Max: {image.array.max()}\")\n# If min is -1024 or -2048, those are likely sentinels\n</code></pre></p>"},{"location":"user_guide/data_loading/#multi-phase-dicom-series","title":"Multi-Phase DICOM Series","text":"<p>Many clinical acquisitions contain multiple phases (e.g., cardiac CT with multiple timepoints, multi-echo MRI). Pictologics can detect and load specific phases from such datasets.</p>"},{"location":"user_guide/data_loading/#discovering-available-phases","title":"Discovering Available Phases","text":"<p>Use <code>get_dicom_phases()</code> to explore what's available before loading:</p> <pre><code>from pictologics.utilities import get_dicom_phases\n\n# Discover phases in a multi-phase DICOM directory\nphases = get_dicom_phases(\"path/to/cardiac_ct/\")\n\nprint(f\"Found {len(phases)} phases:\")\nfor phase in phases:\n    print(f\"  Phase {phase.index}: {phase.label} ({phase.num_slices} slices)\")\n</code></pre> <p>Example output: <pre><code>Found 10 phases:\n  Phase 0: CardiacPhase=0% (64 slices)\n  Phase 1: CardiacPhase=10% (64 slices)\n  Phase 2: CardiacPhase=20% (64 slices)\n  ...\n</code></pre></p> <p>Each <code>DicomPhaseInfo</code> object contains:</p> <ul> <li><code>index</code>: Phase index (0, 1, 2, ...)</li> <li><code>label</code>: Human-readable label (e.g., \"CardiacPhase=0\", \"TemporalPosition=1\")</li> <li><code>num_slices</code>: Number of slices in this phase</li> <li><code>tag_name</code>: The DICOM tag used for detection</li> <li><code>tag_value</code>: The actual tag value</li> </ul>"},{"location":"user_guide/data_loading/#loading-a-specific-phase","title":"Loading a Specific Phase","text":"<p>Use the <code>dataset_index</code> parameter to load a particular phase:</p> <pre><code># Load the first phase (index 0)\nphase_0 = load_image(\"path/to/cardiac_ct/\", dataset_index=0)\n\n# Load the second phase (index 1)\nphase_1 = load_image(\"path/to/cardiac_ct/\", dataset_index=1)\n</code></pre>"},{"location":"user_guide/data_loading/#phase-detection-priority","title":"Phase Detection Priority","text":"<p>Pictologics automatically detects phases using these DICOM tags (in order of priority):</p> <ol> <li>NominalPercentageOfCardiacPhase - Cardiac phases (percentage)</li> <li>TemporalPositionIdentifier - Temporal position index</li> <li>TriggerTime - ECG trigger time</li> <li>AcquisitionNumber - Acquisition sequence number</li> <li>EchoNumber - Multi-echo MRI</li> </ol>"},{"location":"user_guide/data_loading/#4d-nifti-files","title":"4D NIfTI Files","text":"<p>NIfTI files can contain 4D data (3D + time/phase). Use <code>dataset_index</code> similarly:</p> <pre><code># Load a 4D NIfTI file - get the first volume\nvol_0 = load_image(\"path/to/4d_data.nii.gz\", dataset_index=0)\n\n# Load the second volume\nvol_1 = load_image(\"path/to/4d_data.nii.gz\", dataset_index=1)\n</code></pre>"},{"location":"user_guide/data_loading/#dicom-segmentation-seg-files","title":"DICOM Segmentation (SEG) Files","text":"<p>DICOM SEG files are specialized objects containing segmentation masks. Use <code>load_seg()</code> for full control, or let <code>load_image()</code> auto-detect them.</p>"},{"location":"user_guide/data_loading/#auto-detection-in-load_image","title":"Auto-Detection in load_image()","text":"<pre><code># load_image() automatically detects DICOM SEG files\nmask = load_image(\"path/to/segmentation.dcm\")\n</code></pre>"},{"location":"user_guide/data_loading/#detailed-control-with-load_seg","title":"Detailed Control with load_seg()","text":"<pre><code>from pictologics import load_seg\nfrom pictologics.loaders import get_segment_info\n\n# First, inspect what segments are available\nsegments = get_segment_info(\"path/to/segmentation.dcm\")\nfor seg in segments:\n    print(f\"Segment {seg['segment_number']}: {seg['segment_label']}\")\n\n# Load all segments combined into a single label mask\n# Each segment gets its numeric label (1, 2, 3, etc.)\ncombined_mask = load_seg(\"path/to/segmentation.dcm\")\nprint(np.unique(combined_mask.array))  # [0, 1, 2, 3, ...]\n# Background = 0, Segment 1 = 1, Segment 2 = 2, etc.\n\n# Load only specific segments\nliver_mask = load_seg(\n    \"path/to/segmentation.dcm\",\n    segment_numbers=[1, 2]  # Only segments 1 and 2\n)\n\n# Load segments separately (returns dict)\nseparate_masks = load_seg(\n    \"path/to/segmentation.dcm\",\n    combine_segments=False\n)\n# separate_masks = {1: Image(...), 2: Image(...), ...}\n</code></pre>"},{"location":"user_guide/data_loading/#working-with-separate-segments","title":"Working with Separate Segments","text":"<p>When using <code>combine_segments=False</code>, you can iterate over segments for individual analysis:</p> <pre><code># Get each segment as a separate binary mask\nmasks = load_seg(\"seg.dcm\", combine_segments=False)\n\n# Iterate over segments\nfor seg_num, mask in masks.items():\n    print(f\"Segment {seg_num}: {mask.array.sum()} voxels\")\n\n# Process each segment for radiomics\nfor seg_num, mask in masks.items():\n    features = pipeline.run(image=ct, mask=mask)\n</code></pre>"},{"location":"user_guide/data_loading/#combining-specific-segments-into-a-binary-mask","title":"Combining Specific Segments into a Binary Mask","text":"<p>To merge selected segments into a single binary mask:</p> <pre><code># Load specific segments separately\nmasks = load_seg(\"seg.dcm\", segment_numbers=[1, 2], combine_segments=False)\n\n# Combine into single binary mask using logical OR\ncombined = masks[1].array | masks[2].array\n</code></pre>"},{"location":"user_guide/data_loading/#aligning-seg-to-a-reference-image","title":"Aligning SEG to a Reference Image","text":"<p>SEG files may have different geometry than the source image. Use <code>reference_image</code> to align:</p> <pre><code># Load the CT image\nct = load_image(\"path/to/ct_series/\")\n\n# Load and align the segmentation to CT geometry\nmask = load_seg(\n    \"path/to/segmentation.dcm\",\n    reference_image=ct\n)\n\n# Now mask.array.shape == ct.array.shape\n</code></pre>"},{"location":"user_guide/data_loading/#merging-multiple-images-with-load_and_merge_images","title":"Merging Multiple Images with <code>load_and_merge_images()</code>","text":"<p>When you have multiple segmentation masks (e.g., different organs, or masks split across files), use <code>load_and_merge_images()</code> to combine them.</p>"},{"location":"user_guide/data_loading/#basic-merging","title":"Basic Merging","text":"<pre><code>from pictologics import load_and_merge_images\n\n# Merge multiple mask files into one\ncombined_mask = load_and_merge_images([\n    \"path/to/liver_mask.nii.gz\",\n    \"path/to/kidney_mask.nii.gz\",\n    \"path/to/spleen_mask.nii.gz\"\n])\n</code></pre>"},{"location":"user_guide/data_loading/#relabeling-masks-for-visualization","title":"Relabeling Masks for Visualization","text":"<p>When merging binary masks, assign unique labels to each:</p> <pre><code># Each mask gets a unique label (1, 2, 3, ...)\ncombined = load_and_merge_images(\n    [\"mask1.nii.gz\", \"mask2.nii.gz\", \"mask3.nii.gz\"],\n    relabel_masks=True\n)\n# Result: voxels from mask1 = 1, mask2 = 2, mask3 = 3\n</code></pre>"},{"location":"user_guide/data_loading/#merge-strategy-options","title":"Merge Strategy Options","text":"<p>Control how overlapping voxels are handled:</p> <pre><code># \"max\" (default): Take the maximum value at each voxel\ncombined = load_and_merge_images(masks, merge_strategy=\"max\")\n\n# \"sum\": Add values (useful for probability maps)\ncombined = load_and_merge_images(masks, merge_strategy=\"sum\")\n\n# \"first\": Keep the first non-zero value\ncombined = load_and_merge_images(masks, merge_strategy=\"first\")\n\n# \"last\": Keep the last non-zero value\ncombined = load_and_merge_images(masks, merge_strategy=\"last\")\n</code></pre>"},{"location":"user_guide/data_loading/#handling-cropped-masks","title":"Handling Cropped Masks","text":"<p>Medical imaging software often stores segmentation masks as cropped volumes (bounding boxes around the region of interest) to minimize storage. When loading these cropped masks, they need to be repositioned into the original image's coordinate space for proper visualization and analysis.</p> <p>The <code>pictologics</code> loader uses the spatial metadata (<code>ImagePositionPatient</code> for DICOM, affine matrix for NIfTI) to calculate where the cropped mask belongs in the full volume.</p>"},{"location":"user_guide/data_loading/#repositioning-a-single-cropped-mask","title":"Repositioning a Single Cropped Mask","text":"<pre><code># Load the full CT image\nct = load_image(\"path/to/full_ct/\")\n\n# Load a cropped mask and reposition it\ncropped_mask = load_image(\n    \"path/to/cropped_mask.nii.gz\",\n    reference_image=ct\n)\n# cropped_mask now has the same shape as ct\n</code></pre>"},{"location":"user_guide/data_loading/#merging-multiple-cropped-masks","title":"Merging Multiple Cropped Masks","text":"<pre><code># Load CT as reference\nct = load_image(\"path/to/ct/\")\n\n# Merge cropped masks into reference space\ncombined = load_and_merge_images(\n    [\"cropped_liver.nii.gz\", \"cropped_kidney.nii.gz\"],\n    reference_image=ct,\n    reposition_to_reference=True,\n    relabel_masks=True\n)\n</code></pre>"},{"location":"user_guide/data_loading/#handling-axis-transposition","title":"Handling Axis Transposition","text":"<p>If your masks have different axis ordering (e.g., from different software), specify the transformation:</p> <pre><code>combined = load_and_merge_images(\n    mask_paths,\n    reference_image=ct,\n    reposition_to_reference=True,\n    transpose_axes=(1, 0, 2)  # Swap X and Y axes\n)\n</code></pre>"},{"location":"user_guide/data_loading/#error-handling","title":"Error Handling","text":"Issue Behavior Spacing mismatch <code>ValueError</code> raised (resampling not yet supported) Orientation mismatch Warning emitted, positioning continues Mask outside reference bounds Warning emitted, empty volume returned Partial overlap Valid region is positioned, rest is clipped <p>[!TIP] Label Order: When using <code>relabel_masks=True</code>, labels are assigned based on the order of files in <code>image_paths</code>. Use <code>sorted()</code> for consistent ordering, or specify the exact order you want.</p>"},{"location":"user_guide/data_loading/#creating-a-full-mask","title":"Creating a Full Mask","text":"<p>When you don't have a segmentation mask and want to analyze the entire image:</p> <pre><code>from pictologics import create_full_mask\n\n# Create a mask of all ones matching the image geometry\nimage = load_image(\"scan.nii.gz\")\nfull_mask = create_full_mask(image)\n\n# Now use full_mask for whole-image analysis\n</code></pre> <p>[!TIP] If you pass <code>mask=None</code> to <code>RadiomicsPipeline.run()</code>, it automatically creates a full mask internally.</p>"},{"location":"user_guide/data_loading/#complete-workflow-examples","title":"Complete Workflow Examples","text":""},{"location":"user_guide/data_loading/#example-1-standard-nifti-workflow","title":"Example 1: Standard NIfTI Workflow","text":"<pre><code>from pictologics import load_image, RadiomicsPipeline\n\n# Load image and mask\nimage = load_image(\"patient_ct.nii.gz\")\nmask = load_image(\"tumor_segmentation.nii.gz\")\n\n# Run radiomics pipeline\npipeline = RadiomicsPipeline()\nresults = pipeline.run(image, mask, config_names=[\"standard_fbn_32\"])\n</code></pre>"},{"location":"user_guide/data_loading/#example-2-multi-phase-dicom-analysis","title":"Example 2: Multi-Phase DICOM Analysis","text":"<pre><code>from pictologics import load_image\nfrom pictologics.utilities import get_dicom_phases\n\n# Discover available phases\nphases = get_dicom_phases(\"cardiac_ct_folder/\")\nprint(f\"Found {len(phases)} cardiac phases\")\n\n# Analyze each phase\nfor phase in phases:\n    image = load_image(\"cardiac_ct_folder/\", dataset_index=phase.index)\n    print(f\"Phase {phase.label}: shape = {image.array.shape}\")\n    # ... run analysis on each phase\n</code></pre>"},{"location":"user_guide/data_loading/#example-3-dicom-seg-with-reference-alignment","title":"Example 3: DICOM SEG with Reference Alignment","text":"<pre><code>from pictologics import load_image, load_seg\nfrom pictologics.loaders import get_segment_info\n\n# Load the CT series\nct = load_image(\"ct_series/\")\n\n# Check available segments\nsegments = get_segment_info(\"segmentation.dcm\")\nprint(\"Available segments:\", [s['segment_label'] for s in segments])\n\n# Load only the liver segment, aligned to CT\nliver = load_seg(\n    \"segmentation.dcm\",\n    segment_numbers=[1],\n    reference_image=ct\n)\n\n# Verify alignment\nassert liver.array.shape == ct.array.shape\n</code></pre>"},{"location":"user_guide/data_loading/#example-4-merging-cropped-multi-organ-masks","title":"Example 4: Merging Cropped Multi-Organ Masks","text":"<pre><code>from pictologics import load_image, load_and_merge_images\n\n# Reference CT\nct = load_image(\"full_body_ct/\")\n\n# List of cropped organ masks\norgan_masks = [\n    \"liver_cropped.nii.gz\",\n    \"spleen_cropped.nii.gz\",\n    \"left_kidney_cropped.nii.gz\",\n    \"right_kidney_cropped.nii.gz\"\n]\n\n# Merge all into reference space with unique labels\ncombined = load_and_merge_images(\n    organ_masks,\n    reference_image=ct,\n    reposition_to_reference=True,\n    relabel_masks=True\n)\n\n# Result: combined.array contains:\n# 0 = background, 1 = liver, 2 = spleen, 3 = left kidney, 4 = right kidney\n</code></pre>"},{"location":"user_guide/data_loading/#summary-of-loading-functions","title":"Summary of Loading Functions","text":"Function Purpose <code>load_image()</code> Main entry point - loads NIfTI, DICOM series, single DICOM, or DICOM SEG <code>load_seg()</code> Detailed DICOM SEG loading with segment selection and alignment <code>get_segment_info()</code> Inspect available segments in a DICOM SEG file <code>load_and_merge_images()</code> Combine multiple images/masks with various strategies <code>create_full_mask()</code> Create an all-ones mask matching image geometry <code>get_dicom_phases()</code> Discover available phases in multi-phase DICOM"},{"location":"user_guide/data_loading/#next-steps","title":"Next Steps","text":"<ul> <li>Feature Calculations - Get started with your first radiomics analysis</li> <li>Pipeline Usage - Configure and run the radiomics pipeline</li> <li>Utilities - DICOM database parsing, visualization, and more</li> </ul>"},{"location":"user_guide/feature_calculations/","title":"Feature Calculations","text":"<p>This guide walks you through extracting radiomic features from medical images using Pictologics.</p>"},{"location":"user_guide/feature_calculations/#prerequisites","title":"Prerequisites","text":"<p>You will need:</p> <ol> <li>A medical image (e.g., <code>image.nii.gz</code>, DICOM folder, or a single DICOM file).</li> <li>Optionally a corresponding mask/segmentation (e.g., <code>mask.nii.gz</code>).</li> </ol> <p>Note</p> <p>Mask is optional If you omit <code>mask</code> (or pass <code>mask=None</code> / <code>mask=\"\"</code>), Pictologics treats the entire image as the ROI by generating a full (all-ones) mask internally. This can be useful for certain workflows (see the Case examples page), but it may not be scientifically appropriate for all studies.</p> <p>Detailed information on how to load images and masks can be found in the Data Loading guide.</p>"},{"location":"user_guide/feature_calculations/#method-1-the-radiomics-pipeline-recommended","title":"Method 1: The Radiomics Pipeline (Recommended)","text":"<p>For reproducible research and standardisation, use the <code>RadiomicsPipeline</code>. This ensures that all preprocessing steps (resampling, resegmentation, discretisation) are applied consistently.</p> <p>Pictologics includes a set of Standard Configurations commonly used in radiomic analyses. You can run all of them with a single command.</p> <p>Note</p> <p>Default performance behavior The built-in <code>standard_*</code> configurations disable the two most time-intensive intensity extras by default: spatial intensity (Moran's I / Geary's C) and local intensity peak features.</p> <p>If you need these metrics, see the customization examples below.</p> <pre><code>from pictologics import RadiomicsPipeline, format_results, save_results\n\n# 1. Initialize the pipeline\npipeline = RadiomicsPipeline()\n\n# 2. Run the \"all_standard\" configurations\nresults = pipeline.run(\n    image=\"path/to/image.nii.gz\",\n    mask=\"path/to/mask.nii.gz\",\n    subject_id=\"Subject_001\",\n    config_names=[\"all_standard\"]\n)\n\n# 3. Format and Save Results\nrow = format_results(\n    results, \n    fmt=\"wide\", \n    meta={\"subject_id\": \"Subject_001\"}\n)\nsave_results([row], \"results.csv\")\n\nprint(f\"Saved {len(results)} configurations to results.csv\")\n</code></pre>"},{"location":"user_guide/feature_calculations/#intelligent-image-routing","title":"Intelligent image routing","text":"<p>The pipeline automatically uses the correct image for each feature family. After discretisation, the pipeline maintains both the original (raw) image and the discretised image, ensuring each feature type gets the appropriate input.</p> Feature Family Image Used Why Intensity Raw image Statistics require original continuous values Morphology Raw image Volume/surface calculations use original geometry Histogram Discretised Bin-based statistics require integer bins Texture (GLCM, GLRLM, etc.) Discretised Co-occurrence matrices require discrete grey levels IVH Configurable Can use raw (continuous) or discretised values <p>Example workflow:</p> <pre><code>pipeline.add_config(\"my_config\", [\n    # Step 1: Resample to 0.5mm isotropic\n    {\"step\": \"resample\", \"params\": {\"new_spacing\": (0.5, 0.5, 0.5)}},\n\n    # Step 2: Discretise with 32 bins (creates discretised copy)\n    {\"step\": \"discretise\", \"params\": {\"method\": \"FBN\", \"n_bins\": 32}},\n\n    # Step 3: Extract features (routing happens automatically)\n    {\"step\": \"extract_features\", \"params\": {\n        \"families\": [\"intensity\", \"morphology\", \"texture\", \"histogram\"]\n    }}\n])\n\n# When extract_features runs:\n# - intensity features \u2192 uses resampled raw image\n# - morphology features \u2192 uses resampled raw image  \n# - histogram features \u2192 uses discretised image\n# - texture features \u2192 uses discretised image\n</code></pre> <p>This means you don't need to worry about which image to pass \u2014 the pipeline handles it correctly.</p>"},{"location":"user_guide/feature_calculations/#working-with-results","title":"Working with results","text":"<p>The <code>format_results()</code> function converts pipeline output into different formats for analysis or export.</p> <p>Format Options (<code>fmt</code>):</p> <ol> <li> <p>Wide Format (<code>fmt=\"wide\"</code>): One row per subject with all features as columns.     Column names use the pattern <code>{config}__{feature}</code> (e.g., <code>standard_fbn_32__mean_intensity_Q4LE</code>).     <pre><code>row = format_results(results, fmt=\"wide\", meta={\"subject_id\": \"case1\"})\n# Returns: {\"subject_id\": \"case1\", \"standard_fbn_32__mean_intensity_Q4LE\": 123.4, ...}\n</code></pre></p> </li> <li> <p>Long Format (<code>fmt=\"long\"</code>): Tidy data with one row per feature. The configuration name is automatically included in a <code>config</code> column \u2014 you don't need to specify it in <code>meta</code>.     <pre><code>df = format_results(results, fmt=\"long\", meta={\"subject_id\": \"case1\"}, output_type=\"pandas\")\n# Returns DataFrame with columns: [subject_id, config, feature_name, value]\n# Example rows:\n# | subject_id | config          | feature_name        | value  |\n# |------------|-----------------|---------------------|--------|\n# | case1      | standard_fbn_32 | mean_intensity_Q4LE | 123.4  |\n# | case1      | standard_fbn_32 | volume_RNU0         | 5420.0 |\n# | case1      | standard_fbs_8  | mean_intensity_Q4LE | 123.4  |\n</code></pre></p> </li> </ol> <p>Output Types (<code>output_type</code>):</p> <ul> <li><code>\"dict\"</code> (default): Returns a Python dictionary (wide) or list of dicts (long)</li> <li><code>\"pandas\"</code>: Returns a <code>pandas.DataFrame</code></li> <li><code>\"json\"</code>: Returns a JSON string</li> </ul>"},{"location":"user_guide/feature_calculations/#batch-processing-pattern","title":"Batch Processing Pattern","text":"<pre><code>all_rows = []\nfor file in image_files:\n    res = pipeline.run(image=file, ...)\n    # Format and collect\n    all_rows.append(format_results(res, fmt=\"wide\", meta={\"filename\": file.name}))\n\n# Save everything at once (automatically merges columns)\nsave_results(all_rows, \"full_study_results.csv\")\n</code></pre>"},{"location":"user_guide/feature_calculations/#customizing-the-pipeline","title":"Customizing the pipeline","text":"<p>You can define your own steps to enable advanced features or change parameters.</p> <pre><code>from pictologics import RadiomicsPipeline\n\n# Define a config ensuring 0.5mm isotropic pixels and enabling robust texture extraction\ncfg = [\n    {\"step\": \"resample\", \"params\": {\"new_spacing\": (0.5, 0.5, 0.5), \"round_intensities\": True}},\n    {\"step\": \"discretise\", \"params\": {\"method\": \"FBN\", \"n_bins\": 32}},\n    {\n        \"step\": \"extract_features\",\n        \"params\": {\n            \"families\": [\"intensity\", \"morphology\", \"texture\", \"histogram\", \"ivh\"],\n            \"include_spatial_intensity\": True,  # Enable Moran's I / Geary's C\n            \"include_local_intensity\": True,    # Enable local intensity peaks\n        },\n    },\n]\n\npipeline = RadiomicsPipeline().add_config(\"my_custom_config\", cfg)\n# ... run as normal\n</code></pre>"},{"location":"user_guide/feature_calculations/#performance-notes-practical","title":"Performance notes (practical)","text":"<ul> <li>Spatial/local intensity can be extremely slow on large ROIs. If you do not need them, keep <code>include_spatial_intensity=False</code> and <code>include_local_intensity=False</code>.</li> <li>Texture requires discretisation. If you request <code>\"texture\"</code> without including a <code>discretise</code> step first, the pipeline will raise an error.</li> <li>If you are working with large 3D images, consider resampling to a coarser spacing for exploratory work.</li> </ul>"},{"location":"user_guide/feature_calculations/#method-2-step-by-step-manual-extraction","title":"Method 2: Step-by-Step Manual Extraction","text":"<p>If you want to understand the underlying process or need granular control over a specific function, you can call the feature extraction functions directly.</p> <p>Create a new Python file (e.g., <code>extract.py</code>) and add the following code:</p> <pre><code>import numpy as np\nfrom pictologics import load_image\nfrom pictologics.preprocessing import discretise_image, resample_image\nfrom pictologics.features.intensity import calculate_intensity_features\nfrom pictologics.features.morphology import calculate_morphology_features\nfrom pictologics.features.texture import calculate_all_texture_features\n\n# 1. Load Data\n# ---------------------------------------------------------\nprint(\"Loading data...\")\nimage = load_image(\"path/to/image.nii.gz\")\nmask = load_image(\"path/to/mask.nii.gz\")\n\n# 2. Preprocessing (Optional but Recommended)\n# ---------------------------------------------------------\n# Resample to isotropic 1x1x1 mm spacing for standardisation\nprint(\"Resampling...\")\nimage = resample_image(image, new_spacing=(1.0, 1.0, 1.0))\nmask = resample_image(mask, new_spacing=(1.0, 1.0, 1.0), interpolation=\"nearest\")\n\n# 3. Extract Morphology Features\n# ---------------------------------------------------------\nprint(\"Calculating morphology...\")\nmorph_features = calculate_morphology_features(mask)\n\n# 4. Extract Intensity Features\n# ---------------------------------------------------------\nprint(\"Calculating intensity...\")\n# Get voxels inside the mask\nmasked_voxels = image.array[mask.array == 1]\nintensity_features = calculate_intensity_features(masked_voxels)\n\n# 5. Extract Texture Features\n# ---------------------------------------------------------\nprint(\"Calculating texture...\")\n# Texture requires discretisation (binning)\n# Fixed Bin Number (FBN) with 32 bins is a common choice\ndisc_image = discretise_image(image, method=\"FBN\", n_bins=32, roi_mask=mask)\n\ntexture_features = calculate_all_texture_features(\n    disc_array=disc_image.array,\n    mask_array=mask.array,\n    n_bins=32\n)\n\n# 6. Combine and Print Results\n# ---------------------------------------------------------\nall_features = {**morph_features, **intensity_features, **texture_features}\n\nprint(\"\\n--- Extraction Complete ---\")\nprint(f\"Total Features: {len(all_features)}\")\nprint(f\"Volume (RNU0): {all_features.get('volume_RNU0', 'N/A')} mm^3\")\nprint(f\"Mean Intensity (Q4LE): {all_features.get('mean_intensity_Q4LE', 'N/A')}\")\nprint(f\"Contrast (ACUI): {all_features.get('contrast_ACUI', 'N/A')}\")\n</code></pre>"},{"location":"user_guide/feature_calculations/#next-steps","title":"Next Steps","text":"<ul> <li>Read the Pipeline guide for configuration patterns and advanced parameter pass-through.</li> <li>See the Benchmarks to understand performance and compliance.</li> </ul>"},{"location":"user_guide/installation/","title":"Installation","text":""},{"location":"user_guide/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.12+</li> <li>pip</li> </ul>"},{"location":"user_guide/installation/#installation-via-pip","title":"Installation via Pip","text":"<pre><code>pip install pictologics\n</code></pre>"},{"location":"user_guide/installation/#installation-from-github","title":"Installation from GitHub","text":"<p>If you want the latest development version (or you want to install before the next PyPI release), you can install directly from the GitHub repository.</p>"},{"location":"user_guide/installation/#latest-from-main","title":"Latest from <code>main</code>","text":"<pre><code>pip install \"pictologics @ git+https://github.com/martonkolossvary/pictologics.git@main\"\n</code></pre>"},{"location":"user_guide/installation/#pinned-to-a-tag-or-commit","title":"Pinned to a tag or commit","text":"<pre><code># Example: install from a tag\npip install \"pictologics @ git+https://github.com/martonkolossvary/pictologics.git@v0.1.0\"\n\n# Example: install from a commit SHA\npip install \"pictologics @ git+https://github.com/martonkolossvary/pictologics.git@&lt;commit_sha&gt;\"\n</code></pre>"},{"location":"user_guide/installation/#editable-install-development","title":"Editable install (development)","text":"<p>Use this if you plan to modify the code.</p> <pre><code>git clone https://github.com/martonkolossvary/pictologics.git\ncd pictologics\npip install -e .\n</code></pre>"},{"location":"user_guide/installation/#eager-compilation-warmup","title":"Eager Compilation (Warmup)","text":"<p>Pictologics uses Numba for Just-In-Time (JIT) compilation to accelerate feature extraction. To ensure fast runtime performance, Pictologics performs an automatic warmup mechanism during import. This compiles the core functions immediately when <code>import pictologics</code> is executed.</p> <p>Note: This may cause the <code>import pictologics</code> statement to take a few seconds (typically 2-10s depending on your CPU) to complete. This is expected behavior and guarantees that subsequent function calls are executed at full speed without initial compilation lag.</p>"},{"location":"user_guide/installation/#disabling-warmup","title":"Disabling Warmup","text":"<p>If you need fast import times (e.g., for CLI tools checking versions or lightweight scripts) and are willing to pay the compilation cost at the first function call, you can disable this behavior by setting the environment variable:</p> <pre><code>export PICTOLOGICS_DISABLE_WARMUP=1\n</code></pre>"},{"location":"user_guide/pipeline/","title":"Radiomics Pipeline","text":"<p>The <code>RadiomicsPipeline</code> is the core engine of Pictologics for executing reproducible, standardized radiomic feature extraction workflows. It manages the entire lifecycle of the data, from loading and preprocessing to feature extraction and logging.</p>"},{"location":"user_guide/pipeline/#why-use-the-pipeline","title":"Why use the Pipeline?","text":"<ol> <li>Reproducibility: By defining a configuration (a sequence of steps), you ensure that the exact same preprocessing is applied to every image.</li> <li>State Management: The pipeline automatically handles the state of the image and masks (morphological and intensity) as they pass through steps like resampling and resegmentation.</li> <li>Standardisation: It comes with built-in configurations that adhere to IBSI standards.</li> <li>Batch Processing: You can run multiple configurations (e.g., different binning strategies) on the same image in a single pass.</li> <li>Flexibility: The pipeline executes steps in a linear fashion, allowing you to arrange steps in any order, repeat steps if needed, and implement arbitrarily complex workflows.</li> </ol>"},{"location":"user_guide/pipeline/#linear-step-execution","title":"Linear Step Execution","text":"<p>The pipeline module executes steps linearly in order. This means:</p> <ul> <li>Steps are applied one after another in the exact sequence you define.</li> <li>You can repeat steps if needed (e.g., apply <code>discretise</code> multiple times with different settings).</li> <li>You can arrange steps in any order appropriate for your workflow.</li> <li>This linear design allows for implementing complex, multi-stage preprocessing while maintaining full control.</li> </ul> <pre><code># Example: Complex workflow with repeated steps\ncomplex_config = [\n    {\"step\": \"resample\", \"params\": {\"new_spacing\": (2.0, 2.0, 2.0)}},\n    {\"step\": \"keep_largest_component\", \"params\": {\"apply_to\": \"morph\"}},\n    {\"step\": \"resegment\", \"params\": {\"range_min\": -1000, \"range_max\": 400}},\n    {\"step\": \"filter_outliers\", \"params\": {\"sigma\": 3.0}},\n    {\"step\": \"round_intensities\", \"params\": {}},  # Round after all preprocessing\n    {\"step\": \"discretise\", \"params\": {\"method\": \"FBN\", \"n_bins\": 32}},\n    {\"step\": \"extract_features\", \"params\": {\"families\": [\"texture\", \"histogram\"]}},\n]\n</code></pre>"},{"location":"user_guide/pipeline/#masks-are-optional","title":"Masks are optional","text":"<p><code>RadiomicsPipeline.run(...)</code> accepts an optional <code>mask</code> argument.</p> <ul> <li>If you pass a mask path / mask <code>Image</code>, it is used as the ROI (standard radiomics workflow).</li> <li>If you omit <code>mask</code> (or pass <code>mask=None</code> / <code>mask=\"\"</code>), Pictologics generates a full (all-ones) ROI mask internally,   meaning the entire image is treated as the initial ROI.</li> </ul> <p>Warning</p> <p>Empty ROI is an error If preprocessing removes all ROI voxels (e.g., too strict <code>resegment</code> thresholds), the pipeline raises a clear error rather than returning empty/partial feature sets.</p>"},{"location":"user_guide/pipeline/#predefined-configurations","title":"Predefined Configurations","text":"<p>Pictologics includes a suite of Standard Configurations designed to cover the most common radiomics analysis scenarios. These configurations are compliant with general best practices (e.g., IBSI).</p>"},{"location":"user_guide/pipeline/#common-characteristics","title":"Common Characteristics","text":"<p>All standard configurations share the following preprocessing steps:</p> <ul> <li>Resampling: Images are resampled to 0.5mm x 0.5mm x 0.5mm isotropic spacing using Linear interpolation (Nearest Neighbor for masks).</li> <li>Feature Families: All feature families are extracted: <code>intensity</code>, <code>morphology</code>, <code>texture</code>, <code>histogram</code>, and <code>ivh</code>.</li> </ul> <p>Note</p> <p>Performance-friendly default for standard configs The built-in <code>standard_*</code> configurations disable the two most time-intensive intensity extras by default: <code>include_spatial_intensity=False</code> and <code>include_local_intensity=False</code>.</p> <p>This does not change the general behavior of the <code>extract_features</code> step when you build your own custom configuration: if you request <code>\"intensity\"</code> in a custom config and do not specify these flags, spatial/local intensity will still be included (backward compatible).</p> <p>Warning</p> <p>Spatial/local intensity features can be very time consuming. Spatial intensity (Moran's I / Geary's C) and local intensity peak features can dominate runtime for larger ROIs. For images larger than 50\u00d750\u00d750 voxels, this is generally not recommended unless you explicitly need them.</p> <ul> <li>Standard configs: disabled by default</li> <li>Custom configs: enabled by default (unless you set <code>include_spatial_intensity=False</code> / <code>include_local_intensity=False</code>)</li> </ul>"},{"location":"user_guide/pipeline/#available-configurations","title":"Available Configurations","text":"Configuration Name Discretisation Method Parameters Description <code>standard_fbn_8</code> Fixed Bin Number (FBN) <code>n_bins=8</code> Coarse texture analysis. <code>standard_fbn_16</code> Fixed Bin Number (FBN) <code>n_bins=16</code> Medium texture analysis. <code>standard_fbn_32</code> Fixed Bin Number (FBN) <code>n_bins=32</code> Fine texture analysis (Common default). <code>standard_fbs_8</code> Fixed Bin Size (FBS) <code>bin_width=8.0</code> For absolute intensity units (e.g., HU). <code>standard_fbs_16</code> Fixed Bin Size (FBS) <code>bin_width=16.0</code> For absolute intensity units. <code>standard_fbs_32</code> Fixed Bin Size (FBS) <code>bin_width=32.0</code> For absolute intensity units."},{"location":"user_guide/pipeline/#running-standard-configurations","title":"Running Standard Configurations","text":"<p>You can run specific configurations or use the special <code>\"all_standard\"</code> keyword to run all 6 at once.</p> <pre><code>from pictologics import RadiomicsPipeline\n\npipeline = RadiomicsPipeline()\n\n# Option A: Run specific configurations\nresults = pipeline.run(\n    image=\"path/to/image.nii.gz\",\n    mask=\"path/to/mask.nii.gz\",\n    config_names=[\"standard_fbn_32\", \"standard_fbs_16\"]\n)\n\n# Option B: Run ALL 6 standard configurations (Recommended for exploration)\nall_results = pipeline.run(\n    image=\"path/to/image.nii.gz\",\n    mask=\"path/to/mask.nii.gz\",\n    config_names=[\"all_standard\"]\n)\n\n# Accessing results\nprint(all_results[\"standard_fbn_32\"])\n</code></pre>"},{"location":"user_guide/pipeline/#what-you-get-and-what-you-dont","title":"What you get (and what you don't)","text":"<p>The standard configurations are meant to be a fast, reproducible baseline:</p> <ul> <li>You get full first-order intensity statistics (<code>\"intensity\"</code>), morphology, textures, histogram, and IVH.</li> <li>You do not get spatial/local intensity extras unless you build a custom configuration and enable them.</li> </ul> <p>If you need spatial/local intensity metrics for a specific study, use a custom configuration (examples below).</p>"},{"location":"user_guide/pipeline/#custom-configurations","title":"Custom Configurations","text":"<p>For advanced users, the pipeline allows you to define custom sequences of steps. A configuration is a list of dictionaries, where each dictionary represents a step.</p>"},{"location":"user_guide/pipeline/#structure-of-a-configuration","title":"Structure of a Configuration","text":"<pre><code>config = [\n    {\n        \"step\": \"step_name\",\n        \"params\": { \"param1\": value1, \"param2\": value2 }\n    },\n    # ... more steps\n]\n</code></pre>"},{"location":"user_guide/pipeline/#practical-tips","title":"Practical tips","text":"<ul> <li>Keep preprocessing steps explicit (resampling, resegmentation, discretisation) so your results are reproducible.</li> <li>For CT in Hounsfield Units, FBS (<code>bin_width</code>) is often more interpretable; for MRI/PET, FBN (<code>n_bins</code>) can be a     reasonable choice depending on your intensity normalization.</li> <li>If you only need a subset of feature families, set <code>families</code> to avoid unnecessary work.</li> </ul>"},{"location":"user_guide/pipeline/#available-steps","title":"Available Steps","text":""},{"location":"user_guide/pipeline/#1-resample","title":"1. <code>resample</code>","text":"<p>Resamples the image and mask to a new voxel spacing.</p> <ul> <li><code>new_spacing</code>: Tuple of (x, y, z) spacing in mm (e.g., <code>(1.0, 1.0, 1.0)</code>).<ul> <li>Alias: <code>spacing</code> (older configs/tests).</li> </ul> </li> <li><code>interpolation</code>: Interpolation for the image (<code>\"linear\"</code>, <code>\"cubic\"</code>, <code>\"nearest\"</code>). Default: <code>\"linear\"</code>.</li> <li><code>mask_interpolation</code>: Interpolation for the mask (<code>\"nearest\"</code>, <code>\"linear\"</code>). Default: <code>\"nearest\"</code>.</li> <li><code>mask_threshold</code>: When using non-nearest mask interpolation, voxels above this threshold become ROI. Default: <code>0.5</code>.</li> <li><code>round_intensities</code>: Whether to round image intensities to nearest integer after resampling. Default: <code>False</code>.</li> </ul>"},{"location":"user_guide/pipeline/#2-resegment","title":"2. <code>resegment</code>","text":"<p>Refines the mask based on intensity thresholds (e.g., excluding bone from a soft tissue mask). This is also the IBSI-recommended approach for filtering out sentinel/NA values (e.g., -1024, -2048 in DICOM) that represent missing or invalid data.</p> <ul> <li><code>range_min</code>: Minimum intensity value.</li> <li><code>range_max</code>: Maximum intensity value.</li> </ul>"},{"location":"user_guide/pipeline/#3-filter_outliers","title":"3. <code>filter_outliers</code>","text":"<p>Removes outliers from the intensity mask based on standard deviations from the mean.</p> <ul> <li><code>sigma</code>: Number of standard deviations (e.g., <code>3.0</code>).</li> </ul>"},{"location":"user_guide/pipeline/#4-keep_largest_component","title":"4. <code>keep_largest_component</code>","text":"<p>Restricts the mask to the largest connected component. Useful for removing noise or disconnected artifacts.</p> <ul> <li><code>apply_to</code>: Which mask(s) to process. Options:<ul> <li><code>\"both\"</code> (default): Apply to both morphological and intensity masks.</li> <li><code>\"morph\"</code>: Apply only to the morphological mask.</li> <li><code>\"intensity\"</code>: Apply only to the intensity mask.</li> </ul> </li> </ul>"},{"location":"user_guide/pipeline/#5-round_intensities","title":"5. <code>round_intensities</code>","text":"<p>Rounds image intensities to the nearest integer. Useful before discretisation if values are close to integers.</p> <ul> <li>No parameters.</li> </ul>"},{"location":"user_guide/pipeline/#6-discretise","title":"6. <code>discretise</code>","text":"<p>Discretises the image intensities into bins. This is crucial for texture analysis.</p> <ul> <li><code>method</code>: <code>\"FBN\"</code> (Fixed Bin Number) or <code>\"FBS\"</code> (Fixed Bin Size).</li> <li><code>n_bins</code>: Number of bins (for FBN).</li> <li><code>bin_width</code>: Width of each bin (for FBS).</li> </ul>"},{"location":"user_guide/pipeline/#7-extract_features","title":"7. <code>extract_features</code>","text":"<p>Calculates the radiomic features based on the current state of the image and mask.</p> <p>Feature Calculation Inputs</p> <p>The pipeline automatically selects the appropriate image state for each feature family:</p> <ul> <li>Intensity, Morphology, Spatial Intensity, Local Intensity: Calculated on the Raw Image (non-discretised, floating-point values).</li> <li>Texture, Histogram: Calculated on the Discretised Image (integer bins).</li> <li>IVH: Configurable. Defaults to Discretised Image, but can use Raw Image (<code>ivh_use_continuous=True</code>) or a Temporary Discretisation (<code>ivh_discretisation={...}</code>).</li> </ul> <ul> <li><code>families</code>: List of feature families to extract. Options:<ul> <li><code>\"intensity\"</code>: First-order statistics (Mean, Skewness, etc.).<ul> <li>By default, this also includes spatial intensity and local intensity.</li> <li>Disable these expensive computations via <code>include_spatial_intensity=False</code> and/or     <code>include_local_intensity=False</code> in the step <code>params</code>.</li> </ul> </li> <li><code>\"spatial_intensity\"</code>: Compute only spatial intensity (Moran's I / Geary's C).</li> <li><code>\"local_intensity\"</code>: Compute only local/global intensity peak features.</li> <li><code>\"morphology\"</code>: Shape and size features (Volume, Sphericity, etc.).</li> <li><code>\"texture\"</code>: GLCM, GLRLM, GLSZM, GLDZM, NGTDM, NGLDM.</li> <li><code>\"histogram\"</code>: Intensity histogram features.</li> <li><code>\"ivh\"</code>: Intensity-Volume Histogram features.</li> </ul> </li> </ul> <p>Additional optional parameters (advanced usage):</p> <ul> <li><code>include_spatial_intensity</code> / <code>include_local_intensity</code>: Booleans controlling whether the expensive     spatial/local intensity extras are included when <code>\"intensity\"</code> is requested.</li> <li><code>ivh_params</code>: Dict forwarded to <code>calculate_ivh_features(...)</code>. Supported keys include:     <code>bin_width</code>, <code>min_val</code>, <code>max_val</code>, <code>target_range_min</code>, <code>target_range_max</code>.     (There are also backward-compatible aliases: <code>ivh_bin_width</code>, <code>ivh_min_val</code>, <code>ivh_max_val</code>,     <code>ivh_target_range_min</code>, <code>ivh_target_range_max</code>.)</li> <li><code>ivh_discretisation</code>: Dict specifying a temporary discretisation for IVH only. This allows     using different binning for IVH vs texture features. Example: <code>{\"method\": \"FBS\", \"bin_width\": 2.5, \"min_val\": -1000}</code>.</li> <li><code>ivh_use_continuous</code>: Boolean. If <code>True</code>, uses raw (non-discretised) intensity values for IVH calculation.     Useful for \"continuous IVH\" as specified in some IBSI configurations.</li> <li><code>texture_matrix_params</code>: Dict forwarded to <code>calculate_all_texture_matrices(...)</code>.     Currently useful key: <code>ngldm_alpha</code> (IBSI default is <code>0</code>).</li> </ul>"},{"location":"user_guide/pipeline/#examples","title":"Examples","text":""},{"location":"user_guide/pipeline/#example-1-standard-suite-fast-baseline","title":"Example 1: Standard suite (fast baseline)","text":"<p>Runs all 6 built-in configurations. Spatial/local intensity extras are disabled by default.</p> <pre><code>from pictologics import RadiomicsPipeline\n\npipeline = RadiomicsPipeline()\nresults = pipeline.run(\n    image=\"path/to/image.nii.gz\",\n    mask=\"path/to/mask.nii.gz\",\n    config_names=[\"all_standard\"],\n)\n\n# Access one configuration\nprint(results[\"standard_fbn_32\"].head())\n</code></pre>"},{"location":"user_guide/pipeline/#example-1b-maskless-run-whole-image-roi","title":"Example 1b: Maskless run (whole-image ROI)","text":"<p>If you do not have a segmentation mask, you can omit the <code>mask</code> argument entirely.</p> <pre><code>from pictologics import RadiomicsPipeline\n\npipeline = RadiomicsPipeline()\nresults = pipeline.run(\n    image=\"path/to/image.nii.gz\",\n    # mask omitted -&gt; whole-image ROI\n    config_names=[\"standard_fbn_32\"],\n)\n\nprint(results[\"standard_fbn_32\"].head())\n</code></pre> <p>Note</p> <p>Morphology meaning With a maskless run, morphology features describe the ROI mask after any mask-refining steps (e.g., <code>resegment</code>, <code>keep_largest_component</code>). Starting from a whole-image ROI can be valid, but may not be scientifically meaningful for many radiomics studies.</p>"},{"location":"user_guide/pipeline/#example-2-enable-spatiallocal-intensity-extras-custom-config","title":"Example 2: Enable spatial/local intensity extras (custom config)","text":"<p>Use this when you explicitly need Moran\u2019s I / Geary\u2019s C and local intensity peak features.</p> <pre><code>from pictologics import RadiomicsPipeline\n\ncfg = [\n    {\"step\": \"resample\", \"params\": {\"new_spacing\": (0.5, 0.5, 0.5)}},\n    {\"step\": \"discretise\", \"params\": {\"method\": \"FBN\", \"n_bins\": 32}},\n    {\n        \"step\": \"extract_features\",\n        \"params\": {\n            \"families\": [\"intensity\", \"morphology\", \"texture\", \"histogram\", \"ivh\"],\n            \"include_spatial_intensity\": True,\n            \"include_local_intensity\": True,\n        },\n    },\n]\n\npipeline = RadiomicsPipeline().add_config(\"with_intensity_extras\", cfg)\nout = pipeline.run(\"path/to/image.nii.gz\", \"path/to/mask.nii.gz\", config_names=[\"with_intensity_extras\"])\nprint(out[\"with_intensity_extras\"].filter(like=\"_\"))\n</code></pre>"},{"location":"user_guide/pipeline/#example-3-only-compute-the-expensive-parts-explicit-families","title":"Example 3: Only compute the expensive parts (explicit families)","text":"<p>If you only want spatial/local intensity and not the entire first-order intensity set:</p> <pre><code>from pictologics import RadiomicsPipeline\n\ncfg = [\n    {\"step\": \"resample\", \"params\": {\"new_spacing\": (1.0, 1.0, 1.0)}},\n    {\n        \"step\": \"extract_features\",\n        \"params\": {\"families\": [\"spatial_intensity\", \"local_intensity\"]},\n    },\n]\n\npipeline = RadiomicsPipeline().add_config(\"intensity_extras_only\", cfg)\nout = pipeline.run(\"path/to/image.nii.gz\", \"path/to/mask.nii.gz\", config_names=[\"intensity_extras_only\"])\nprint(out[\"intensity_extras_only\"].head())\n</code></pre>"},{"location":"user_guide/pipeline/#example-4-ivh-with-physical-unit-mapping-advanced","title":"Example 4: IVH with physical-unit mapping (advanced)","text":"<p>When you discretise with FBS, you can map IVH to physical units by passing <code>bin_width</code> and <code>min_val</code>.</p> <pre><code>from pictologics import RadiomicsPipeline\n\ncfg = [\n    {\"step\": \"resample\", \"params\": {\"new_spacing\": (1.0, 1.0, 1.0)}},\n    {\"step\": \"discretise\", \"params\": {\"method\": \"FBS\", \"bin_width\": 25.0, \"min_val\": -1000}},\n    {\n        \"step\": \"extract_features\",\n        \"params\": {\n            \"families\": [\"ivh\"],\n            \"ivh_params\": {\n                \"bin_width\": 25.0,\n                \"min_val\": -1000,\n                \"target_range_max\": 400,\n            },\n        },\n    },\n]\n\npipeline = RadiomicsPipeline().add_config(\"ivh_hu\", cfg)\nout = pipeline.run(\"path/to/image.nii.gz\", \"path/to/mask.nii.gz\", config_names=[\"ivh_hu\"])\nprint(out[\"ivh_hu\"].head())\n</code></pre>"},{"location":"user_guide/pipeline/#example-5-texture-with-ngldm-tolerance-ngldm_alpha","title":"Example 5: Texture with NGLDM tolerance (<code>ngldm_alpha</code>)","text":"<p>IBSI default is <code>ngldm_alpha=0</code> (exact match). If you want tolerance of \u00b11 grey level, set <code>ngldm_alpha=1</code>.</p> <pre><code>from pictologics import RadiomicsPipeline\n\ncfg = [\n    {\"step\": \"resample\", \"params\": {\"new_spacing\": (1.0, 1.0, 1.0)}},\n    {\"step\": \"discretise\", \"params\": {\"method\": \"FBN\", \"n_bins\": 32}},\n    {\n        \"step\": \"extract_features\",\n        \"params\": {\n            \"families\": [\"texture\"],\n            \"texture_matrix_params\": {\"ngldm_alpha\": 1},\n        },\n    },\n]\n\npipeline = RadiomicsPipeline().add_config(\"texture_ngldm_tolerant\", cfg)\nout = pipeline.run(\"path/to/image.nii.gz\", \"path/to/mask.nii.gz\", config_names=[\"texture_ngldm_tolerant\"])\nprint(out[\"texture_ngldm_tolerant\"].head())\n</code></pre>"},{"location":"user_guide/pipeline/#example-custom-ct-pipeline","title":"Example: Custom CT Pipeline","text":"<pre><code>custom_config = [\n    # 1. Resample to 1mm isotropic\n    {\n        \"step\": \"resample\",\n        \"params\": {\"new_spacing\": (1.0, 1.0, 1.0)}\n    },\n    # 2. Restrict to soft tissue window (-150 to 250 HU)\n    {\n        \"step\": \"resegment\",\n        \"params\": {\"range_min\": -150, \"range_max\": 250}\n    },\n    # 3. Discretise with Fixed Bin Number = 64\n    {\n        \"step\": \"discretise\",\n        \"params\": {\"method\": \"FBN\", \"n_bins\": 64}\n    },\n    # 4. Extract everything\n    {\n        \"step\": \"extract_features\",\n        \"params\": {\"families\": [\"intensity\", \"morphology\", \"texture\", \"histogram\", \"ivh\"]}\n    }\n]\n\npipeline = RadiomicsPipeline()\npipeline.add_config(\"my_custom_ct\", custom_config)\nresults = pipeline.run(image, mask, config_names=[\"my_custom_ct\"])\n</code></pre>"},{"location":"user_guide/pipeline/#logging","title":"Logging","text":"<p>The pipeline maintains a detailed log of every step executed, including parameters and any errors encountered. This is vital for auditing and debugging.</p> <pre><code># After running the pipeline\npipeline.save_log(\"pipeline_execution_log.json\")\n</code></pre> <p>The log file contains:</p> <ul> <li>Timestamp</li> <li>Subject ID</li> <li>Configuration Name</li> <li>List of executed steps with their parameters</li> <li>Status of each step</li> </ul>"},{"location":"user_guide/utilities/","title":"Utilities","text":"<p>Pictologics provides a set of powerful utilities to help with data wrangling and organization, particularly for handling complex DICOM datasets.</p>"},{"location":"user_guide/utilities/#dicom-database-parser","title":"DICOM Database Parser","text":"<p>The <code>DicomDatabase</code> class allows you to easily parse, organize, and query DICOM folders. It automatically structures your data into a Patient -&gt; Study -&gt; Series -&gt; Instance hierarchy and extracts relevant metadata.</p>"},{"location":"user_guide/utilities/#basic-usage","title":"Basic Usage","text":"<p>To parse a directory of DICOM files:</p> <pre><code>from pictologics.utilities import DicomDatabase\n\n# 1. Parse a folder (recursive by default)\ndb = DicomDatabase.from_folders(\n    paths=[\"path/to/dicom/folder\"], \n    num_workers=4  # Use parallel processing for speed\n)\n\n# 2. Get a summary DataFrame of all series\ndf_series = db.get_series_df()\nprint(df_series.head())\n\n# 3. Get detailed DataFrame of all instances\ndf_instances = db.get_instances_df()\n</code></pre>"},{"location":"user_guide/utilities/#parallel-processing-and-progress-bar","title":"Parallel Processing and Progress Bar","text":"<p>For large DICOM datasets, parsing can take significant time. <code>DicomDatabase.from_folders()</code> supports parallel processing to speed up the scan and displays a progress bar showing progress and estimated time remaining.</p> <pre><code># Parallel processing with all available cores\ndb = DicomDatabase.from_folders(\n    paths=[\"large_dataset/\"],\n    num_workers=8,          # Use 8 parallel workers\n    show_progress=True      # Show progress bar (default: True)\n)\n\n# Disable progress bar for silent operation\ndb = DicomDatabase.from_folders(\n    paths=[\"data/\"],\n    show_progress=False\n)\n</code></pre> <p>The progress bar shows: - Number of files processed - Percentage complete - Elapsed time and estimated time remaining</p>"},{"location":"user_guide/utilities/#memory-efficient-exports","title":"Memory-Efficient Exports","text":"<p>By default, DataFrame exports exclude the large <code>InstanceSOPUIDs</code> and <code>InstanceFilePaths</code> columns to reduce memory usage. To include them:</p> <pre><code># Default: smaller DataFrames without instance lists\ndf_compact = db.get_series_df()\n\n# Include full instance lists if needed\ndf_full = db.get_series_df(include_instance_lists=True)\n</code></pre> <p>This applies to <code>get_patients_df()</code>, <code>get_studies_df()</code>, and <code>get_series_df()</code>.</p>"},{"location":"user_guide/utilities/#multi-phase-series-splitting","title":"Multi-Phase Series Splitting","text":"<p>Medical images often contain multiple phases (e.g., dynamic contrast-enhanced MRI, multiphase CT, cardiac phases) within a single \"series\" (sharing the same <code>SeriesInstanceUID</code>). <code>DicomDatabase</code> automatically detects and splits these into separate logical series for easier analysis.</p> <p>By default, <code>split_multiseries=True</code>.</p> <pre><code># Automatically splits series based on:\n# - Cardiac Phase\n# - Acquisition Number\n# - Temporal Position\n# - Echo Number\n# - Trigger Time\n# - Duplicate Spatial Positions (fallback)\n\ndb = DicomDatabase.from_folders([\"path/to/multiphase/data\"])\n\n# The resulting DataFrames will show split series with unique identifiers\n# e.g., \"1.2.3.4.5\" -&gt; \"1.2.3.4.5\" (if single phase)\n# e.g., \"1.2.3.4.5\" -&gt; \"1.2.3.4.5.1\", \"1.2.3.4.5.2\" (if multi-phase)\nseries_df = db.get_series_df()\n</code></pre>"},{"location":"user_guide/utilities/#exporting-data","title":"Exporting Data","text":"<p>You can export the structured data to standard formats:</p> <pre><code># Export all levels to CSV (default: without instance lists for smaller files)\ndb.export_csv(\"output\", levels=[\"patients\", \"studies\", \"series\", \"instances\"])\n\n# Export with full instance UIDs and file paths\ndb.export_csv(\"output\", include_instance_lists=True)\n\n# Export hierarchical JSON (includes file paths by default)\ndb.export_json(\"dataset.json\")\n\n# Export JSON without file paths for smaller files\ndb.export_json(\"dataset.json\", include_instance_lists=False)\n</code></pre>"},{"location":"user_guide/utilities/#accessing-the-hierarchy-directly","title":"Accessing the Hierarchy Directly","text":"<p>You can also traverse the object hierarchy directly if you need fine-grained control:</p> <pre><code>for patient in db.patients:\n    print(f\"Patient: {patient.patient_id}\")\n    for study in patient.studies:\n        print(f\"  Study: {study.study_date}\")\n        for series in study.series:\n            print(f\"    Series: {series.modality} ({len(series.instances)} images)\")\n\n            # Access instances\n            # series.instances is a list of DicomInstance objects\n</code></pre>"},{"location":"user_guide/utilities/#visualization","title":"Visualization","text":"<p>Pictologics provides flexible utilities for visualizing medical images and segmentation masks. The visualization functions support three display modes:</p> Mode <code>image</code> <code>mask</code> Description Overlay \u2713 \u2713 Mask overlaid on grayscale image Image Only \u2713 \u2717 Grayscale image (with optional window/level) Mask Only \u2717 \u2713 Colormap or grayscale mask display"},{"location":"user_guide/utilities/#interactive-viewer","title":"Interactive Viewer","text":"<p>Scroll through slices interactively:</p> <pre><code>from pictologics import load_image\nfrom pictologics.utilities import visualize_slices\n\nimg = load_image(\"scan.nii.gz\")\nmask = load_image(\"segmentation.nii.gz\")\n\n# Overlay mode (image + mask)\nvisualize_slices(image=img, mask=mask, alpha=0.4, colormap=\"tab20\")\n\n# Image only mode\nvisualize_slices(image=img)\n\n# Mask only mode (with colormap)\nvisualize_slices(mask=mask)\n</code></pre>"},{"location":"user_guide/utilities/#save-slices-to-files","title":"Save Slices to Files","text":"<p>Export selected slices as images:</p> <pre><code>from pictologics.utilities import save_slices\n\n# Save overlay slices\nsave_slices(\"output/\", image=img, mask=mask, slice_selection=\"10%\")\n\n# Save every 10th slice\nsave_slices(\"output/\", image=img, mask=mask, slice_selection=\"every_10\")\n\n# Save specific slices\nsave_slices(\"output/\", image=img, slice_selection=[0, 50, 100])\n</code></pre>"},{"location":"user_guide/utilities/#windowlevel-normalization","title":"Window/Level Normalization","text":"<p>For CT and MR images, use window/level controls for proper contrast:</p> <pre><code># Soft tissue window (default: center=200, width=600)\nvisualize_slices(image=img, window_center=40, window_width=400)\n\n# Bone window\nvisualize_slices(image=img, window_center=400, window_width=1800)\n\n# Lung window\nvisualize_slices(image=img, window_center=-600, window_width=1500)\n</code></pre>"},{"location":"user_guide/utilities/#colormap-options","title":"Colormap Options","text":"Colormap Labels Description <code>tab10</code> 10 Distinct categorical colors <code>tab20</code> 20 Default, 20 distinct colors <code>Set1</code> 9 Bold qualitative colors <code>Set2</code> 8 Pastel qualitative colors <code>Paired</code> 12 Paired colors"},{"location":"user_guide/utilities/#output-formats","title":"Output Formats","text":"<p>Supported formats: <code>png</code> (default), <code>jpeg</code>, <code>tiff</code></p> <pre><code>save_slices(\"output/\", image=img, mask=mask, format=\"tiff\", dpi=300)\n</code></pre>"},{"location":"user_guide/utilities/#parallel-batch-processing","title":"Parallel Batch Processing","text":"<p>For processing multiple images efficiently, use <code>concurrent.futures</code>:</p> <pre><code>from concurrent.futures import ProcessPoolExecutor\nfrom pathlib import Path\nfrom pictologics import load_image\nfrom pictologics.utilities import save_slices\n\ndef process_case(args):\n    \"\"\"Process a single image/mask pair.\"\"\"\n    image_path, mask_path, output_dir = args\n\n    # Load images\n    img = load_image(image_path, recursive=True)\n    mask = load_image(mask_path, recursive=True)\n\n    # Save slices\n    return save_slices(\n        output_dir,\n        image=img,\n        mask=mask,\n        slice_selection=\"10%\",\n        window_center=40,\n        window_width=400\n    )\n\n# Prepare list of (image, mask, output) tuples\ncases = [\n    (\"patient_001/ct/\", \"patient_001/seg.dcm\", \"output/patient_001/\"),\n    (\"patient_002/ct/\", \"patient_002/seg.dcm\", \"output/patient_002/\"),\n    (\"patient_003/ct/\", \"patient_003/seg.dcm\", \"output/patient_003/\"),\n]\n\n# Process in parallel\nwith ProcessPoolExecutor(max_workers=4) as executor:\n    results = list(executor.map(process_case, cases))\n\nprint(f\"Processed {len(results)} cases\")\n</code></pre> <p>Performance Notes</p> <ul> <li>Use <code>ProcessPoolExecutor</code> (not <code>ThreadPoolExecutor</code>) to avoid Python's GIL</li> <li>Set <code>max_workers</code> to the number of CPU cores (4-8 is typically optimal)</li> <li>Each worker loads one image at a time, so memory usage scales with <code>max_workers</code></li> </ul>"},{"location":"user_guide/utilities/#dicom-structured-reports-sr","title":"DICOM Structured Reports (SR)","text":"<p>Parse DICOM Structured Reports to extract measurements and tabular data.</p>"},{"location":"user_guide/utilities/#loading-and-parsing-sr","title":"Loading and Parsing SR","text":"<pre><code>from pictologics.utilities import SRDocument\n\nsr = SRDocument.from_file(\"measurements.dcm\")\nprint(f\"Template: {sr.template_id}\")\nprint(f\"Groups: {len(sr.measurement_groups)}\")\n</code></pre>"},{"location":"user_guide/utilities/#extracting-measurements","title":"Extracting Measurements","text":"<pre><code># Get as DataFrame\ndf = sr.get_measurements_df()\nprint(df[[\"measurement_name\", \"value\", \"unit\"]])\n\n# Export to files\nsr.export_csv(\"measurements.csv\")\nsr.export_json(\"measurements.json\")\n</code></pre>"},{"location":"user_guide/utilities/#batch-sr-processing","title":"Batch SR Processing","text":"<p>For processing multiple SR files from folders, use <code>SRDocument.from_folders()</code>:</p> <pre><code>from pictologics.utilities import SRDocument\n\n# Process all SR files in a folder (recursive by default)\nbatch = SRDocument.from_folders(\n    paths=[\"dicom_data/\"],\n    num_workers=4,  # Parallel processing\n    output_dir=\"sr_exports/\",  # Auto-export each SR\n    export_csv=True,\n    export_json=True,\n)\n\n# Access results\nprint(f\"Processed {len(batch.documents)} SR files\")\n\n# Get combined measurements from all SRs\ndf = batch.get_combined_measurements_df()\nprint(df.head())\n\n# Export combined data\nbatch.export_combined_csv(\"sr_exports/all_measurements.csv\")\nbatch.export_log(\"sr_exports/processing_log.csv\")\n</code></pre>"},{"location":"user_guide/utilities/#parallel-processing-and-progress-bar_1","title":"Parallel Processing and Progress Bar","text":"<p>For large collections of SR files, <code>SRDocument.from_folders()</code> supports parallel processing for faster parsing and displays a progress bar showing progress and estimated time remaining.</p> <pre><code># Parallel processing with 8 workers\nbatch = SRDocument.from_folders(\n    paths=[\"large_dataset/\"],\n    num_workers=8,          # Use 8 parallel workers\n    show_progress=True      # Show progress bar (default: True)\n)\n\n# Disable progress bar for silent operation\nbatch = SRDocument.from_folders(\n    paths=[\"data/\"],\n    show_progress=False\n)\n</code></pre> <p>The progress bar shows: - Number of SR files processed - Percentage complete - Elapsed time and estimated time remaining</p>"},{"location":"user_guide/utilities/#output-structure","title":"Output Structure","text":"<p>When <code>output_dir</code> is specified: <pre><code>sr_exports/\n\u251c\u2500\u2500 all_measurements.csv       # Combined measurements (optional)\n\u251c\u2500\u2500 processing_log.csv         # Log of all processed files\n\u251c\u2500\u2500 1_2_3_4_5_6.csv           # Individual SR (if export_csv=True)\n\u251c\u2500\u2500 1_2_3_4_5_6.json          # Individual SR (if export_json=True)\n\u2514\u2500\u2500 ...\n</code></pre></p>"},{"location":"user_guide/utilities/#processing-log","title":"Processing Log","text":"<p>The processing log tracks each file:</p> Column Description file_path Source SR file path sop_instance_uid SOP Instance UID status \"success\" or \"error\" num_measurements Count of measurements csv_path Path to exported CSV json_path Path to exported JSON error_message Error details if failed"}]}